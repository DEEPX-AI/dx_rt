<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.17"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>DXRT: /home/devops/workspace/ghes-actions-runner/worker-02/_work/dx_rt/dx_rt/_internal/lib/include/dxrt/inference_engine.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">DXRT
   </div>
   <div id="projectbrief">DEEPX Runtime SDK for AI inference on DEEPX devices.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.17 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_97aefd0d527b934f1d99a682da8fe6a9.html">lib</a></li><li class="navelem"><a class="el" href="dir_5a30104352ef4255dc24354b02eb2d20.html">include</a></li><li class="navelem"><a class="el" href="dir_287f01a5ea996b045710906789d63f6d.html">dxrt</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">inference_engine.h</div>  </div>
</div><!--header-->
<div class="contents">
<div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">// Copyright (c) 2022 DEEPX Corporation. All rights reserved.</span></div>
<div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment">// Licensed under the MIT License.</span></div>
<div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160; </div>
<div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="preprocessor">#pragma once</span></div>
<div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160; </div>
<div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="preprocessor">#include &quot;dxrt/common.h&quot;</span></div>
<div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160; </div>
<div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#include &lt;string&gt;</span></div>
<div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="preprocessor">#include &lt;iostream&gt;</span></div>
<div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="preprocessor">#include &lt;fstream&gt;</span></div>
<div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="preprocessor">#include &lt;cassert&gt;</span></div>
<div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="preprocessor">#include &lt;map&gt;</span></div>
<div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="preprocessor">#include &lt;memory&gt;</span></div>
<div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="preprocessor">#include &lt;mutex&gt;</span></div>
<div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="preprocessor">#include &lt;functional&gt;</span></div>
<div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="preprocessor">#include &lt;vector&gt;</span></div>
<div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160; </div>
<div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160; </div>
<div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="preprocessor">#include &quot;dxrt/model.h&quot;</span></div>
<div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="comment">// #include &quot;dxrt/inference_option.h&quot;</span></div>
<div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="preprocessor">#include &quot;dxrt/tensor.h&quot;</span></div>
<div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="preprocessor">#include &quot;dxrt/inference_option.h&quot;</span></div>
<div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;<span class="preprocessor">#include &quot;dxrt/testdata.h&quot;</span></div>
<div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="preprocessor">#include &quot;dxrt/inference_job.h&quot;</span></div>
<div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="preprocessor">#include &quot;dxrt/inference_timer.h&quot;</span></div>
<div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160; </div>
<div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160; </div>
<div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160; </div>
<div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="preprocessor">#define NPU_PARAM_FILE &quot;rmap.info&quot;</span></div>
<div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160; </div>
<div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160; </div>
<div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacedxrt.html">dxrt</a> {</div>
<div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;<span class="keyword">using</span> rmap_info = deepx_rmapinfo::RegisterInfoDatabase;</div>
<div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;<span class="keyword">class </span>Task;</div>
<div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;<span class="keyword">struct </span>TimePoint;</div>
<div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160; </div>
<div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160; </div>
<div class="line"><a name="l00064"></a><span class="lineno"><a class="line" href="classdxrt_1_1InferenceEngine.html">   64</a></span>&#160;<span class="keyword">class </span>DXRT_API <a class="code" href="classdxrt_1_1InferenceEngine.html">InferenceEngine</a></div>
<div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;{</div>
<div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;    <span class="comment">// static</span></div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;        <span class="keyword">static</span> constexpr <span class="keywordtype">int</span> INFERENCE_JOB_MAX_COUNT = 1024;  <span class="comment">// max job count</span></div>
<div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160; </div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160; <span class="keyword">public</span>:</div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;    <span class="keyword">explicit</span> <a class="code" href="classdxrt_1_1InferenceEngine.html">InferenceEngine</a>(<span class="keyword">const</span> std::string &amp;modelPath, <a class="code" href="classdxrt_1_1InferenceOption.html">InferenceOption</a> &amp;option = <a class="code" href="namespacedxrt.html#aab5060680ba2f567f47f8868cd8b1f00">DefaultInferenceOption</a>);</div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;    ~<a class="code" href="classdxrt_1_1InferenceEngine.html">InferenceEngine</a>(<span class="keywordtype">void</span>);</div>
<div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160; </div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;    TensorPtrs Run(<span class="keywordtype">void</span> *inputPtr, <span class="keywordtype">void</span> *userArg = <span class="keyword">nullptr</span>, <span class="keywordtype">void</span> *outputPtr = <span class="keyword">nullptr</span>);</div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160; </div>
<div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;    std::vector&lt;TensorPtrs&gt; Run(</div>
<div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;        <span class="keyword">const</span> std::vector&lt;void*&gt;&amp; inputBuffers,</div>
<div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;        <span class="keyword">const</span> std::vector&lt;void*&gt;&amp; outputBuffers,</div>
<div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;        <span class="keyword">const</span> std::vector&lt;void*&gt;&amp; userArgs = {}</div>
<div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;    );</div>
<div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160; </div>
<div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160; </div>
<div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;    <span class="keywordtype">int</span> RunAsync(<span class="keywordtype">void</span> *inputPtr, <span class="keywordtype">void</span> *userArg=<span class="keyword">nullptr</span>, <span class="keywordtype">void</span> *outputPtr = <span class="keyword">nullptr</span>);</div>
<div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160; </div>
<div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;    <span class="keywordtype">int</span> RunAsync(<span class="keyword">const</span> std::vector&lt;void*&gt;&amp; inputPtrs, <span class="keywordtype">void</span> *userArg=<span class="keyword">nullptr</span>, <span class="keywordtype">void</span> *outputPtr = <span class="keyword">nullptr</span>);</div>
<div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160; </div>
<div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;    <span class="keywordtype">int</span> RunAsyncMultiInput(<span class="keyword">const</span> std::map&lt;std::string, void*&gt;&amp; inputTensors, <span class="keywordtype">void</span> *userArg=<span class="keyword">nullptr</span>, <span class="keywordtype">void</span> *outputPtr = <span class="keyword">nullptr</span>);</div>
<div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160; </div>
<div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;    <span class="keywordtype">int</span> RunAsyncMultiInput(<span class="keyword">const</span> std::vector&lt;void*&gt;&amp; inputPtrs, <span class="keywordtype">void</span> *userArg=<span class="keyword">nullptr</span>, <span class="keywordtype">void</span> *outputPtr = <span class="keyword">nullptr</span>);</div>
<div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;    </div>
<div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;    [[deprecated(<span class="stringliteral">&quot;Use RunBenchmark() instead&quot;</span>)]]</div>
<div class="line"><a name="l00174"></a><span class="lineno"><a class="line" href="classdxrt_1_1InferenceEngine.html#ab0c6629f048341d62bfa3a400c90e827">  174</a></span>&#160;    <span class="keywordtype">float</span> <a class="code" href="classdxrt_1_1InferenceEngine.html#ab0c6629f048341d62bfa3a400c90e827">RunBenchMark</a>(<span class="keywordtype">int</span> num, <span class="keywordtype">void</span>* inputPtr = <span class="keyword">nullptr</span>) { <span class="keywordflow">return</span> RunBenchmark(num, inputPtr); }</div>
<div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160; </div>
<div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;    <span class="keywordtype">float</span> RunBenchmark(<span class="keywordtype">int</span> num, <span class="keywordtype">void</span>* inputPtr = <span class="keyword">nullptr</span>);</div>
<div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160; </div>
<div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;    TensorPtrs ValidateDevice(<span class="keywordtype">void</span> *inputPtr, <span class="keywordtype">int</span> deviceId = 0);</div>
<div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160; </div>
<div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;    TensorPtrs ValidateDevice(<span class="keyword">const</span> std::vector&lt;void*&gt;&amp; inputPtrs, <span class="keywordtype">int</span> deviceId = 0);</div>
<div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160; </div>
<div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;    TensorPtrs ValidateDeviceMultiInput(<span class="keyword">const</span> std::map&lt;std::string, void*&gt;&amp; inputTensors, <span class="keywordtype">int</span> deviceId = 0);</div>
<div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160; </div>
<div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;    TensorPtrs ValidateDeviceMultiInput(<span class="keyword">const</span> std::vector&lt;void*&gt;&amp; inputPtrs, <span class="keywordtype">int</span> deviceId = 0);</div>
<div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160; </div>
<div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;    [[deprecated(<span class="stringliteral">&quot;Use RegisterCallback() instead&quot;</span>)]]</div>
<div class="line"><a name="l00229"></a><span class="lineno"><a class="line" href="classdxrt_1_1InferenceEngine.html#a3d3fc75faa79470d9a3bdbdc61561a3a">  229</a></span>&#160;    <span class="keywordtype">void</span> <a class="code" href="classdxrt_1_1InferenceEngine.html#a3d3fc75faa79470d9a3bdbdc61561a3a">RegisterCallBack</a>(std::function&lt;<span class="keywordtype">int</span>(TensorPtrs&amp; outputs, <span class="keywordtype">void</span>* userArg)&gt; callbackFunc) { <span class="keywordflow">return</span> RegisterCallback(callbackFunc); }</div>
<div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160; </div>
<div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;    <span class="keywordtype">void</span> RegisterCallback(std::function&lt;<span class="keywordtype">int</span>(TensorPtrs&amp; outputs, <span class="keywordtype">void</span>* userArg)&gt; callbackFunc);</div>
<div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160; </div>
<div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;    TensorPtrs Wait(<span class="keywordtype">int</span> jobId);</div>
<div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160; </div>
<div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;    [[deprecated(<span class="stringliteral">&quot;Use GetInputs() instead&quot;</span>)]]</div>
<div class="line"><a name="l00253"></a><span class="lineno"><a class="line" href="classdxrt_1_1InferenceEngine.html#afbee8b031fdd6c0a3916ed00d08c9cd8">  253</a></span>&#160;    Tensors <a class="code" href="classdxrt_1_1InferenceEngine.html#afbee8b031fdd6c0a3916ed00d08c9cd8">inputs</a>(<span class="keywordtype">void</span> *ptr = <span class="keyword">nullptr</span>, uint64_t phyAddr = 0) { <span class="keywordflow">return</span> GetInputs(ptr, phyAddr); }</div>
<div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160; </div>
<div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;    Tensors GetInputs(<span class="keywordtype">void</span> *ptr = <span class="keyword">nullptr</span>, uint64_t phyAddr = 0);</div>
<div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160; </div>
<div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;    [[deprecated(<span class="stringliteral">&quot;Use GetInputs() instead&quot;</span>)]]</div>
<div class="line"><a name="l00270"></a><span class="lineno"><a class="line" href="classdxrt_1_1InferenceEngine.html#af81b48e8ccd95953dd9bc483e5ec678b">  270</a></span>&#160;    std::vector&lt;Tensors&gt; <a class="code" href="classdxrt_1_1InferenceEngine.html#af81b48e8ccd95953dd9bc483e5ec678b">inputs</a>(<span class="keywordtype">int</span> devId) { <span class="keywordflow">return</span> GetInputs(devId); }</div>
<div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160; </div>
<div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;    std::vector&lt;Tensors&gt; GetInputs(<span class="keywordtype">int</span> devId);</div>
<div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160; </div>
<div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;    [[deprecated(<span class="stringliteral">&quot;Use GetOutputs() instead&quot;</span>)]]</div>
<div class="line"><a name="l00287"></a><span class="lineno"><a class="line" href="classdxrt_1_1InferenceEngine.html#a0893b724d6eed939556f1315ce05829d">  287</a></span>&#160;    Tensors <a class="code" href="classdxrt_1_1InferenceEngine.html#a0893b724d6eed939556f1315ce05829d">outputs</a>(<span class="keywordtype">void</span> *ptr = <span class="keyword">nullptr</span>, uint64_t phyAddr = 0) { <span class="keywordflow">return</span> GetOutputs(ptr, phyAddr); }</div>
<div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160; </div>
<div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;    Tensors GetOutputs(<span class="keywordtype">void</span> *ptr = <span class="keyword">nullptr</span>, uint64_t phyAddr = 0);</div>
<div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160; </div>
<div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;    [[deprecated(<span class="stringliteral">&quot;Use GetInputSize() instead&quot;</span>)]]</div>
<div class="line"><a name="l00303"></a><span class="lineno"><a class="line" href="classdxrt_1_1InferenceEngine.html#a96c4e5953a0daf4a1c886002c052a6ba">  303</a></span>&#160;    uint64_t <a class="code" href="classdxrt_1_1InferenceEngine.html#a96c4e5953a0daf4a1c886002c052a6ba">input_size</a>() { <span class="keywordflow">return</span> GetInputSize(); }</div>
<div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160; </div>
<div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;    uint64_t GetInputSize();</div>
<div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160; </div>
<div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;    std::vector&lt;uint64_t&gt; GetInputTensorSizes();</div>
<div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160; </div>
<div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;    std::vector&lt;uint64_t&gt; GetOutputTensorSizes();</div>
<div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160; </div>
<div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;    [[deprecated(<span class="stringliteral">&quot;Use GetOutputSize() instead&quot;</span>)]]</div>
<div class="line"><a name="l00329"></a><span class="lineno"><a class="line" href="classdxrt_1_1InferenceEngine.html#a93e1d7b460b7f8656e725ed708de507b">  329</a></span>&#160;    uint64_t <a class="code" href="classdxrt_1_1InferenceEngine.html#a93e1d7b460b7f8656e725ed708de507b">output_size</a>() { <span class="keywordflow">return</span> GetOutputSize(); }</div>
<div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160; </div>
<div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;    uint64_t GetOutputSize();</div>
<div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160; </div>
<div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;    [[deprecated(<span class="stringliteral">&quot;Use GetModelName() instead&quot;</span>)]]</div>
<div class="line"><a name="l00343"></a><span class="lineno"><a class="line" href="classdxrt_1_1InferenceEngine.html#a3fb16094508bd367cc4971238f002765">  343</a></span>&#160;    std::string <a class="code" href="classdxrt_1_1InferenceEngine.html#a3fb16094508bd367cc4971238f002765">name</a>() { <span class="keywordflow">return</span> GetModelName(); }</div>
<div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160; </div>
<div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;    std::string GetModelName();</div>
<div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160; </div>
<div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;    [[deprecated(<span class="stringliteral">&quot;Use GetTaskOrder() instead&quot;</span>)]]</div>
<div class="line"><a name="l00357"></a><span class="lineno"><a class="line" href="classdxrt_1_1InferenceEngine.html#a578a0098f9b49902fa4c81d95945baa4">  357</a></span>&#160;    std::vector&lt;std::string&gt; <a class="code" href="classdxrt_1_1InferenceEngine.html#a578a0098f9b49902fa4c81d95945baa4">task_order</a>() { <span class="keywordflow">return</span> GetTaskOrder(); }</div>
<div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160; </div>
<div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;    std::vector&lt;std::string&gt; GetTaskOrder();</div>
<div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160; </div>
<div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;    [[deprecated(<span class="stringliteral">&quot;Use GetLatency() instead&quot;</span>)]]</div>
<div class="line"><a name="l00371"></a><span class="lineno"><a class="line" href="classdxrt_1_1InferenceEngine.html#a990ca720e7f8a28ac5394206eb6f9491">  371</a></span>&#160;    <span class="keywordtype">int</span> <a class="code" href="classdxrt_1_1InferenceEngine.html#a990ca720e7f8a28ac5394206eb6f9491">latency</a>() { <span class="keywordflow">return</span> GetLatency(); }</div>
<div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160; </div>
<div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;    <span class="keywordtype">int</span> GetLatency();</div>
<div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160; </div>
<div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;    [[deprecated(<span class="stringliteral">&quot;Use GetNpuInferenceTime() instead&quot;</span>)]]</div>
<div class="line"><a name="l00384"></a><span class="lineno"><a class="line" href="classdxrt_1_1InferenceEngine.html#aad2f3b616e0e996b66ef7df37dc16a85">  384</a></span>&#160;    uint32_t <a class="code" href="classdxrt_1_1InferenceEngine.html#aad2f3b616e0e996b66ef7df37dc16a85">inference_time</a>() { <span class="keywordflow">return</span> GetNpuInferenceTime(); }</div>
<div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160; </div>
<div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;    uint32_t GetNpuInferenceTime();</div>
<div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160; </div>
<div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;    std::vector&lt;int&gt; GetLatencyVector();</div>
<div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160; </div>
<div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;    std::vector&lt;uint32_t&gt; GetNpuInferenceTimeVector();</div>
<div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160; </div>
<div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;    <span class="keywordtype">double</span> GetLatencyMean();</div>
<div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160; </div>
<div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;    <span class="keywordtype">double</span> GetNpuInferenceTimeMean();</div>
<div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160; </div>
<div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;    <span class="keywordtype">double</span> GetLatencyStdDev();</div>
<div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160; </div>
<div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;    <span class="keywordtype">double</span> GetNpuInferenceTimeStdDev();</div>
<div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160; </div>
<div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;    <span class="keywordtype">int</span> GetLatencyCnt();</div>
<div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160; </div>
<div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;    <span class="keywordtype">int</span> GetNpuInferenceTimeCnt();</div>
<div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160; </div>
<div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;    [[deprecated(<span class="stringliteral">&quot;Use GetAllTaskOutputs() instead&quot;</span>)]]</div>
<div class="line"><a name="l00437"></a><span class="lineno"><a class="line" href="classdxrt_1_1InferenceEngine.html#a34dfe51c8f5289bd54ff96be8d64bc12">  437</a></span>&#160;    std::vector&lt;TensorPtrs&gt; <a class="code" href="classdxrt_1_1InferenceEngine.html#a34dfe51c8f5289bd54ff96be8d64bc12">get_outputs</a>() { <span class="keywordflow">return</span> GetAllTaskOutputs(); }</div>
<div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160; </div>
<div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;    std::vector&lt;TensorPtrs&gt; GetAllTaskOutputs();</div>
<div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160; </div>
<div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;    [[deprecated(<span class="stringliteral">&quot;Use GetBitmatchMask() instead&quot;</span>)]]</div>
<div class="line"><a name="l00453"></a><span class="lineno"><a class="line" href="classdxrt_1_1InferenceEngine.html#aa8ab6719ae0efdf0f5c678e3401ab57d">  453</a></span>&#160;    std::vector&lt;uint8_t&gt; <a class="code" href="classdxrt_1_1InferenceEngine.html#aa8ab6719ae0efdf0f5c678e3401ab57d">bitmatch_mask</a>(<span class="keywordtype">int</span> index) { <span class="keywordflow">return</span> GetBitmatchMask(index); }</div>
<div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160; </div>
<div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;    std::vector&lt;uint8_t&gt; GetBitmatchMask(<span class="keywordtype">int</span> index);</div>
<div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160; </div>
<div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;    [[deprecated(<span class="stringliteral">&quot;Use GetNumTailTasks() instead&quot;</span>)]]</div>
<div class="line"><a name="l00472"></a><span class="lineno"><a class="line" href="classdxrt_1_1InferenceEngine.html#a0b38cd5001ec327cbdc5b00a7143d0e2">  472</a></span>&#160;    <span class="keywordtype">int</span> <a class="code" href="classdxrt_1_1InferenceEngine.html#a0b38cd5001ec327cbdc5b00a7143d0e2">get_num_tails</a>() { <span class="keywordflow">return</span> GetNumTailTasks(); }</div>
<div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160; </div>
<div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;    <span class="keywordtype">int</span> GetNumTailTasks();</div>
<div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160; </div>
<div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;    [[deprecated(<span class="stringliteral">&quot;Use GetCompileType() instead&quot;</span>)]]</div>
<div class="line"><a name="l00489"></a><span class="lineno"><a class="line" href="classdxrt_1_1InferenceEngine.html#a265ff0d27c6bac98c0c641c0e5f8f6ba">  489</a></span>&#160;    std::string <a class="code" href="classdxrt_1_1InferenceEngine.html#a265ff0d27c6bac98c0c641c0e5f8f6ba">get_compile_type</a>() { <span class="keywordflow">return</span> GetCompileType(); }</div>
<div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160; </div>
<div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;    std::string GetCompileType();</div>
<div class="line"><a name="l00496"></a><span class="lineno">  496</span>&#160; </div>
<div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;    std::string GetModelVersion();</div>
<div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160; </div>
<div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;    [[deprecated(<span class="stringliteral">&quot;Use IsPPU() instead&quot;</span>)]]</div>
<div class="line"><a name="l00509"></a><span class="lineno"><a class="line" href="classdxrt_1_1InferenceEngine.html#a9aeb596b415843e7e318c47938444259">  509</a></span>&#160;    <span class="keywordtype">bool</span> <a class="code" href="classdxrt_1_1InferenceEngine.html#a9aeb596b415843e7e318c47938444259">is_PPU</a>() { <span class="keywordflow">return</span> IsPPU(); }</div>
<div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160; </div>
<div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;    <span class="keywordtype">bool</span> IsPPU();</div>
<div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160; </div>
<div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;    <span class="keywordtype">bool</span> IsOrtConfigured();</div>
<div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160; </div>
<div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;    <span class="keywordtype">bool</span> IsMultiInputModel() <span class="keyword">const</span>;</div>
<div class="line"><a name="l00529"></a><span class="lineno">  529</span>&#160; </div>
<div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;    <span class="keywordtype">int</span> GetInputTensorCount() <span class="keyword">const</span>;</div>
<div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160; </div>
<div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;    std::vector&lt;std::string&gt; GetInputTensorNames() <span class="keyword">const</span>;</div>
<div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160; </div>
<div class="line"><a name="l00546"></a><span class="lineno">  546</span>&#160;    std::vector&lt;std::string&gt; GetOutputTensorNames() <span class="keyword">const</span>;</div>
<div class="line"><a name="l00547"></a><span class="lineno">  547</span>&#160; </div>
<div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;    std::map&lt;std::string, std::string&gt; GetInputTensorToTaskMapping() <span class="keyword">const</span>;</div>
<div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160; </div>
<div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;    <span class="keywordtype">void</span> Dispose();</div>
<div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160; </div>
<div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;<span class="preprocessor">#ifdef _WIN32</span></div>
<div class="line"><a name="l00560"></a><span class="lineno">  560</span>&#160;    <span class="keywordtype">float</span> RunBenchMarkWindows(<span class="keywordtype">int</span> num, <span class="keywordtype">void</span>* inputPtr = <span class="keyword">nullptr</span>);</div>
<div class="line"><a name="l00561"></a><span class="lineno">  561</span>&#160;<span class="preprocessor">#endif  // _WIN32</span></div>
<div class="line"><a name="l00562"></a><span class="lineno">  562</span>&#160;    <span class="keyword">friend</span> DXRT_API std::ostream&amp; operator&lt;&lt;(std::ostream&amp;, <span class="keyword">const</span> <a class="code" href="classdxrt_1_1InferenceEngine.html">InferenceEngine</a>&amp;);</div>
<div class="line"><a name="l00563"></a><span class="lineno">  563</span>&#160;    InferenceTimer* getTimer(){<span class="keywordflow">return</span> &amp;_inferenceTimer;}</div>
<div class="line"><a name="l00564"></a><span class="lineno">  564</span>&#160; </div>
<div class="line"><a name="l00571"></a><span class="lineno">  571</span>&#160;    TensorPtrs RunMultiInput(<span class="keyword">const</span> std::map&lt;std::string, void*&gt;&amp; inputTensors, <span class="keywordtype">void</span> *userArg=<span class="keyword">nullptr</span>, <span class="keywordtype">void</span> *outputPtr=<span class="keyword">nullptr</span>);</div>
<div class="line"><a name="l00572"></a><span class="lineno">  572</span>&#160; </div>
<div class="line"><a name="l00579"></a><span class="lineno">  579</span>&#160;    TensorPtrs RunMultiInput(<span class="keyword">const</span> std::vector&lt;void*&gt;&amp; inputPtrs, <span class="keywordtype">void</span> *userArg=<span class="keyword">nullptr</span>, <span class="keywordtype">void</span> *outputPtr=<span class="keyword">nullptr</span>);</div>
<div class="line"><a name="l00580"></a><span class="lineno">  580</span>&#160; </div>
<div class="line"><a name="l00584"></a><span class="lineno">  584</span>&#160;    <span class="keywordtype">bool</span> supportsTensorCentricOffsets() <span class="keyword">const</span>;</div>
<div class="line"><a name="l00585"></a><span class="lineno">  585</span>&#160; </div>
<div class="line"><a name="l00590"></a><span class="lineno">  590</span>&#160;    uint64_t getTensorOffset(<span class="keyword">const</span> std::string&amp; tensorName) <span class="keyword">const</span>;</div>
<div class="line"><a name="l00591"></a><span class="lineno">  591</span>&#160; </div>
<div class="line"><a name="l00597"></a><span class="lineno">  597</span>&#160;    <span class="keywordtype">size_t</span> GetOutputTensorOffset(<span class="keyword">const</span> std::string&amp; tensorName) <span class="keyword">const</span>;</div>
<div class="line"><a name="l00598"></a><span class="lineno">  598</span>&#160; </div>
<div class="line"><a name="l00599"></a><span class="lineno">  599</span>&#160;    <span class="comment">// DSP Code</span></div>
<div class="line"><a name="l00600"></a><span class="lineno">  600</span>&#160;    <span class="keywordtype">int</span> DSP_GetDeviceBufferPtr(uint64_t *inputPtr, uint64_t *outputPtr);</div>
<div class="line"><a name="l00601"></a><span class="lineno">  601</span>&#160;    <span class="keywordtype">void</span> *DSP_Run(<span class="keywordtype">void</span> *inputPtr, <span class="keywordtype">void</span> *outputPtr = <span class="keyword">nullptr</span>, <span class="keywordtype">void</span> *userArg = <span class="keyword">nullptr</span>);</div>
<div class="line"><a name="l00602"></a><span class="lineno">  602</span>&#160;    <span class="keywordtype">void</span> *DSP_Wait(<span class="keywordtype">int</span> jobId);</div>
<div class="line"><a name="l00603"></a><span class="lineno">  603</span>&#160; </div>
<div class="line"><a name="l00604"></a><span class="lineno">  604</span>&#160; <span class="keyword">private</span>:  <span class="comment">// private functions</span></div>
<div class="line"><a name="l00605"></a><span class="lineno">  605</span>&#160;    <span class="keywordtype">int</span> runAsync(<span class="keywordtype">void</span> *inputPtr, <span class="keywordtype">void</span> *userArg, <span class="keywordtype">void</span> *outputPtr,</div>
<div class="line"><a name="l00606"></a><span class="lineno">  606</span>&#160;        std::function&lt;<span class="keywordtype">void</span>(TensorPtrs &amp;outputs, <span class="keywordtype">void</span> *userArg, <span class="keywordtype">int</span> jobId)&gt; batchCallback);</div>
<div class="line"><a name="l00607"></a><span class="lineno">  607</span>&#160; </div>
<div class="line"><a name="l00608"></a><span class="lineno">  608</span>&#160;    <span class="keywordtype">void</span> runSubBatch(std::vector&lt;TensorPtrs&gt;&amp; result, <span class="keywordtype">int</span> batchCount, <span class="keywordtype">int</span> startIndex, <span class="keywordtype">void</span>* batchArgs,</div>
<div class="line"><a name="l00609"></a><span class="lineno">  609</span>&#160;            <span class="keyword">const</span> std::vector&lt;void*&gt;&amp; inputPtrs,</div>
<div class="line"><a name="l00610"></a><span class="lineno">  610</span>&#160;            <span class="keyword">const</span> std::vector&lt;void*&gt;&amp; outputPtrs,</div>
<div class="line"><a name="l00611"></a><span class="lineno">  611</span>&#160;            <span class="keyword">const</span> std::vector&lt;void*&gt;&amp; userArgs);</div>
<div class="line"><a name="l00612"></a><span class="lineno">  612</span>&#160; </div>
<div class="line"><a name="l00613"></a><span class="lineno">  613</span>&#160;    <span class="comment">// Helper method to check if single input buffer should be auto-split for multi-input models</span></div>
<div class="line"><a name="l00614"></a><span class="lineno">  614</span>&#160;    <span class="keywordtype">bool</span> shouldAutoSplitInput() <span class="keyword">const</span>;</div>
<div class="line"><a name="l00615"></a><span class="lineno">  615</span>&#160; </div>
<div class="line"><a name="l00616"></a><span class="lineno">  616</span>&#160;    <span class="comment">// Helper method to check if user output buffer should be used for final output allocation</span></div>
<div class="line"><a name="l00617"></a><span class="lineno">  617</span>&#160;    <span class="keywordtype">bool</span> shouldUseUserOutputBuffer() <span class="keyword">const</span>;</div>
<div class="line"><a name="l00618"></a><span class="lineno">  618</span>&#160; </div>
<div class="line"><a name="l00619"></a><span class="lineno">  619</span>&#160; <span class="keyword">private</span>:</div>
<div class="line"><a name="l00620"></a><span class="lineno">  620</span>&#160;    std::string _modelFile;</div>
<div class="line"><a name="l00621"></a><span class="lineno">  621</span>&#160;    std::string _modelDir;</div>
<div class="line"><a name="l00622"></a><span class="lineno">  622</span>&#160;    std::string _name;</div>
<div class="line"><a name="l00623"></a><span class="lineno">  623</span>&#160;    std::string _modelCompileType;</div>
<div class="line"><a name="l00624"></a><span class="lineno">  624</span>&#160;    <span class="keywordtype">bool</span> _isOffloadingModel = <span class="keyword">false</span>;</div>
<div class="line"><a name="l00625"></a><span class="lineno">  625</span>&#160;    <span class="keywordtype">bool</span> _isPPU = <span class="keyword">false</span>;</div>
<div class="line"><a name="l00626"></a><span class="lineno">  626</span>&#160; </div>
<div class="line"><a name="l00627"></a><span class="lineno">  627</span>&#160;    ModelDataBase _modelData;</div>
<div class="line"><a name="l00628"></a><span class="lineno">  628</span>&#160;    std::vector&lt;uint8_t&gt; _maskBuf;</div>
<div class="line"><a name="l00629"></a><span class="lineno">  629</span>&#160;    std::map&lt;std::string, deepx_graphinfo::SubGraph&gt; _subGraphMap;</div>
<div class="line"><a name="l00630"></a><span class="lineno">  630</span>&#160;    InferenceOption _option;</div>
<div class="line"><a name="l00631"></a><span class="lineno">  631</span>&#160;    std::vector&lt;std::shared_ptr&lt;Task&gt;&gt; _tasks;  <span class="comment">// to be changed to complex graph</span></div>
<div class="line"><a name="l00632"></a><span class="lineno">  632</span>&#160;    std::shared_ptr&lt;Task&gt; _head;  <span class="comment">// Primary head task (for backward compatibility), actual multi-head processing uses _inputTasks</span></div>
<div class="line"><a name="l00633"></a><span class="lineno">  633</span>&#160;    std::vector&lt;std::shared_ptr&lt;Task&gt;&gt; _tails;</div>
<div class="line"><a name="l00634"></a><span class="lineno">  634</span>&#160;    <span class="keywordtype">int</span> _numTails;</div>
<div class="line"><a name="l00635"></a><span class="lineno">  635</span>&#160;    std::map&lt;std::string, std::shared_ptr&lt;Task&gt;&gt; _taskMap;</div>
<div class="line"><a name="l00636"></a><span class="lineno">  636</span>&#160;    InferenceTimer _inferenceTimer;</div>
<div class="line"><a name="l00637"></a><span class="lineno">  637</span>&#160;    std::vector&lt;std::string&gt; _taskOrder;</div>
<div class="line"><a name="l00638"></a><span class="lineno">  638</span>&#160;    std::vector&lt;std::string&gt; _lastOutputOrder;  <span class="comment">// Keep for backward compatibility</span></div>
<div class="line"><a name="l00639"></a><span class="lineno">  639</span>&#160;    std::vector&lt;std::string&gt; _finalOutputOrder;  <span class="comment">// New tensor-centric order</span></div>
<div class="line"><a name="l00640"></a><span class="lineno">  640</span>&#160; </div>
<div class="line"><a name="l00641"></a><span class="lineno">  641</span>&#160;    <span class="comment">// Multi-input support</span></div>
<div class="line"><a name="l00642"></a><span class="lineno">  642</span>&#160;    <span class="keywordtype">bool</span> _isMultiInput = <span class="keyword">false</span>;</div>
<div class="line"><a name="l00643"></a><span class="lineno">  643</span>&#160;    std::vector&lt;std::shared_ptr&lt;Task&gt;&gt; _inputTasks;</div>
<div class="line"><a name="l00644"></a><span class="lineno">  644</span>&#160;    std::vector&lt;std::string&gt; _modelInputOrder;</div>
<div class="line"><a name="l00645"></a><span class="lineno">  645</span>&#160;    std::map&lt;std::string, std::string&gt; _inputTensorToTaskMap;</div>
<div class="line"><a name="l00646"></a><span class="lineno">  646</span>&#160; </div>
<div class="line"><a name="l00647"></a><span class="lineno">  647</span>&#160;    <span class="comment">// Multi-output buffer management</span></div>
<div class="line"><a name="l00648"></a><span class="lineno">  648</span>&#160;    <span class="keywordtype">bool</span> _hasUserOutputBuffer = <span class="keyword">false</span>;</div>
<div class="line"><a name="l00649"></a><span class="lineno">  649</span>&#160;    <span class="keywordtype">void</span>* _userOutputPtr = <span class="keyword">nullptr</span>;</div>
<div class="line"><a name="l00650"></a><span class="lineno">  650</span>&#160; </div>
<div class="line"><a name="l00651"></a><span class="lineno">  651</span>&#160;    <span class="comment">// Tensor-centric management for better extensibility</span></div>
<div class="line"><a name="l00652"></a><span class="lineno">  652</span>&#160;    <span class="keyword">struct </span>TensorDescriptor {</div>
<div class="line"><a name="l00653"></a><span class="lineno">  653</span>&#160;        std::string name;</div>
<div class="line"><a name="l00654"></a><span class="lineno">  654</span>&#160;        std::string producerTask;</div>
<div class="line"><a name="l00655"></a><span class="lineno">  655</span>&#160;        std::vector&lt;std::string&gt; consumerTasks;</div>
<div class="line"><a name="l00656"></a><span class="lineno">  656</span>&#160;        <span class="keywordtype">bool</span> isModelInput = <span class="keyword">false</span>;</div>
<div class="line"><a name="l00657"></a><span class="lineno">  657</span>&#160;        <span class="keywordtype">bool</span> isModelOutput = <span class="keyword">false</span>;</div>
<div class="line"><a name="l00658"></a><span class="lineno">  658</span>&#160;        uint64_t sizeInBytes = 0;</div>
<div class="line"><a name="l00659"></a><span class="lineno">  659</span>&#160;        uint64_t outputBufferOffset = 0;  <span class="comment">// Offset in final output buffer</span></div>
<div class="line"><a name="l00660"></a><span class="lineno">  660</span>&#160; </div>
<div class="line"><a name="l00661"></a><span class="lineno">  661</span>&#160;        TensorDescriptor() = <span class="keywordflow">default</span>;</div>
<div class="line"><a name="l00662"></a><span class="lineno">  662</span>&#160;        TensorDescriptor(<span class="keyword">const</span> std::string&amp; tensorName, <span class="keyword">const</span> std::string&amp; producer)</div>
<div class="line"><a name="l00663"></a><span class="lineno">  663</span>&#160;            : name(tensorName), producerTask(producer) {}</div>
<div class="line"><a name="l00664"></a><span class="lineno">  664</span>&#160;    };</div>
<div class="line"><a name="l00665"></a><span class="lineno">  665</span>&#160; </div>
<div class="line"><a name="l00666"></a><span class="lineno">  666</span>&#160;    <span class="comment">// Tensor registry for comprehensive management</span></div>
<div class="line"><a name="l00667"></a><span class="lineno">  667</span>&#160;    std::map&lt;std::string, TensorDescriptor&gt; _tensorRegistry;</div>
<div class="line"><a name="l00668"></a><span class="lineno">  668</span>&#160; </div>
<div class="line"><a name="l00669"></a><span class="lineno">  669</span>&#160;    <span class="comment">// Helper methods for tensor-centric management</span></div>
<div class="line"><a name="l00670"></a><span class="lineno">  670</span>&#160;    <span class="keywordtype">void</span> initializeEnvironmentVariables();</div>
<div class="line"><a name="l00671"></a><span class="lineno">  671</span>&#160;    <span class="keywordtype">void</span> initializeModel();</div>
<div class="line"><a name="l00672"></a><span class="lineno">  672</span>&#160;    <span class="keywordtype">void</span> buildTasksAndSubgraphMap();</div>
<div class="line"><a name="l00673"></a><span class="lineno">  673</span>&#160;    <span class="keywordtype">void</span> buildInputTensorMapping();</div>
<div class="line"><a name="l00674"></a><span class="lineno">  674</span>&#160;    <span class="keywordtype">void</span> buildTaskGraph();</div>
<div class="line"><a name="l00675"></a><span class="lineno">  675</span>&#160;    <span class="keywordtype">void</span> buildTensorRegistry();</div>
<div class="line"><a name="l00676"></a><span class="lineno">  676</span>&#160;    <span class="keywordtype">void</span> calculateTensorOffsets();</div>
<div class="line"><a name="l00677"></a><span class="lineno">  677</span>&#160;    <span class="keywordtype">bool</span> isTensorModelOutput(<span class="keyword">const</span> std::string&amp; tensorName) <span class="keyword">const</span>;</div>
<div class="line"><a name="l00678"></a><span class="lineno">  678</span>&#160;    <span class="keywordtype">bool</span> isTensorModelInput(<span class="keyword">const</span> std::string&amp; tensorName) <span class="keyword">const</span>;</div>
<div class="line"><a name="l00679"></a><span class="lineno">  679</span>&#160; </div>
<div class="line"><a name="l00680"></a><span class="lineno">  680</span>&#160;    <span class="comment">// Debug logging for model data comparison</span></div>
<div class="line"><a name="l00681"></a><span class="lineno">  681</span>&#160;    <span class="keywordtype">void</span> LogModelDataDetails();</div>
<div class="line"><a name="l00682"></a><span class="lineno">  682</span>&#160; </div>
<div class="line"><a name="l00683"></a><span class="lineno">  683</span>&#160;    <span class="comment">// Callback and disposal management</span></div>
<div class="line"><a name="l00684"></a><span class="lineno">  684</span>&#160;    std::function&lt;int(TensorPtrs &amp;outputs, <span class="keywordtype">void</span> *userArg)&gt; _userCallback;</div>
<div class="line"><a name="l00685"></a><span class="lineno">  685</span>&#160; </div>
<div class="line"><a name="l00686"></a><span class="lineno">  686</span>&#160;    <span class="keywordtype">void</span> disposeOnce();</div>
<div class="line"><a name="l00687"></a><span class="lineno">  687</span>&#160;    std::once_flag _disposeOnceFlag;</div>
<div class="line"><a name="l00688"></a><span class="lineno">  688</span>&#160;    <span class="keywordtype">bool</span> _isDisposed = <span class="keyword">false</span>;</div>
<div class="line"><a name="l00689"></a><span class="lineno">  689</span>&#160; </div>
<div class="line"><a name="l00690"></a><span class="lineno">  690</span>&#160;    <span class="comment">// inference job pool for IE</span></div>
<div class="line"><a name="l00691"></a><span class="lineno">  691</span>&#160;    std::shared_ptr&lt;CircularDataPool&lt;InferenceJob&gt;&gt; _inferenceJobPool;</div>
<div class="line"><a name="l00692"></a><span class="lineno">  692</span>&#160; </div>
<div class="line"><a name="l00693"></a><span class="lineno">  693</span>&#160; <span class="keyword">private</span>:</div>
<div class="line"><a name="l00694"></a><span class="lineno">  694</span>&#160;    <span class="keyword">static</span> std::mutex _sInferenceEngineMutex;</div>
<div class="line"><a name="l00695"></a><span class="lineno">  695</span>&#160;};</div>
<div class="line"><a name="l00696"></a><span class="lineno">  696</span>&#160; </div>
<div class="line"><a name="l00697"></a><span class="lineno">  697</span>&#160;} <span class="comment">/* namespace dxrt */</span></div>
</div><!-- fragment --></div><!-- contents -->
<div class="ttc" id="aclassdxrt_1_1InferenceEngine_html_a93e1d7b460b7f8656e725ed708de507b"><div class="ttname"><a href="classdxrt_1_1InferenceEngine.html#a93e1d7b460b7f8656e725ed708de507b">dxrt::InferenceEngine::output_size</a></div><div class="ttdeci">uint64_t output_size()</div><div class="ttdoc">Get total size of output tensors (Legacy API)</div><div class="ttdef"><b>Definition:</b> inference_engine.h:329</div></div>
<div class="ttc" id="aclassdxrt_1_1InferenceEngine_html_a3fb16094508bd367cc4971238f002765"><div class="ttname"><a href="classdxrt_1_1InferenceEngine.html#a3fb16094508bd367cc4971238f002765">dxrt::InferenceEngine::name</a></div><div class="ttdeci">std::string name()</div><div class="ttdoc">Get model name (Legacy API)</div><div class="ttdef"><b>Definition:</b> inference_engine.h:343</div></div>
<div class="ttc" id="aclassdxrt_1_1InferenceEngine_html_a96c4e5953a0daf4a1c886002c052a6ba"><div class="ttname"><a href="classdxrt_1_1InferenceEngine.html#a96c4e5953a0daf4a1c886002c052a6ba">dxrt::InferenceEngine::input_size</a></div><div class="ttdeci">uint64_t input_size()</div><div class="ttdoc">Get total size of input tensors (Legacy API)</div><div class="ttdef"><b>Definition:</b> inference_engine.h:303</div></div>
<div class="ttc" id="aclassdxrt_1_1InferenceEngine_html_a34dfe51c8f5289bd54ff96be8d64bc12"><div class="ttname"><a href="classdxrt_1_1InferenceEngine.html#a34dfe51c8f5289bd54ff96be8d64bc12">dxrt::InferenceEngine::get_outputs</a></div><div class="ttdeci">std::vector&lt; TensorPtrs &gt; get_outputs()</div><div class="ttdoc">Get output tensors of all tasks (Legacy API)</div><div class="ttdef"><b>Definition:</b> inference_engine.h:437</div></div>
<div class="ttc" id="aclassdxrt_1_1InferenceEngine_html_a578a0098f9b49902fa4c81d95945baa4"><div class="ttname"><a href="classdxrt_1_1InferenceEngine.html#a578a0098f9b49902fa4c81d95945baa4">dxrt::InferenceEngine::task_order</a></div><div class="ttdeci">std::vector&lt; std::string &gt; task_order()</div><div class="ttdoc">Get model task order (Legacy API)</div><div class="ttdef"><b>Definition:</b> inference_engine.h:357</div></div>
<div class="ttc" id="aclassdxrt_1_1InferenceEngine_html_a990ca720e7f8a28ac5394206eb6f9491"><div class="ttname"><a href="classdxrt_1_1InferenceEngine.html#a990ca720e7f8a28ac5394206eb6f9491">dxrt::InferenceEngine::latency</a></div><div class="ttdeci">int latency()</div><div class="ttdoc">Get latest latency (Legacy API)</div><div class="ttdef"><b>Definition:</b> inference_engine.h:371</div></div>
<div class="ttc" id="aclassdxrt_1_1InferenceEngine_html_a265ff0d27c6bac98c0c641c0e5f8f6ba"><div class="ttname"><a href="classdxrt_1_1InferenceEngine.html#a265ff0d27c6bac98c0c641c0e5f8f6ba">dxrt::InferenceEngine::get_compile_type</a></div><div class="ttdeci">std::string get_compile_type()</div><div class="ttdoc">Returns the compile type of the model. (Legacy API)</div><div class="ttdef"><b>Definition:</b> inference_engine.h:489</div></div>
<div class="ttc" id="aclassdxrt_1_1InferenceEngine_html_a3d3fc75faa79470d9a3bdbdc61561a3a"><div class="ttname"><a href="classdxrt_1_1InferenceEngine.html#a3d3fc75faa79470d9a3bdbdc61561a3a">dxrt::InferenceEngine::RegisterCallBack</a></div><div class="ttdeci">void RegisterCallBack(std::function&lt; int(TensorPtrs &amp;outputs, void *userArg)&gt; callbackFunc)</div><div class="ttdoc">Register user callback function to be called by inference completion. (Legacy API)</div><div class="ttdef"><b>Definition:</b> inference_engine.h:229</div></div>
<div class="ttc" id="aclassdxrt_1_1InferenceEngine_html_ab0c6629f048341d62bfa3a400c90e827"><div class="ttname"><a href="classdxrt_1_1InferenceEngine.html#ab0c6629f048341d62bfa3a400c90e827">dxrt::InferenceEngine::RunBenchMark</a></div><div class="ttdeci">float RunBenchMark(int num, void *inputPtr=nullptr)</div><div class="ttdoc">run benchmark with loop n times (Legacy API)</div><div class="ttdef"><b>Definition:</b> inference_engine.h:174</div></div>
<div class="ttc" id="aclassdxrt_1_1InferenceEngine_html_af81b48e8ccd95953dd9bc483e5ec678b"><div class="ttname"><a href="classdxrt_1_1InferenceEngine.html#af81b48e8ccd95953dd9bc483e5ec678b">dxrt::InferenceEngine::inputs</a></div><div class="ttdeci">std::vector&lt; Tensors &gt; inputs(int devId)</div><div class="ttdoc">Get input tensor (Legacy API)</div><div class="ttdef"><b>Definition:</b> inference_engine.h:270</div></div>
<div class="ttc" id="aclassdxrt_1_1InferenceEngine_html_aad2f3b616e0e996b66ef7df37dc16a85"><div class="ttname"><a href="classdxrt_1_1InferenceEngine.html#aad2f3b616e0e996b66ef7df37dc16a85">dxrt::InferenceEngine::inference_time</a></div><div class="ttdeci">uint32_t inference_time()</div><div class="ttdoc">Get latest inference time (Legacy API)</div><div class="ttdef"><b>Definition:</b> inference_engine.h:384</div></div>
<div class="ttc" id="aclassdxrt_1_1InferenceEngine_html_a0b38cd5001ec327cbdc5b00a7143d0e2"><div class="ttname"><a href="classdxrt_1_1InferenceEngine.html#a0b38cd5001ec327cbdc5b00a7143d0e2">dxrt::InferenceEngine::get_num_tails</a></div><div class="ttdeci">int get_num_tails()</div><div class="ttdoc">Returns the number of tail tasks in the model. (Legacy API)</div><div class="ttdef"><b>Definition:</b> inference_engine.h:472</div></div>
<div class="ttc" id="aclassdxrt_1_1InferenceEngine_html_afbee8b031fdd6c0a3916ed00d08c9cd8"><div class="ttname"><a href="classdxrt_1_1InferenceEngine.html#afbee8b031fdd6c0a3916ed00d08c9cd8">dxrt::InferenceEngine::inputs</a></div><div class="ttdeci">Tensors inputs(void *ptr=nullptr, uint64_t phyAddr=0)</div><div class="ttdoc">Get input tensor (Legacy API)</div><div class="ttdef"><b>Definition:</b> inference_engine.h:253</div></div>
<div class="ttc" id="aclassdxrt_1_1InferenceEngine_html_a9aeb596b415843e7e318c47938444259"><div class="ttname"><a href="classdxrt_1_1InferenceEngine.html#a9aeb596b415843e7e318c47938444259">dxrt::InferenceEngine::is_PPU</a></div><div class="ttdeci">bool is_PPU()</div><div class="ttdoc">Returns whether the model is using PPU. (Legacy API)</div><div class="ttdef"><b>Definition:</b> inference_engine.h:509</div></div>
<div class="ttc" id="anamespacedxrt_html_aab5060680ba2f567f47f8868cd8b1f00"><div class="ttname"><a href="namespacedxrt.html#aab5060680ba2f567f47f8868cd8b1f00">dxrt::DefaultInferenceOption</a></div><div class="ttdeci">DXRT_API InferenceOption DefaultInferenceOption</div><div class="ttdoc">Default inference option.</div></div>
<div class="ttc" id="aclassdxrt_1_1InferenceEngine_html_aa8ab6719ae0efdf0f5c678e3401ab57d"><div class="ttname"><a href="classdxrt_1_1InferenceEngine.html#aa8ab6719ae0efdf0f5c678e3401ab57d">dxrt::InferenceEngine::bitmatch_mask</a></div><div class="ttdeci">std::vector&lt; uint8_t &gt; bitmatch_mask(int index)</div><div class="ttdef"><b>Definition:</b> inference_engine.h:453</div></div>
<div class="ttc" id="aclassdxrt_1_1InferenceOption_html"><div class="ttname"><a href="classdxrt_1_1InferenceOption.html">dxrt::InferenceOption</a></div><div class="ttdoc">This struct specifies inference options applied to dxrt::InferenceEngine.</div><div class="ttdef"><b>Definition:</b> inference_option.h:21</div></div>
<div class="ttc" id="anamespacedxrt_html"><div class="ttname"><a href="namespacedxrt.html">dxrt</a></div><div class="ttdoc">DXRT C++ APIs are provided in this namespace.</div><div class="ttdef"><b>Definition:</b> buffer.h:8</div></div>
<div class="ttc" id="aclassdxrt_1_1InferenceEngine_html_a0893b724d6eed939556f1315ce05829d"><div class="ttname"><a href="classdxrt_1_1InferenceEngine.html#a0893b724d6eed939556f1315ce05829d">dxrt::InferenceEngine::outputs</a></div><div class="ttdeci">Tensors outputs(void *ptr=nullptr, uint64_t phyAddr=0)</div><div class="ttdoc">Get output tensor (Legacy API)</div><div class="ttdef"><b>Definition:</b> inference_engine.h:287</div></div>
<div class="ttc" id="aclassdxrt_1_1InferenceEngine_html"><div class="ttname"><a href="classdxrt_1_1InferenceEngine.html">dxrt::InferenceEngine</a></div><div class="ttdoc">This class abstracts runtime inference executor for user's compiled model.</div><div class="ttdef"><b>Definition:</b> inference_engine.h:64</div></div>
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.17
</small></address>
</body>
</html>
