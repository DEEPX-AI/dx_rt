
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="08_Global_Instance.html">
      
      
        <link rel="next" href="09_02_Python_Tutorials.html">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>C++ Tutorials - DXNN Runtime (DX-RT) User Manual</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans+Display:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Noto Sans Display";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#c>_tutorials" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="DXNN Runtime (DX-RT) User Manual" class="md-header__button md-logo" aria-label="DXNN Runtime (DX-RT) User Manual" data-md-component="logo">
      
  <img src="../img/deepx.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            DXNN Runtime (DX-RT) User Manual
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              C++ Tutorials
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="01_DXNN_Runtime_Overview.html" class="md-tabs__link">
        
  
  
    
  
  DXNN Runtime Overview

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="02_Installation_on_Linux.html" class="md-tabs__link">
        
  
  
    
  
  Installation on Linux

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="03_Installation_on_Windows.html" class="md-tabs__link">
        
  
  
    
  
  Installation on Windows

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="04_Model_Inference.html" class="md-tabs__link">
        
  
  
    
  
  Model Inference

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="05_Command_Line_Interface.html" class="md-tabs__link">
        
  
  
    
  
  Command Line Interface

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="06_Inference_API.html" class="md-tabs__link">
        
  
  
    
  
  Inference API Guide

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="07_Multi_Input_Inference.html" class="md-tabs__link">
        
  
  
    
  
  Multi-input Inference Guide

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="08_Global_Instance.html" class="md-tabs__link">
        
  
  
    
  
  Configuration and DeviceStatus Guide

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="09_01_C%2B%2B_Tutorials.html" class="md-tabs__link">
          
  
  
  Tutorials

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="10_01_C%2B%2B_API_Reference.html" class="md-tabs__link">
          
  
  
  API Reference

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="Appendix_Change_Log.html" class="md-tabs__link">
        
  
  
    
  
  Change Log

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="DXNN Runtime (DX-RT) User Manual" class="md-nav__button md-logo" aria-label="DXNN Runtime (DX-RT) User Manual" data-md-component="logo">
      
  <img src="../img/deepx.png" alt="logo">

    </a>
    DXNN Runtime (DX-RT) User Manual
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="01_DXNN_Runtime_Overview.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    DXNN Runtime Overview
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="02_Installation_on_Linux.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Installation on Linux
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="03_Installation_on_Windows.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Installation on Windows
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="04_Model_Inference.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Model Inference
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="05_Command_Line_Interface.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Command Line Interface
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="06_Inference_API.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Inference API Guide
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="07_Multi_Input_Inference.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Multi-input Inference Guide
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="08_Global_Instance.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Configuration and DeviceStatus Guide
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_9" checked>
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Tutorials
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    C++ Tutorials
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="09_01_C%2B%2B_Tutorials.html" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    C++ Tutorials
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#c>_tutorials" class="md-nav__link">
    <span class="md-ellipsis">
      C++ Tutorials
    </span>
  </a>
  
    <nav class="md-nav" aria-label="C++ Tutorials">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#run>_synchronous" class="md-nav__link">
    <span class="md-ellipsis">
      Run (Synchronous)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#runasync>_asynchronous" class="md-nav__link">
    <span class="md-ellipsis">
      RunAsync (Asynchronous)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run>_batch" class="md-nav__link">
    <span class="md-ellipsis">
      Run (Batch)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run>_runasync" class="md-nav__link">
    <span class="md-ellipsis">
      Run &amp; RunAsync
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#inference>_option" class="md-nav__link">
    <span class="md-ellipsis">
      Inference Option
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#configuration>_and>_device>_status" class="md-nav__link">
    <span class="md-ellipsis">
      Configuration and Device Status
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#profiler>_configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Profiler Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#camera>_inference>_display" class="md-nav__link">
    <span class="md-ellipsis">
      Camera / Inference / Display
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#exception" class="md-nav__link">
    <span class="md-ellipsis">
      Exception
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#multi-input>_inference" class="md-nav__link">
    <span class="md-ellipsis">
      Multi-Input Inference
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#examples" class="md-nav__link">
    <span class="md-ellipsis">
      Examples
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="09_02_Python_Tutorials.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python Tutorials
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_10" >
        
          
          <label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    API Reference
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="10_01_C%2B%2B_API_Reference.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    C++ API Reference
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="10_02_Python_API_Reference.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python API Reference
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="Appendix_Change_Log.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Change Log
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



  <h1>C++ Tutorials</h1>

<h2 id="c&gt;_tutorials">C++ Tutorials<a class="headerlink" href="#c&gt;_tutorials" title="Permanent link">&para;</a></h2>
<h3 id="run&gt;_synchronous">Run (Synchronous)<a class="headerlink" href="#run&gt;_synchronous" title="Permanent link">&para;</a></h3>
<p>The synchronous Run method uses a single NPU core to perform inference in a blocking manner. It can be configured to utilize multiple NPU cores simultaneously by employing threads to run each core independently.</p>
<div class="center-text">
<p align="center">
<img src="./../resources/06_01_01_Sync_Inference_Operation.png" alt="Synchronous Inference Operation" width="250px">  
<br>
Figure. Synchronous Inference Operation  
<br><br>
</p>
</div>

<p>Inference Engine Run synchronous  </p>
<ul>
<li>Inference synchronously  </li>
<li>Use <strong>only</strong> one npu core  </li>
</ul>
<p>The following is the simplest example of synchronous inference.  </p>
<p><code>run_sync_model.cpp</code>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>// DX-RT includes
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>#include &quot;dxrt/dxrt_api.h&quot;
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>...
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>int main()
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>{
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    std::string modelPath = &quot;model-path&quot;;
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    try 
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    {
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>        // create inference engine instance with model
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>        dxrt::InferenceEngine ie(modelPath);
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>        // create temporary input buffer for example
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>        std::vector&lt;uint8_t&gt; inputPtr(ie.GetInputSize(), 0);
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>        // inference loop
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>        for(int i = 0; i &lt; 100; ++i)
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>        {
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>            // inference synchronously
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>            // use only one npu core
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>            auto outputs = ie.Run(inputPtr.data());
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>            // post processing
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a>            postProcessing(outputs);
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a>        } // for i
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a>    }
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#__codelineno-0-29"></a>    catch(const dxrt::Exception&amp; e)  // exception for inference engine  
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#__codelineno-0-30"></a>    {
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#__codelineno-0-31"></a>        std::cerr &lt;&lt; e.what() &lt;&lt; &quot; error-code=&quot; &lt;&lt; e.code() &lt;&lt; std::endl;
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#__codelineno-0-32"></a>        return -1;
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#__codelineno-0-33"></a>    }
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#__codelineno-0-34"></a>    catch(const std::exception&amp; e)
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#__codelineno-0-35"></a>    {
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#__codelineno-0-36"></a>        std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#__codelineno-0-37"></a>        return -1;
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#__codelineno-0-38"></a>    }
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#__codelineno-0-39"></a>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#__codelineno-0-40"></a>    return 0;
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#__codelineno-0-41"></a>}
</code></pre></div></p>
<hr />
<h3 id="runasync&gt;_asynchronous">RunAsync (Asynchronous)<a class="headerlink" href="#runasync&gt;_asynchronous" title="Permanent link">&para;</a></h3>
<p>The asynchronous Run mode is a method that performs inference asynchronously while utilizing multiple NPU cores simultaneously. It can be implemented to maximize NPU resources through a callback function or a thread wait mechanism.</p>
<div class="center-text">
<p align="center">
<img src="./../resources/06_01_02_Async_Inference_Operation.png" alt="Asynchronous Inference Operation" width="900px">  
<br>
Figure. Asynchronous Inference Operation  
<br><br>
</p>
</div>

<p>Inference Engine RunAsync, Callback, User Argument  </p>
<ul>
<li>the outputs are guaranteed to be valid <strong>only</strong> within this callback function  </li>
<li>processing this callback functions as quickly as possible is beneficial for improving inference performance  </li>
<li>inference asynchronously, use all npu cores  </li>
<li>if <code>device-load &gt;= max-load-value</code>, this function will block  </li>
</ul>
<p>The following is an example of asynchronous inference using a callback function. A user argument can be used to synchronize the input with the output of the callback.  </p>
<p><code>run_async_model.cpp</code>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>// DX-RT includes
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>#include &quot;dxrt/dxrt_api.h&quot;
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>...
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>int main(int argc, char* argv[])
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>{
<a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>    ...
<a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>
<a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>    int callback_count = 0;
<a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>
<a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>    try 
<a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>    {
<a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>
<a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a>        std::mutex cv_mutex;
<a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a>        std::condition_variable cv;
<a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a>
<a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a>        // create inference engine instance with model
<a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a>        dxrt::InferenceEngine ie(model_path);
<a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a>
<a id="__codelineno-1-20" name="__codelineno-1-20" href="#__codelineno-1-20"></a>        // register call back function
<a id="__codelineno-1-21" name="__codelineno-1-21" href="#__codelineno-1-21"></a>        ie.RegisterCallback([&amp;callback_count, &amp;loop_count, &amp;cv_mutex, &amp;cv] 
<a id="__codelineno-1-22" name="__codelineno-1-22" href="#__codelineno-1-22"></a>            (dxrt::TensorPtrs &amp;outputs, void *userArg) {
<a id="__codelineno-1-23" name="__codelineno-1-23" href="#__codelineno-1-23"></a>
<a id="__codelineno-1-24" name="__codelineno-1-24" href="#__codelineno-1-24"></a>            std::ignore = outputs;
<a id="__codelineno-1-25" name="__codelineno-1-25" href="#__codelineno-1-25"></a>            std::ignore = userArg;
<a id="__codelineno-1-26" name="__codelineno-1-26" href="#__codelineno-1-26"></a>
<a id="__codelineno-1-27" name="__codelineno-1-27" href="#__codelineno-1-27"></a>            std::unique_lock&lt;std::mutex&gt; lock(cv_mutex);
<a id="__codelineno-1-28" name="__codelineno-1-28" href="#__codelineno-1-28"></a>            callback_count++;
<a id="__codelineno-1-29" name="__codelineno-1-29" href="#__codelineno-1-29"></a>            if ( callback_count == loop_count ) cv.notify_one();
<a id="__codelineno-1-30" name="__codelineno-1-30" href="#__codelineno-1-30"></a>
<a id="__codelineno-1-31" name="__codelineno-1-31" href="#__codelineno-1-31"></a>            return 0;
<a id="__codelineno-1-32" name="__codelineno-1-32" href="#__codelineno-1-32"></a>        });
<a id="__codelineno-1-33" name="__codelineno-1-33" href="#__codelineno-1-33"></a>
<a id="__codelineno-1-34" name="__codelineno-1-34" href="#__codelineno-1-34"></a>        // create temporary input buffer for example
<a id="__codelineno-1-35" name="__codelineno-1-35" href="#__codelineno-1-35"></a>        std::vector&lt;uint8_t&gt; inputPtr(ie.GetInputSize(), 0);
<a id="__codelineno-1-36" name="__codelineno-1-36" href="#__codelineno-1-36"></a>
<a id="__codelineno-1-37" name="__codelineno-1-37" href="#__codelineno-1-37"></a>        auto start = std::chrono::high_resolution_clock::now();
<a id="__codelineno-1-38" name="__codelineno-1-38" href="#__codelineno-1-38"></a>
<a id="__codelineno-1-39" name="__codelineno-1-39" href="#__codelineno-1-39"></a>        // inference loop
<a id="__codelineno-1-40" name="__codelineno-1-40" href="#__codelineno-1-40"></a>        for(int i = 0; i &lt; loop_count; ++i)
<a id="__codelineno-1-41" name="__codelineno-1-41" href="#__codelineno-1-41"></a>        {
<a id="__codelineno-1-42" name="__codelineno-1-42" href="#__codelineno-1-42"></a>            // user argument
<a id="__codelineno-1-43" name="__codelineno-1-43" href="#__codelineno-1-43"></a>            std::pair&lt;int, int&gt; *userData = new std::pair&lt;int, int&gt;(i, loop_count);
<a id="__codelineno-1-44" name="__codelineno-1-44" href="#__codelineno-1-44"></a>
<a id="__codelineno-1-45" name="__codelineno-1-45" href="#__codelineno-1-45"></a>            // inference asynchronously, use all npu cores
<a id="__codelineno-1-46" name="__codelineno-1-46" href="#__codelineno-1-46"></a>            ie.RunAsync(inputPtr.data(), userData);
<a id="__codelineno-1-47" name="__codelineno-1-47" href="#__codelineno-1-47"></a>
<a id="__codelineno-1-48" name="__codelineno-1-48" href="#__codelineno-1-48"></a>            log.Debug(&quot;Inference request submitted with user_arg(&quot; + std::to_string(i) + &quot;)&quot;);
<a id="__codelineno-1-49" name="__codelineno-1-49" href="#__codelineno-1-49"></a>        }
<a id="__codelineno-1-50" name="__codelineno-1-50" href="#__codelineno-1-50"></a>
<a id="__codelineno-1-51" name="__codelineno-1-51" href="#__codelineno-1-51"></a>        // wait until all callbacks have been processed
<a id="__codelineno-1-52" name="__codelineno-1-52" href="#__codelineno-1-52"></a>        std::unique_lock&lt;std::mutex&gt; lock(cv_mutex);
<a id="__codelineno-1-53" name="__codelineno-1-53" href="#__codelineno-1-53"></a>        cv.wait(lock, [&amp;callback_count, &amp;loop_count] { 
<a id="__codelineno-1-54" name="__codelineno-1-54" href="#__codelineno-1-54"></a>            return callback_count == loop_count;
<a id="__codelineno-1-55" name="__codelineno-1-55" href="#__codelineno-1-55"></a>        });
<a id="__codelineno-1-56" name="__codelineno-1-56" href="#__codelineno-1-56"></a>
<a id="__codelineno-1-57" name="__codelineno-1-57" href="#__codelineno-1-57"></a>        ...
<a id="__codelineno-1-58" name="__codelineno-1-58" href="#__codelineno-1-58"></a>
<a id="__codelineno-1-59" name="__codelineno-1-59" href="#__codelineno-1-59"></a>    }
<a id="__codelineno-1-60" name="__codelineno-1-60" href="#__codelineno-1-60"></a>    catch (const dxrt::Exception&amp; e)
<a id="__codelineno-1-61" name="__codelineno-1-61" href="#__codelineno-1-61"></a>    {
<a id="__codelineno-1-62" name="__codelineno-1-62" href="#__codelineno-1-62"></a>        ...
<a id="__codelineno-1-63" name="__codelineno-1-63" href="#__codelineno-1-63"></a>        return -1;
<a id="__codelineno-1-64" name="__codelineno-1-64" href="#__codelineno-1-64"></a>    }
<a id="__codelineno-1-65" name="__codelineno-1-65" href="#__codelineno-1-65"></a>    catch (const std::exception&amp; e)
<a id="__codelineno-1-66" name="__codelineno-1-66" href="#__codelineno-1-66"></a>    {
<a id="__codelineno-1-67" name="__codelineno-1-67" href="#__codelineno-1-67"></a>        ...
<a id="__codelineno-1-68" name="__codelineno-1-68" href="#__codelineno-1-68"></a>        return -1;
<a id="__codelineno-1-69" name="__codelineno-1-69" href="#__codelineno-1-69"></a>    }
<a id="__codelineno-1-70" name="__codelineno-1-70" href="#__codelineno-1-70"></a>    catch(...)
<a id="__codelineno-1-71" name="__codelineno-1-71" href="#__codelineno-1-71"></a>    {
<a id="__codelineno-1-72" name="__codelineno-1-72" href="#__codelineno-1-72"></a>        ...
<a id="__codelineno-1-73" name="__codelineno-1-73" href="#__codelineno-1-73"></a>        return -1;
<a id="__codelineno-1-74" name="__codelineno-1-74" href="#__codelineno-1-74"></a>    }
<a id="__codelineno-1-75" name="__codelineno-1-75" href="#__codelineno-1-75"></a>
<a id="__codelineno-1-76" name="__codelineno-1-76" href="#__codelineno-1-76"></a>    return (callback_count == loop_count ? 0 : -1);
<a id="__codelineno-1-77" name="__codelineno-1-77" href="#__codelineno-1-77"></a>}
</code></pre></div></p>
<p>The following is an example where multiple threads start input and inference, and a single callback processes the output.  </p>
<p>Inference Engine RunAsync, Callback, User Argument, Thread  </p>
<ul>
<li>the outputs are guaranteed to be valid <strong>only</strong> within this callback function  </li>
<li>processing this callback functions as quickly as possible is beneficial for improving inference performance  </li>
<li>inference asynchronously, use all npu cores  </li>
<li>if <code>device-load &gt;= max-load-value</code>, this function will block  </li>
</ul>
<p><code>run_async_model_thread.cpp</code>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>// DX-RT includes
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>#include &quot;dxrt/dxrt_api.h&quot;
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>...
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>static const int THREAD_COUNT = 3;
<a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>static std::atomic&lt;int&gt; gResultCount = {0};
<a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>static std::atomic&lt;int&gt; gTotalCount = {0};
<a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a>static ConcurrentQueue&lt;int&gt; gResultQueue(1);
<a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a>static std::mutex gCBMutex;
<a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a>
<a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a>static int inferenceThreadFunc(dxrt::InferenceEngine&amp; ie, std::vector&lt;uint8_t&gt;&amp; inputPtr, int threadIndex, int loopCount)
<a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a>{
<a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a>
<a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a>    // inference loop
<a id="__codelineno-2-15" name="__codelineno-2-15" href="#__codelineno-2-15"></a>    for(int i = 0; i &lt; loopCount; ++i) 
<a id="__codelineno-2-16" name="__codelineno-2-16" href="#__codelineno-2-16"></a>    {
<a id="__codelineno-2-17" name="__codelineno-2-17" href="#__codelineno-2-17"></a>        // user argument
<a id="__codelineno-2-18" name="__codelineno-2-18" href="#__codelineno-2-18"></a>        UserData *userData = new UserData();
<a id="__codelineno-2-19" name="__codelineno-2-19" href="#__codelineno-2-19"></a>
<a id="__codelineno-2-20" name="__codelineno-2-20" href="#__codelineno-2-20"></a>        // thread index 
<a id="__codelineno-2-21" name="__codelineno-2-21" href="#__codelineno-2-21"></a>        userData-&gt;setThreadIndex(threadIndex);
<a id="__codelineno-2-22" name="__codelineno-2-22" href="#__codelineno-2-22"></a>
<a id="__codelineno-2-23" name="__codelineno-2-23" href="#__codelineno-2-23"></a>        // total loop count
<a id="__codelineno-2-24" name="__codelineno-2-24" href="#__codelineno-2-24"></a>        userData-&gt;setLoopCount(loopCount);
<a id="__codelineno-2-25" name="__codelineno-2-25" href="#__codelineno-2-25"></a>
<a id="__codelineno-2-26" name="__codelineno-2-26" href="#__codelineno-2-26"></a>        // loop index
<a id="__codelineno-2-27" name="__codelineno-2-27" href="#__codelineno-2-27"></a>        userData-&gt;setLoopIndex(i);
<a id="__codelineno-2-28" name="__codelineno-2-28" href="#__codelineno-2-28"></a>
<a id="__codelineno-2-29" name="__codelineno-2-29" href="#__codelineno-2-29"></a>        try
<a id="__codelineno-2-30" name="__codelineno-2-30" href="#__codelineno-2-30"></a>        {
<a id="__codelineno-2-31" name="__codelineno-2-31" href="#__codelineno-2-31"></a>            // inference asynchronously, use all npu cores
<a id="__codelineno-2-32" name="__codelineno-2-32" href="#__codelineno-2-32"></a>            // if device-load &gt;= max-load-value, this function will block  
<a id="__codelineno-2-33" name="__codelineno-2-33" href="#__codelineno-2-33"></a>            ie.RunAsync(inputPtr.data(), userData);
<a id="__codelineno-2-34" name="__codelineno-2-34" href="#__codelineno-2-34"></a>        }
<a id="__codelineno-2-35" name="__codelineno-2-35" href="#__codelineno-2-35"></a>        catch(const dxrt::Exception&amp; e)
<a id="__codelineno-2-36" name="__codelineno-2-36" href="#__codelineno-2-36"></a>        {
<a id="__codelineno-2-37" name="__codelineno-2-37" href="#__codelineno-2-37"></a>            std::cerr &lt;&lt; e.what() &lt;&lt; &quot; error-code=&quot; &lt;&lt; e.code() &lt;&lt; std::endl;
<a id="__codelineno-2-38" name="__codelineno-2-38" href="#__codelineno-2-38"></a>            std::exit(-1);
<a id="__codelineno-2-39" name="__codelineno-2-39" href="#__codelineno-2-39"></a>        }
<a id="__codelineno-2-40" name="__codelineno-2-40" href="#__codelineno-2-40"></a>        catch(const std::exception&amp; e)
<a id="__codelineno-2-41" name="__codelineno-2-41" href="#__codelineno-2-41"></a>        {
<a id="__codelineno-2-42" name="__codelineno-2-42" href="#__codelineno-2-42"></a>            std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;
<a id="__codelineno-2-43" name="__codelineno-2-43" href="#__codelineno-2-43"></a>            std::exit(-1);
<a id="__codelineno-2-44" name="__codelineno-2-44" href="#__codelineno-2-44"></a>        }
<a id="__codelineno-2-45" name="__codelineno-2-45" href="#__codelineno-2-45"></a>
<a id="__codelineno-2-46" name="__codelineno-2-46" href="#__codelineno-2-46"></a>    } // for i
<a id="__codelineno-2-47" name="__codelineno-2-47" href="#__codelineno-2-47"></a>
<a id="__codelineno-2-48" name="__codelineno-2-48" href="#__codelineno-2-48"></a>    return 0;
<a id="__codelineno-2-49" name="__codelineno-2-49" href="#__codelineno-2-49"></a>
<a id="__codelineno-2-50" name="__codelineno-2-50" href="#__codelineno-2-50"></a>}
<a id="__codelineno-2-51" name="__codelineno-2-51" href="#__codelineno-2-51"></a>
<a id="__codelineno-2-52" name="__codelineno-2-52" href="#__codelineno-2-52"></a>// invoke this function asynchronously after the inference is completed
<a id="__codelineno-2-53" name="__codelineno-2-53" href="#__codelineno-2-53"></a>static int onInferenceCallbackFunc(dxrt::TensorPtrs &amp;outputs, void *userArg)
<a id="__codelineno-2-54" name="__codelineno-2-54" href="#__codelineno-2-54"></a>{
<a id="__codelineno-2-55" name="__codelineno-2-55" href="#__codelineno-2-55"></a>
<a id="__codelineno-2-56" name="__codelineno-2-56" href="#__codelineno-2-56"></a>    // the outputs are guaranteed to be valid only within this callback function
<a id="__codelineno-2-57" name="__codelineno-2-57" href="#__codelineno-2-57"></a>    // processing this callback functions as quickly as possible is beneficial 
<a id="__codelineno-2-58" name="__codelineno-2-58" href="#__codelineno-2-58"></a>    // for improving inference performance
<a id="__codelineno-2-59" name="__codelineno-2-59" href="#__codelineno-2-59"></a>
<a id="__codelineno-2-60" name="__codelineno-2-60" href="#__codelineno-2-60"></a>    // user data type casting
<a id="__codelineno-2-61" name="__codelineno-2-61" href="#__codelineno-2-61"></a>    UserData *user_data = reinterpret_cast&lt;UserData*&gt;(userArg);
<a id="__codelineno-2-62" name="__codelineno-2-62" href="#__codelineno-2-62"></a>
<a id="__codelineno-2-63" name="__codelineno-2-63" href="#__codelineno-2-63"></a>    // thread index
<a id="__codelineno-2-64" name="__codelineno-2-64" href="#__codelineno-2-64"></a>    int thread_index = user_data-&gt;getThreadIndex();
<a id="__codelineno-2-65" name="__codelineno-2-65" href="#__codelineno-2-65"></a>
<a id="__codelineno-2-66" name="__codelineno-2-66" href="#__codelineno-2-66"></a>    // loop index
<a id="__codelineno-2-67" name="__codelineno-2-67" href="#__codelineno-2-67"></a>    int loop_index = user_data-&gt;getLoopIndex();
<a id="__codelineno-2-68" name="__codelineno-2-68" href="#__codelineno-2-68"></a>
<a id="__codelineno-2-69" name="__codelineno-2-69" href="#__codelineno-2-69"></a>    // post processing
<a id="__codelineno-2-70" name="__codelineno-2-70" href="#__codelineno-2-70"></a>    // transfer outputs to the target thread by thread_index
<a id="__codelineno-2-71" name="__codelineno-2-71" href="#__codelineno-2-71"></a>    // postProcessing(outputs, thread_index);
<a id="__codelineno-2-72" name="__codelineno-2-72" href="#__codelineno-2-72"></a>    (void)outputs;
<a id="__codelineno-2-73" name="__codelineno-2-73" href="#__codelineno-2-73"></a>
<a id="__codelineno-2-74" name="__codelineno-2-74" href="#__codelineno-2-74"></a>
<a id="__codelineno-2-75" name="__codelineno-2-75" href="#__codelineno-2-75"></a>    // result count 
<a id="__codelineno-2-76" name="__codelineno-2-76" href="#__codelineno-2-76"></a>    {
<a id="__codelineno-2-77" name="__codelineno-2-77" href="#__codelineno-2-77"></a>        // Mutex locks should be properly adjusted 
<a id="__codelineno-2-78" name="__codelineno-2-78" href="#__codelineno-2-78"></a>        // to ensure that callback functions are thread-safe.
<a id="__codelineno-2-79" name="__codelineno-2-79" href="#__codelineno-2-79"></a>        std::lock_guard&lt;std::mutex&gt; lock(gCBMutex);
<a id="__codelineno-2-80" name="__codelineno-2-80" href="#__codelineno-2-80"></a>
<a id="__codelineno-2-81" name="__codelineno-2-81" href="#__codelineno-2-81"></a>        gResultCount++;
<a id="__codelineno-2-82" name="__codelineno-2-82" href="#__codelineno-2-82"></a>        if ( gResultCount.load() == gTotalCount.load() ) gResultQueue.push(0);
<a id="__codelineno-2-83" name="__codelineno-2-83" href="#__codelineno-2-83"></a>    }
<a id="__codelineno-2-84" name="__codelineno-2-84" href="#__codelineno-2-84"></a>
<a id="__codelineno-2-85" name="__codelineno-2-85" href="#__codelineno-2-85"></a>    // delete argument object 
<a id="__codelineno-2-86" name="__codelineno-2-86" href="#__codelineno-2-86"></a>    delete user_data;
<a id="__codelineno-2-87" name="__codelineno-2-87" href="#__codelineno-2-87"></a>
<a id="__codelineno-2-88" name="__codelineno-2-88" href="#__codelineno-2-88"></a>    return 0;
<a id="__codelineno-2-89" name="__codelineno-2-89" href="#__codelineno-2-89"></a>}
<a id="__codelineno-2-90" name="__codelineno-2-90" href="#__codelineno-2-90"></a>
<a id="__codelineno-2-91" name="__codelineno-2-91" href="#__codelineno-2-91"></a>
<a id="__codelineno-2-92" name="__codelineno-2-92" href="#__codelineno-2-92"></a>int main(int argc, char* argv[])
<a id="__codelineno-2-93" name="__codelineno-2-93" href="#__codelineno-2-93"></a>{
<a id="__codelineno-2-94" name="__codelineno-2-94" href="#__codelineno-2-94"></a>    ...
<a id="__codelineno-2-95" name="__codelineno-2-95" href="#__codelineno-2-95"></a>
<a id="__codelineno-2-96" name="__codelineno-2-96" href="#__codelineno-2-96"></a>    bool result = false;
<a id="__codelineno-2-97" name="__codelineno-2-97" href="#__codelineno-2-97"></a>
<a id="__codelineno-2-98" name="__codelineno-2-98" href="#__codelineno-2-98"></a>    try
<a id="__codelineno-2-99" name="__codelineno-2-99" href="#__codelineno-2-99"></a>    {
<a id="__codelineno-2-100" name="__codelineno-2-100" href="#__codelineno-2-100"></a>        // create inference engine instance with model
<a id="__codelineno-2-101" name="__codelineno-2-101" href="#__codelineno-2-101"></a>        dxrt::InferenceEngine ie(modelPath);
<a id="__codelineno-2-102" name="__codelineno-2-102" href="#__codelineno-2-102"></a>
<a id="__codelineno-2-103" name="__codelineno-2-103" href="#__codelineno-2-103"></a>        // register call back function
<a id="__codelineno-2-104" name="__codelineno-2-104" href="#__codelineno-2-104"></a>        ie.RegisterCallback(onInferenceCallbackFunc);    
<a id="__codelineno-2-105" name="__codelineno-2-105" href="#__codelineno-2-105"></a>
<a id="__codelineno-2-106" name="__codelineno-2-106" href="#__codelineno-2-106"></a>        // create temporary input buffer for example
<a id="__codelineno-2-107" name="__codelineno-2-107" href="#__codelineno-2-107"></a>        std::vector&lt;uint8_t&gt; inputPtr(ie.GetInputSize(), 0);
<a id="__codelineno-2-108" name="__codelineno-2-108" href="#__codelineno-2-108"></a>
<a id="__codelineno-2-109" name="__codelineno-2-109" href="#__codelineno-2-109"></a>        gTotalCount.store(loop_count * THREAD_COUNT);
<a id="__codelineno-2-110" name="__codelineno-2-110" href="#__codelineno-2-110"></a>
<a id="__codelineno-2-111" name="__codelineno-2-111" href="#__codelineno-2-111"></a>        // thread vector 
<a id="__codelineno-2-112" name="__codelineno-2-112" href="#__codelineno-2-112"></a>        std::vector&lt;std::thread&gt; thread_array;
<a id="__codelineno-2-113" name="__codelineno-2-113" href="#__codelineno-2-113"></a>
<a id="__codelineno-2-114" name="__codelineno-2-114" href="#__codelineno-2-114"></a>        for(int i = 0; i &lt; THREAD_COUNT; ++i)
<a id="__codelineno-2-115" name="__codelineno-2-115" href="#__codelineno-2-115"></a>        {
<a id="__codelineno-2-116" name="__codelineno-2-116" href="#__codelineno-2-116"></a>            // create thread
<a id="__codelineno-2-117" name="__codelineno-2-117" href="#__codelineno-2-117"></a>            thread_array.push_back(std::thread(inferenceThreadFunc, std::ref(ie), std::ref(inputPtr), i, loop_count));
<a id="__codelineno-2-118" name="__codelineno-2-118" href="#__codelineno-2-118"></a>        }
<a id="__codelineno-2-119" name="__codelineno-2-119" href="#__codelineno-2-119"></a>
<a id="__codelineno-2-120" name="__codelineno-2-120" href="#__codelineno-2-120"></a>        for(auto &amp;t : thread_array)
<a id="__codelineno-2-121" name="__codelineno-2-121" href="#__codelineno-2-121"></a>        {
<a id="__codelineno-2-122" name="__codelineno-2-122" href="#__codelineno-2-122"></a>            t.join();
<a id="__codelineno-2-123" name="__codelineno-2-123" href="#__codelineno-2-123"></a>        } // for t
<a id="__codelineno-2-124" name="__codelineno-2-124" href="#__codelineno-2-124"></a>
<a id="__codelineno-2-125" name="__codelineno-2-125" href="#__codelineno-2-125"></a>
<a id="__codelineno-2-126" name="__codelineno-2-126" href="#__codelineno-2-126"></a>        // wait until all callbacks have been processed
<a id="__codelineno-2-127" name="__codelineno-2-127" href="#__codelineno-2-127"></a>        gResultQueue.pop();
<a id="__codelineno-2-128" name="__codelineno-2-128" href="#__codelineno-2-128"></a>
<a id="__codelineno-2-129" name="__codelineno-2-129" href="#__codelineno-2-129"></a>    }
<a id="__codelineno-2-130" name="__codelineno-2-130" href="#__codelineno-2-130"></a>    catch (const dxrt::Exception&amp; e)
<a id="__codelineno-2-131" name="__codelineno-2-131" href="#__codelineno-2-131"></a>    {
<a id="__codelineno-2-132" name="__codelineno-2-132" href="#__codelineno-2-132"></a>        std::cerr &lt;&lt; e.what() &lt;&lt; &quot; error-code=&quot; &lt;&lt; e.code() &lt;&lt; std::endl;
<a id="__codelineno-2-133" name="__codelineno-2-133" href="#__codelineno-2-133"></a>        return -1;
<a id="__codelineno-2-134" name="__codelineno-2-134" href="#__codelineno-2-134"></a>    }
<a id="__codelineno-2-135" name="__codelineno-2-135" href="#__codelineno-2-135"></a>    catch (const std::exception&amp; e)
<a id="__codelineno-2-136" name="__codelineno-2-136" href="#__codelineno-2-136"></a>    {
<a id="__codelineno-2-137" name="__codelineno-2-137" href="#__codelineno-2-137"></a>        std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;
<a id="__codelineno-2-138" name="__codelineno-2-138" href="#__codelineno-2-138"></a>        return -1;
<a id="__codelineno-2-139" name="__codelineno-2-139" href="#__codelineno-2-139"></a>    }
<a id="__codelineno-2-140" name="__codelineno-2-140" href="#__codelineno-2-140"></a>    catch(...)
<a id="__codelineno-2-141" name="__codelineno-2-141" href="#__codelineno-2-141"></a>    {
<a id="__codelineno-2-142" name="__codelineno-2-142" href="#__codelineno-2-142"></a>        std::cerr &lt;&lt; &quot;Exception&quot; &lt;&lt; std::endl;
<a id="__codelineno-2-143" name="__codelineno-2-143" href="#__codelineno-2-143"></a>        return -1;
<a id="__codelineno-2-144" name="__codelineno-2-144" href="#__codelineno-2-144"></a>    }
<a id="__codelineno-2-145" name="__codelineno-2-145" href="#__codelineno-2-145"></a>
<a id="__codelineno-2-146" name="__codelineno-2-146" href="#__codelineno-2-146"></a>    return result ? 0 : -1;
<a id="__codelineno-2-147" name="__codelineno-2-147" href="#__codelineno-2-147"></a>}
</code></pre></div></p>
<p>The following is an example of performing asynchronous inference by creating an inference wait thread. The main thread starts input and inference, and the inference wait thread retrieves the output data corresponding to the input.  </p>
<p>Inference Engine RunAsync, Wait  </p>
<ul>
<li>inference asynchronously, use all npu cores  </li>
<li>if <code>device-load &gt;= max-load-value</code>, this function will block  </li>
</ul>
<p><code>run_async_model_wait.cpp</code>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>// DX-RT includes
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>#include &quot;dxrt/dxrt_api.h&quot;
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>...
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>
<a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>// concurrent queue is a thread-safe queue data structure 
<a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>// designed to be used in a multi-threaded environment
<a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>static ConcurrentQueue&lt;int&gt; gJobIdQueue;
<a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>
<a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>// user thread to wait for the completion of inference 
<a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>static int inferenceThreadFunc(dxrt::InferenceEngine&amp; ie, int loopCount)
<a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>{
<a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a>    int count = 0;
<a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>
<a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a>    while(...)
<a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a>    {
<a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a>        // pop item from queue 
<a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a>        int jobId = gJobIdQueue.pop();
<a id="__codelineno-3-18" name="__codelineno-3-18" href="#__codelineno-3-18"></a>
<a id="__codelineno-3-19" name="__codelineno-3-19" href="#__codelineno-3-19"></a>        try 
<a id="__codelineno-3-20" name="__codelineno-3-20" href="#__codelineno-3-20"></a>        {
<a id="__codelineno-3-21" name="__codelineno-3-21" href="#__codelineno-3-21"></a>            // waiting for the inference to complete by jobId 
<a id="__codelineno-3-22" name="__codelineno-3-22" href="#__codelineno-3-22"></a>            auto outputs = ie.Wait(jobId);
<a id="__codelineno-3-23" name="__codelineno-3-23" href="#__codelineno-3-23"></a>
<a id="__codelineno-3-24" name="__codelineno-3-24" href="#__codelineno-3-24"></a>            // post processing 
<a id="__codelineno-3-25" name="__codelineno-3-25" href="#__codelineno-3-25"></a>            postProcessing(outputs);
<a id="__codelineno-3-26" name="__codelineno-3-26" href="#__codelineno-3-26"></a>
<a id="__codelineno-3-27" name="__codelineno-3-27" href="#__codelineno-3-27"></a>        }
<a id="__codelineno-3-28" name="__codelineno-3-28" href="#__codelineno-3-28"></a>        catch(const dxrt::Exception&amp; e)  // exception for inference engine 
<a id="__codelineno-3-29" name="__codelineno-3-29" href="#__codelineno-3-29"></a>        {
<a id="__codelineno-3-30" name="__codelineno-3-30" href="#__codelineno-3-30"></a>            std::cerr &lt;&lt; e.what() &lt;&lt; &quot; error-code=&quot; &lt;&lt; e.code() &lt;&lt; std::endl;
<a id="__codelineno-3-31" name="__codelineno-3-31" href="#__codelineno-3-31"></a>            std::exit(-1);
<a id="__codelineno-3-32" name="__codelineno-3-32" href="#__codelineno-3-32"></a>        }
<a id="__codelineno-3-33" name="__codelineno-3-33" href="#__codelineno-3-33"></a>        catch(const std::exception&amp; e)
<a id="__codelineno-3-34" name="__codelineno-3-34" href="#__codelineno-3-34"></a>        {
<a id="__codelineno-3-35" name="__codelineno-3-35" href="#__codelineno-3-35"></a>            std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;
<a id="__codelineno-3-36" name="__codelineno-3-36" href="#__codelineno-3-36"></a>            std::exit(-1);
<a id="__codelineno-3-37" name="__codelineno-3-37" href="#__codelineno-3-37"></a>        }
<a id="__codelineno-3-38" name="__codelineno-3-38" href="#__codelineno-3-38"></a>
<a id="__codelineno-3-39" name="__codelineno-3-39" href="#__codelineno-3-39"></a>        // something to do
<a id="__codelineno-3-40" name="__codelineno-3-40" href="#__codelineno-3-40"></a>
<a id="__codelineno-3-41" name="__codelineno-3-41" href="#__codelineno-3-41"></a>        count++;
<a id="__codelineno-3-42" name="__codelineno-3-42" href="#__codelineno-3-42"></a>        if ( count &gt;= loopCount ) break;
<a id="__codelineno-3-43" name="__codelineno-3-43" href="#__codelineno-3-43"></a>
<a id="__codelineno-3-44" name="__codelineno-3-44" href="#__codelineno-3-44"></a>    } // while
<a id="__codelineno-3-45" name="__codelineno-3-45" href="#__codelineno-3-45"></a>
<a id="__codelineno-3-46" name="__codelineno-3-46" href="#__codelineno-3-46"></a>    return 0;
<a id="__codelineno-3-47" name="__codelineno-3-47" href="#__codelineno-3-47"></a>}
<a id="__codelineno-3-48" name="__codelineno-3-48" href="#__codelineno-3-48"></a>
<a id="__codelineno-3-49" name="__codelineno-3-49" href="#__codelineno-3-49"></a>int main()
<a id="__codelineno-3-50" name="__codelineno-3-50" href="#__codelineno-3-50"></a>{
<a id="__codelineno-3-51" name="__codelineno-3-51" href="#__codelineno-3-51"></a>    const int LOOP_COUNT = 100;
<a id="__codelineno-3-52" name="__codelineno-3-52" href="#__codelineno-3-52"></a>    std::string modelPath = &quot;model-path&quot;;
<a id="__codelineno-3-53" name="__codelineno-3-53" href="#__codelineno-3-53"></a>
<a id="__codelineno-3-54" name="__codelineno-3-54" href="#__codelineno-3-54"></a>    try
<a id="__codelineno-3-55" name="__codelineno-3-55" href="#__codelineno-3-55"></a>    {
<a id="__codelineno-3-56" name="__codelineno-3-56" href="#__codelineno-3-56"></a>        // create inference engine instance with model
<a id="__codelineno-3-57" name="__codelineno-3-57" href="#__codelineno-3-57"></a>        dxrt::InferenceEngine ie(modelPath);
<a id="__codelineno-3-58" name="__codelineno-3-58" href="#__codelineno-3-58"></a>
<a id="__codelineno-3-59" name="__codelineno-3-59" href="#__codelineno-3-59"></a>        // do not register call back function
<a id="__codelineno-3-60" name="__codelineno-3-60" href="#__codelineno-3-60"></a>        // inferenceEngine.RegisterCallback(onInferenceCallbackFunc);
<a id="__codelineno-3-61" name="__codelineno-3-61" href="#__codelineno-3-61"></a>
<a id="__codelineno-3-62" name="__codelineno-3-62" href="#__codelineno-3-62"></a>        // create temporary input buffer for example
<a id="__codelineno-3-63" name="__codelineno-3-63" href="#__codelineno-3-63"></a>        std::vector&lt;uint8_t&gt; inputPtr(ie.GetInputSize(), 0);
<a id="__codelineno-3-64" name="__codelineno-3-64" href="#__codelineno-3-64"></a>
<a id="__codelineno-3-65" name="__codelineno-3-65" href="#__codelineno-3-65"></a>        // create thread
<a id="__codelineno-3-66" name="__codelineno-3-66" href="#__codelineno-3-66"></a>        auto t1 = std::thread(inferenceThreadFunc, std::ref(ie), LOOP_COUNT);
<a id="__codelineno-3-67" name="__codelineno-3-67" href="#__codelineno-3-67"></a>
<a id="__codelineno-3-68" name="__codelineno-3-68" href="#__codelineno-3-68"></a>        // inference loop
<a id="__codelineno-3-69" name="__codelineno-3-69" href="#__codelineno-3-69"></a>        for(int i = 0; i &lt; LOOP_COUNT; ++i)
<a id="__codelineno-3-70" name="__codelineno-3-70" href="#__codelineno-3-70"></a>        {
<a id="__codelineno-3-71" name="__codelineno-3-71" href="#__codelineno-3-71"></a>
<a id="__codelineno-3-72" name="__codelineno-3-72" href="#__codelineno-3-72"></a>            // no need user argument
<a id="__codelineno-3-73" name="__codelineno-3-73" href="#__codelineno-3-73"></a>            // UserData *userData = getUserDataInstanceFromDataPool();
<a id="__codelineno-3-74" name="__codelineno-3-74" href="#__codelineno-3-74"></a>
<a id="__codelineno-3-75" name="__codelineno-3-75" href="#__codelineno-3-75"></a>            // inference asynchronously, use all npu cores
<a id="__codelineno-3-76" name="__codelineno-3-76" href="#__codelineno-3-76"></a>            // if device-load &gt;= max-load-value, this function will block
<a id="__codelineno-3-77" name="__codelineno-3-77" href="#__codelineno-3-77"></a>            auto jobId = ie.RunAsync(inputPtr.data());
<a id="__codelineno-3-78" name="__codelineno-3-78" href="#__codelineno-3-78"></a>
<a id="__codelineno-3-79" name="__codelineno-3-79" href="#__codelineno-3-79"></a>            // push jobId in global queue variable
<a id="__codelineno-3-80" name="__codelineno-3-80" href="#__codelineno-3-80"></a>            gJobIdQueue.push(jobId);
<a id="__codelineno-3-81" name="__codelineno-3-81" href="#__codelineno-3-81"></a>
<a id="__codelineno-3-82" name="__codelineno-3-82" href="#__codelineno-3-82"></a>        } // for i
<a id="__codelineno-3-83" name="__codelineno-3-83" href="#__codelineno-3-83"></a>
<a id="__codelineno-3-84" name="__codelineno-3-84" href="#__codelineno-3-84"></a>        t1.join();
<a id="__codelineno-3-85" name="__codelineno-3-85" href="#__codelineno-3-85"></a>    }
<a id="__codelineno-3-86" name="__codelineno-3-86" href="#__codelineno-3-86"></a>    catch(const dxrt::Exception&amp; e)  // exception for inference engine 
<a id="__codelineno-3-87" name="__codelineno-3-87" href="#__codelineno-3-87"></a>    {
<a id="__codelineno-3-88" name="__codelineno-3-88" href="#__codelineno-3-88"></a>        std::cerr &lt;&lt; e.what() &lt;&lt; &quot; error-code=&quot; &lt;&lt; e.code() &lt;&lt; std::endl;
<a id="__codelineno-3-89" name="__codelineno-3-89" href="#__codelineno-3-89"></a>        return -1;
<a id="__codelineno-3-90" name="__codelineno-3-90" href="#__codelineno-3-90"></a>    }
<a id="__codelineno-3-91" name="__codelineno-3-91" href="#__codelineno-3-91"></a>    catch(std::exception&amp; e)
<a id="__codelineno-3-92" name="__codelineno-3-92" href="#__codelineno-3-92"></a>    {
<a id="__codelineno-3-93" name="__codelineno-3-93" href="#__codelineno-3-93"></a>        std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;
<a id="__codelineno-3-94" name="__codelineno-3-94" href="#__codelineno-3-94"></a>        return -1;
<a id="__codelineno-3-95" name="__codelineno-3-95" href="#__codelineno-3-95"></a>    }
<a id="__codelineno-3-96" name="__codelineno-3-96" href="#__codelineno-3-96"></a>
<a id="__codelineno-3-97" name="__codelineno-3-97" href="#__codelineno-3-97"></a>    return 0;
<a id="__codelineno-3-98" name="__codelineno-3-98" href="#__codelineno-3-98"></a>}
</code></pre></div></p>
<hr />
<h3 id="run&gt;_batch">Run (Batch)<a class="headerlink" href="#run&gt;_batch" title="Permanent link">&para;</a></h3>
<p>The following is an example of batch inference with multiple inputs and multiple outputs.</p>
<p><code>run_batch_model.cpp</code></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>int main(int argc, char* argv[])
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>{
<a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>    ...
<a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a>
<a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>    try
<a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>    {
<a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a>
<a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>        // create inference engine instance with model
<a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>        dxrt::InferenceEngine ie(modelPath);
<a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a>
<a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>        // create temporary input buffer for example
<a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a>        std::vector&lt;uint8_t&gt; inputBuffer(ie.GetInputSize(), 0);
<a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a>
<a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a>        // input buffer vector
<a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a>        std::vector&lt;void*&gt; inputBuffers;
<a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a>        for(int i = 0; i &lt; batch_count; ++i)
<a id="__codelineno-4-17" name="__codelineno-4-17" href="#__codelineno-4-17"></a>        {
<a id="__codelineno-4-18" name="__codelineno-4-18" href="#__codelineno-4-18"></a>            // assigns the same buffer pointer in this example
<a id="__codelineno-4-19" name="__codelineno-4-19" href="#__codelineno-4-19"></a>            inputBuffers.emplace_back(inputBuffer.data());
<a id="__codelineno-4-20" name="__codelineno-4-20" href="#__codelineno-4-20"></a>        }
<a id="__codelineno-4-21" name="__codelineno-4-21" href="#__codelineno-4-21"></a>
<a id="__codelineno-4-22" name="__codelineno-4-22" href="#__codelineno-4-22"></a>        // output buffer vector
<a id="__codelineno-4-23" name="__codelineno-4-23" href="#__codelineno-4-23"></a>        std::vector&lt;void*&gt; output_buffers(batch_count, 0);
<a id="__codelineno-4-24" name="__codelineno-4-24" href="#__codelineno-4-24"></a>
<a id="__codelineno-4-25" name="__codelineno-4-25" href="#__codelineno-4-25"></a>        // create user output buffers
<a id="__codelineno-4-26" name="__codelineno-4-26" href="#__codelineno-4-26"></a>        for(auto&amp; ptr : output_buffers)
<a id="__codelineno-4-27" name="__codelineno-4-27" href="#__codelineno-4-27"></a>        {
<a id="__codelineno-4-28" name="__codelineno-4-28" href="#__codelineno-4-28"></a>            ptr = new uint8_t[ie.GetOutputSize()];
<a id="__codelineno-4-29" name="__codelineno-4-29" href="#__codelineno-4-29"></a>        } // for i
<a id="__codelineno-4-30" name="__codelineno-4-30" href="#__codelineno-4-30"></a>
<a id="__codelineno-4-31" name="__codelineno-4-31" href="#__codelineno-4-31"></a>        // batch inference loop
<a id="__codelineno-4-32" name="__codelineno-4-32" href="#__codelineno-4-32"></a>        for(int i = 0; i &lt; loop_count; ++i)
<a id="__codelineno-4-33" name="__codelineno-4-33" href="#__codelineno-4-33"></a>        {
<a id="__codelineno-4-34" name="__codelineno-4-34" href="#__codelineno-4-34"></a>            // inference asynchronously, use all npu core
<a id="__codelineno-4-35" name="__codelineno-4-35" href="#__codelineno-4-35"></a>            auto outputPtrs = ie.Run(inputBuffers, output_buffers);
<a id="__codelineno-4-36" name="__codelineno-4-36" href="#__codelineno-4-36"></a>
<a id="__codelineno-4-37" name="__codelineno-4-37" href="#__codelineno-4-37"></a>            // postProcessing(outputs);
<a id="__codelineno-4-38" name="__codelineno-4-38" href="#__codelineno-4-38"></a>            (void)outputPtrs;
<a id="__codelineno-4-39" name="__codelineno-4-39" href="#__codelineno-4-39"></a>        }
<a id="__codelineno-4-40" name="__codelineno-4-40" href="#__codelineno-4-40"></a>
<a id="__codelineno-4-41" name="__codelineno-4-41" href="#__codelineno-4-41"></a>        // Deallocated the user&#39;s output buffers
<a id="__codelineno-4-42" name="__codelineno-4-42" href="#__codelineno-4-42"></a>        for(auto&amp; ptr : output_buffers)
<a id="__codelineno-4-43" name="__codelineno-4-43" href="#__codelineno-4-43"></a>        {
<a id="__codelineno-4-44" name="__codelineno-4-44" href="#__codelineno-4-44"></a>            delete[] static_cast&lt;uint8_t*&gt;(ptr);
<a id="__codelineno-4-45" name="__codelineno-4-45" href="#__codelineno-4-45"></a>        } // for i
<a id="__codelineno-4-46" name="__codelineno-4-46" href="#__codelineno-4-46"></a>
<a id="__codelineno-4-47" name="__codelineno-4-47" href="#__codelineno-4-47"></a>    }
<a id="__codelineno-4-48" name="__codelineno-4-48" href="#__codelineno-4-48"></a>    catch (const dxrt::Exception&amp; e)
<a id="__codelineno-4-49" name="__codelineno-4-49" href="#__codelineno-4-49"></a>    {
<a id="__codelineno-4-50" name="__codelineno-4-50" href="#__codelineno-4-50"></a>        std::cerr &lt;&lt; e.what() &lt;&lt; &quot; error-code=&quot; &lt;&lt; e.code() &lt;&lt; std::endl;
<a id="__codelineno-4-51" name="__codelineno-4-51" href="#__codelineno-4-51"></a>        return -1;
<a id="__codelineno-4-52" name="__codelineno-4-52" href="#__codelineno-4-52"></a>    }
<a id="__codelineno-4-53" name="__codelineno-4-53" href="#__codelineno-4-53"></a>    catch (const std::exception&amp; e)
<a id="__codelineno-4-54" name="__codelineno-4-54" href="#__codelineno-4-54"></a>    {
<a id="__codelineno-4-55" name="__codelineno-4-55" href="#__codelineno-4-55"></a>        std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;
<a id="__codelineno-4-56" name="__codelineno-4-56" href="#__codelineno-4-56"></a>        return -1;
<a id="__codelineno-4-57" name="__codelineno-4-57" href="#__codelineno-4-57"></a>    }
<a id="__codelineno-4-58" name="__codelineno-4-58" href="#__codelineno-4-58"></a>    catch(...)
<a id="__codelineno-4-59" name="__codelineno-4-59" href="#__codelineno-4-59"></a>    {
<a id="__codelineno-4-60" name="__codelineno-4-60" href="#__codelineno-4-60"></a>        std::cerr &lt;&lt; &quot;Exception&quot; &lt;&lt; std::endl;
<a id="__codelineno-4-61" name="__codelineno-4-61" href="#__codelineno-4-61"></a>        return -1;
<a id="__codelineno-4-62" name="__codelineno-4-62" href="#__codelineno-4-62"></a>    }
<a id="__codelineno-4-63" name="__codelineno-4-63" href="#__codelineno-4-63"></a>
<a id="__codelineno-4-64" name="__codelineno-4-64" href="#__codelineno-4-64"></a>    return 0;
<a id="__codelineno-4-65" name="__codelineno-4-65" href="#__codelineno-4-65"></a>}
</code></pre></div>
<hr />
<h3 id="run&gt;_runasync">Run &amp; RunAsync<a class="headerlink" href="#run&gt;_runasync" title="Permanent link">&para;</a></h3>
<p>The method for converting a synchronous inference approach using one NPU core into an asynchronous inference approach using multiple NPU cores is as follows. It requires the use of callbacks or threads, as well as the implementation of multiple input buffers to support concurrent operations effectively.</p>
<p><strong>Converting Run(Sync) to RunAsync</strong>  </p>
<ul>
<li>Shift from Single NPU Core to Multiple Cores<br />
    : Modify the existing Run(Sync) structure, which utilizes a single NPU core, to RunAsync structure capable of leveraging multiple NPU cores simultaneously.  </li>
<li>Create Multiple Input/Output Buffers<br />
    : Implement multiple input/output buffers to prevent overwriting. Ensure an appropriate number of buffers are created to support concurrent operations effectively.  </li>
<li>Introduce Multi-Buffer Concept<br />
    : To handle simultaneous inference processes, integrate a multi-buffer mechanism. This is essential for managing concurrent inputs and outputs without data conflicts.  </li>
<li>Asynchronous Inference with Threads or Callbacks<br />
    : Adjust the code to ensure that inference inputs and outputs operate asynchronously using threads or callbacks for efficient processing.  </li>
<li>Thread-Safe Data Exchange<br />
    : For data exchange between threads or callbacks, use a thread-safe queue or structured data mechanisms to avoid race conditions and ensure integrity.  </li>
</ul>
<div class="center-text">
<p align="center">
<img src="./../resources/06_01_03_Converting_Run_Sync_to_RunAcync.png" alt="Converting Run(Sync) to RunAsync" width="1000px">  
<br>
Figure. Converting Run(Sync) to RunAsync  
<br><br>
</p>
</div>

<hr />
<h3 id="inference&gt;_option">Inference Option<a class="headerlink" href="#inference&gt;_option" title="Permanent link">&para;</a></h3>
<p>The following inference options allow you to specify an NPU core for performing inference.</p>
<p>Inference Engine Run, Inference Option  </p>
<ul>
<li>Select devices<br />
    : default devices is <code>{}</code><br />
    : Choose devices to utilize  </li>
<li>Select bound option per device<br />
    : <code>dxrt::InferenceOption::BOUND_OPTION::NPU_ALL</code><br />
    : <code>dxrt::InferenceOption::BOUND_OPTION::NPU_0</code><br />
    : <code>dxrt::InferenceOption::BOUND_OPTION::NPU_1</code><br />
    : <code>dxrt::InferenceOption::BOUND_OPTION::NPU_2</code><br />
    : <code>dxrt::InferenceOption::BOUND_OPTION::NPU_01</code><br />
    : <code>dxrt::InferenceOption::BOUND_OPTION::NPU_12</code><br />
    : <code>dxrt::InferenceOption::BOUND_OPTION::NPU_02</code>  </li>
<li>Use onnx runtime library (<code>ORT</code>)<br />
    : <code>useORT</code> on or off  </li>
</ul>
<p><code>run_sync_model_bound.cpp</code>
<div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a>// DX-RT includes
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>#include &quot;dxrt/dxrt_api.h&quot;
<a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>...
<a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>
<a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>int main()
<a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>{
<a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>    std::string modelPath = &quot;model-path&quot;;
<a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>
<a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>    try
<a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>    {
<a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a>
<a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a>        // select bound option NPU_0 to NPU_2 per device  
<a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a>        dxrt::InferenceOption op;
<a id="__codelineno-5-14" name="__codelineno-5-14" href="#__codelineno-5-14"></a>
<a id="__codelineno-5-15" name="__codelineno-5-15" href="#__codelineno-5-15"></a>        // first device only, default null
<a id="__codelineno-5-16" name="__codelineno-5-16" href="#__codelineno-5-16"></a>        op.devices.push_back(0); // use device 0 
<a id="__codelineno-5-17" name="__codelineno-5-17" href="#__codelineno-5-17"></a>        op.devices.push_back(3); // use device 3 
<a id="__codelineno-5-18" name="__codelineno-5-18" href="#__codelineno-5-18"></a>
<a id="__codelineno-5-19" name="__codelineno-5-19" href="#__codelineno-5-19"></a>        // use BOUND_OPTION::NPU_0 only
<a id="__codelineno-5-20" name="__codelineno-5-20" href="#__codelineno-5-20"></a>        op.boundOption = dxrt::InferenceOption::BOUND_OPTION::NPU_0; 
<a id="__codelineno-5-21" name="__codelineno-5-21" href="#__codelineno-5-21"></a>
<a id="__codelineno-5-22" name="__codelineno-5-22" href="#__codelineno-5-22"></a>        // use ORT
<a id="__codelineno-5-23" name="__codelineno-5-23" href="#__codelineno-5-23"></a>        op.useORT = false;
<a id="__codelineno-5-24" name="__codelineno-5-24" href="#__codelineno-5-24"></a>
<a id="__codelineno-5-25" name="__codelineno-5-25" href="#__codelineno-5-25"></a>        // create inference engine instance with model
<a id="__codelineno-5-26" name="__codelineno-5-26" href="#__codelineno-5-26"></a>        dxrt::InferenceEngine ie(modelPath, op);
<a id="__codelineno-5-27" name="__codelineno-5-27" href="#__codelineno-5-27"></a>
<a id="__codelineno-5-28" name="__codelineno-5-28" href="#__codelineno-5-28"></a>        // create temporary input buffer for example 
<a id="__codelineno-5-29" name="__codelineno-5-29" href="#__codelineno-5-29"></a>        std::vector&lt;uint8_t&gt; inputPtr(ie.GetInputSize(), 0);
<a id="__codelineno-5-30" name="__codelineno-5-30" href="#__codelineno-5-30"></a>
<a id="__codelineno-5-31" name="__codelineno-5-31" href="#__codelineno-5-31"></a>        // inference loop
<a id="__codelineno-5-32" name="__codelineno-5-32" href="#__codelineno-5-32"></a>        for(int i = 0; i &lt; 100; ++i)
<a id="__codelineno-5-33" name="__codelineno-5-33" href="#__codelineno-5-33"></a>        {
<a id="__codelineno-5-34" name="__codelineno-5-34" href="#__codelineno-5-34"></a>            // input
<a id="__codelineno-5-35" name="__codelineno-5-35" href="#__codelineno-5-35"></a>            uint8_t* inputPtr = readInputData();
<a id="__codelineno-5-36" name="__codelineno-5-36" href="#__codelineno-5-36"></a>
<a id="__codelineno-5-37" name="__codelineno-5-37" href="#__codelineno-5-37"></a>            // inference synchronously with boundOption
<a id="__codelineno-5-38" name="__codelineno-5-38" href="#__codelineno-5-38"></a>            // use only one npu core
<a id="__codelineno-5-39" name="__codelineno-5-39" href="#__codelineno-5-39"></a>            // ownership of the outputs is transferred to the user 
<a id="__codelineno-5-40" name="__codelineno-5-40" href="#__codelineno-5-40"></a>            auto outputs = ie.Run(inputPtr.data());
<a id="__codelineno-5-41" name="__codelineno-5-41" href="#__codelineno-5-41"></a>
<a id="__codelineno-5-42" name="__codelineno-5-42" href="#__codelineno-5-42"></a>            // post processing
<a id="__codelineno-5-43" name="__codelineno-5-43" href="#__codelineno-5-43"></a>            postProcessing(outputs);
<a id="__codelineno-5-44" name="__codelineno-5-44" href="#__codelineno-5-44"></a>
<a id="__codelineno-5-45" name="__codelineno-5-45" href="#__codelineno-5-45"></a>        } // for i
<a id="__codelineno-5-46" name="__codelineno-5-46" href="#__codelineno-5-46"></a>    }
<a id="__codelineno-5-47" name="__codelineno-5-47" href="#__codelineno-5-47"></a>    catch(const dxrt::Exception&amp; e)  // exception for inference engine 
<a id="__codelineno-5-48" name="__codelineno-5-48" href="#__codelineno-5-48"></a>    {
<a id="__codelineno-5-49" name="__codelineno-5-49" href="#__codelineno-5-49"></a>        std::cerr &lt;&lt; e.what() &lt;&lt; &quot; error-code=&quot; &lt;&lt; e.code() &lt;&lt; std::endl;
<a id="__codelineno-5-50" name="__codelineno-5-50" href="#__codelineno-5-50"></a>        return -1;
<a id="__codelineno-5-51" name="__codelineno-5-51" href="#__codelineno-5-51"></a>    }
<a id="__codelineno-5-52" name="__codelineno-5-52" href="#__codelineno-5-52"></a>    catch(const std::exception&amp; e)
<a id="__codelineno-5-53" name="__codelineno-5-53" href="#__codelineno-5-53"></a>    {
<a id="__codelineno-5-54" name="__codelineno-5-54" href="#__codelineno-5-54"></a>        std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;
<a id="__codelineno-5-55" name="__codelineno-5-55" href="#__codelineno-5-55"></a>        return -1;
<a id="__codelineno-5-56" name="__codelineno-5-56" href="#__codelineno-5-56"></a>    }
<a id="__codelineno-5-57" name="__codelineno-5-57" href="#__codelineno-5-57"></a>
<a id="__codelineno-5-58" name="__codelineno-5-58" href="#__codelineno-5-58"></a>    return 0;
<a id="__codelineno-5-59" name="__codelineno-5-59" href="#__codelineno-5-59"></a>}
</code></pre></div></p>
<hr />
<h3 id="configuration&gt;_and&gt;_device&gt;_status">Configuration and Device Status<a class="headerlink" href="#configuration&gt;_and&gt;_device&gt;_status" title="Permanent link">&para;</a></h3>
<p>This guide explains how to use the <code>Configuration</code> class to set up the inference engine and the <code>DeviceStatus</code> class to monitor hardware status in C++.</p>
<h4 id="engine&gt;_configuration">Engine Configuration ⚙️<a class="headerlink" href="#engine&gt;_configuration" title="Permanent link">&para;</a></h4>
<p>The <code>Configuration</code> class, implemented as a Singleton, allows you to set global parameters for the inference engine before it runs.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="c1">// Get the singleton instance and set engine parameters</span>
<a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span class="n">dxrt</span><span class="o">::</span><span class="n">Configuration</span><span class="o">::</span><span class="n">GetInstance</span><span class="p">().</span><span class="n">SetEnable</span><span class="p">(</span><span class="n">dxrt</span><span class="o">::</span><span class="n">Configuration</span><span class="o">::</span><span class="n">ITEM</span><span class="o">::</span><span class="n">SHOW_MODEL_INFO</span><span class="p">,</span><span class="w"> </span><span class="nb">true</span><span class="p">);</span>
<a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="n">dxrt</span><span class="o">::</span><span class="n">Configuration</span><span class="o">::</span><span class="n">GetInstance</span><span class="p">().</span><span class="n">SetEnable</span><span class="p">(</span><span class="n">dxrt</span><span class="o">::</span><span class="n">Configuration</span><span class="o">::</span><span class="n">ITEM</span><span class="o">::</span><span class="n">SHOW_PROFILE</span><span class="p">,</span><span class="w"> </span><span class="nb">true</span><span class="p">);</span>
</code></pre></div>
<ul>
<li><strong><code>Configuration::GetInstance()</code></strong>: Accesses the single, global instance of the configuration manager.</li>
<li><strong><code>.SetEnable(...)</code></strong>: Enables engine features. Here, it's configured to print detailed model information and performance profiling data when the <code>InferenceEngine</code> is initialized.</li>
</ul>
<h4 id="querying&gt;_device&gt;_status">Querying Device Status 🖥️<a class="headerlink" href="#querying&gt;_device&gt;_status" title="Permanent link">&para;</a></h4>
<p>The <code>DeviceStatus</code> class is used to get real-time operational information from the NPU hardware. This is often done after a workload to check the device's state.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="c1">// Get the number of available devices</span>
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="k">auto</span><span class="w"> </span><span class="n">device_count</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dxrt</span><span class="o">::</span><span class="n">DeviceStatus</span><span class="o">::</span><span class="n">GetDeviceCount</span><span class="p">();</span>
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>
<a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="c1">// Loop through each device</span>
<a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a><span class="k">for</span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">device_count</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span>
<a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a><span class="p">{</span>
<a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a><span class="w">    </span><span class="c1">// Get a status snapshot for the current device</span>
<a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a><span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">device_status</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dxrt</span><span class="o">::</span><span class="n">DeviceStatus</span><span class="o">::</span><span class="n">GetCurrentStatus</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
<a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a>
<a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a><span class="w">    </span><span class="c1">// Query and print specific metrics like temperature, voltage, and clock speed</span>
<a id="__codelineno-7-11" name="__codelineno-7-11" href="#__codelineno-7-11"></a><span class="w">    </span><span class="n">log</span><span class="p">.</span><span class="n">Info</span><span class="p">(</span><span class="s">&quot;Device: &quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">to_string</span><span class="p">(</span><span class="n">device_status</span><span class="p">.</span><span class="n">GetId</span><span class="p">()));</span>
<a id="__codelineno-7-12" name="__codelineno-7-12" href="#__codelineno-7-12"></a><span class="w">    </span><span class="n">log</span><span class="p">.</span><span class="n">Info</span><span class="p">(</span><span class="s">&quot;   Temperature: &quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">to_string</span><span class="p">(</span><span class="n">device_status</span><span class="p">.</span><span class="n">GetTemperature</span><span class="p">(</span><span class="mi">0</span><span class="p">)));</span>
<a id="__codelineno-7-13" name="__codelineno-7-13" href="#__codelineno-7-13"></a><span class="w">    </span><span class="n">log</span><span class="p">.</span><span class="n">Info</span><span class="p">(</span><span class="s">&quot;   Voltage: &quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">to_string</span><span class="p">(</span><span class="n">device_status</span><span class="p">.</span><span class="n">GetNpuVoltage</span><span class="p">(</span><span class="mi">0</span><span class="p">)));</span>
<a id="__codelineno-7-14" name="__codelineno-7-14" href="#__codelineno-7-14"></a><span class="w">    </span><span class="n">log</span><span class="p">.</span><span class="n">Info</span><span class="p">(</span><span class="s">&quot;   Clock: &quot;</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">to_string</span><span class="p">(</span><span class="n">device_status</span><span class="p">.</span><span class="n">GetNpuClock</span><span class="p">(</span><span class="mi">0</span><span class="p">)));</span>
<a id="__codelineno-7-15" name="__codelineno-7-15" href="#__codelineno-7-15"></a><span class="p">}</span>
</code></pre></div>
<ul>
<li><strong><code>DeviceStatus::GetDeviceCount()</code></strong>: A static method that returns the number of connected DEEPX devices.</li>
<li><strong><code>DeviceStatus::GetCurrentStatus(i)</code></strong>: Returns a status object containing a <strong>snapshot</strong> of the hardware metrics for device <code>i</code> at that specific moment.</li>
<li><strong><code>device_status.Get...()</code></strong>: Instance methods used to retrieve individual metrics from the status object, such as <code>GetTemperature()</code>, <code>GetNpuVoltage()</code>, and <code>GetNpuClock()</code> for a specific NPU core (e.g., core 0).</li>
</ul>
<hr />
<h3 id="profiler&gt;_configuration">Profiler Configuration<a class="headerlink" href="#profiler&gt;_configuration" title="Permanent link">&para;</a></h3>
<p>This guide provides a simple, code-focused manual on how to configure the profiler using the DXRT SDK. The profiler is a powerful tool for analyzing the performance of each layer within your model.</p>
<p>Configuration is managed through the <code>dxrt::Configuration</code> singleton instance.</p>
<h4 id="enabling&gt;_the&gt;_profiler">Enabling the Profiler<a class="headerlink" href="#enabling&gt;_the&gt;_profiler" title="Permanent link">&para;</a></h4>
<p>Before you can use any profiler features, you must first <strong>enable</strong> it. This is the essential first step for any profiling activity.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="c1">// Enable the profiler feature</span>
<a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="n">dxrt</span><span class="o">::</span><span class="n">Configuration</span><span class="o">::</span><span class="n">GetInstance</span><span class="p">().</span><span class="n">SetEnable</span><span class="p">(</span><span class="n">dxrt</span><span class="o">::</span><span class="n">Configuration</span><span class="o">::</span><span class="n">ITEM</span><span class="o">::</span><span class="n">PROFILER</span><span class="p">,</span><span class="w"> </span><span class="nb">true</span><span class="p">);</span>
</code></pre></div>
<ul>
<li><strong><code>SetEnable</code></strong>: This function activates or deactivates a specific DXRT feature.</li>
<li><strong><code>dxrt::Configuration::ITEM::PROFILER</code></strong>: Specifies that the target feature is the profiler.</li>
<li><strong><code>true</code></strong>: Enables the profiler. Set to <code>false</code> to disable it.</li>
</ul>
<h4 id="configuration&gt;_options">Configuration Options<a class="headerlink" href="#configuration&gt;_options" title="Permanent link">&para;</a></h4>
<p>Once enabled, you can set specific attributes for the profiler's behavior.</p>
<h5 id="displaying&gt;_profiler&gt;_data&gt;_in&gt;_the&gt;_console">Displaying Profiler Data in the Console<a class="headerlink" href="#displaying&gt;_profiler&gt;_data&gt;_in&gt;_the&gt;_console" title="Permanent link">&para;</a></h5>
<p>To see the profiling results printed directly to your console after the inference runs, use the <code>PROFILER_SHOW_DATA</code> attribute.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="c1">// Configure the profiler to print its report to the console</span>
<a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="n">dxrt</span><span class="o">::</span><span class="n">Configuration</span><span class="o">::</span><span class="n">GetInstance</span><span class="p">().</span><span class="n">SetAttribute</span><span class="p">(</span><span class="n">dxrt</span><span class="o">::</span><span class="n">Configuration</span><span class="o">::</span><span class="n">ITEM</span><span class="o">::</span><span class="n">PROFILER</span><span class="p">,</span>
<a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a><span class="w">                                                 </span><span class="n">dxrt</span><span class="o">::</span><span class="n">Configuration</span><span class="o">::</span><span class="n">ATTRIBUTE</span><span class="o">::</span><span class="n">PROFILER_SHOW_DATA</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;ON&quot;</span><span class="p">);</span>
</code></pre></div>
<ul>
<li><strong><code>SetAttribute</code></strong>: Sets a specific property for a DXRT feature.</li>
<li><strong><code>PROFILER_SHOW_DATA</code></strong>: The attribute to control console output.</li>
<li><strong><code>"ON"</code></strong>: A string value to enable this attribute. Use <code>"OFF"</code> to disable it.</li>
</ul>
<h5 id="saving&gt;_profiler&gt;_data&gt;_to&gt;_a&gt;_file">Saving Profiler Data to a File<a class="headerlink" href="#saving&gt;_profiler&gt;_data&gt;_to&gt;_a&gt;_file" title="Permanent link">&para;</a></h5>
<p>To save the profiling report to a file for later analysis, use the <code>PROFILER_SAVE_DATA</code> attribute. The resulting report is generated in the same folder with the name <strong><code>profiler.json</code></strong>. 📄</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="c1">// Configure the profiler to save its report to a file</span>
<a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a><span class="n">dxrt</span><span class="o">::</span><span class="n">Configuration</span><span class="o">::</span><span class="n">GetInstance</span><span class="p">().</span><span class="n">SetAttribute</span><span class="p">(</span><span class="n">dxrt</span><span class="o">::</span><span class="n">Configuration</span><span class="o">::</span><span class="n">ITEM</span><span class="o">::</span><span class="n">PROFILER</span><span class="p">,</span>
<a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a><span class="w">                                                 </span><span class="n">dxrt</span><span class="o">::</span><span class="n">Configuration</span><span class="o">::</span><span class="n">ATTRIBUTE</span><span class="o">::</span><span class="n">PROFILER_SAVE_DATA</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;ON&quot;</span><span class="p">);</span>
</code></pre></div>
<ul>
<li><strong><code>PROFILER_SAVE_DATA</code></strong>: The attribute to control file output.</li>
<li><strong><code>"ON"</code></strong>: A string value to enable file saving. Use <code>"OFF"</code> to disable it.</li>
</ul>
<h4 id="complete&gt;_code&gt;_example">Complete Code Example<a class="headerlink" href="#complete&gt;_code&gt;_example" title="Permanent link">&para;</a></h4>
<p>Here is a complete example showing how to apply all the configurations within a <code>try-catch</code> block before creating the <code>InferenceEngine</code>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="k">try</span><span class="w"> </span>
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a><span class="p">{</span>
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a><span class="w">    </span><span class="c1">// Step 1: Enable the profiler</span>
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a><span class="w">    </span><span class="n">dxrt</span><span class="o">::</span><span class="n">Configuration</span><span class="o">::</span><span class="n">GetInstance</span><span class="p">().</span><span class="n">SetEnable</span><span class="p">(</span><span class="n">dxrt</span><span class="o">::</span><span class="n">Configuration</span><span class="o">::</span><span class="n">ITEM</span><span class="o">::</span><span class="n">PROFILER</span><span class="p">,</span><span class="w"> </span><span class="nb">true</span><span class="p">);</span>
<a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a>
<a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a><span class="w">    </span><span class="c1">// Step 2: Set attributes to show data in console and save to a file</span>
<a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a><span class="w">    </span><span class="n">dxrt</span><span class="o">::</span><span class="n">Configuration</span><span class="o">::</span><span class="n">GetInstance</span><span class="p">().</span><span class="n">SetAttribute</span><span class="p">(</span><span class="n">dxrt</span><span class="o">::</span><span class="n">Configuration</span><span class="o">::</span><span class="n">ITEM</span><span class="o">::</span><span class="n">PROFILER</span><span class="p">,</span><span class="w"> </span>
<a id="__codelineno-11-8" name="__codelineno-11-8" href="#__codelineno-11-8"></a><span class="w">                                                     </span><span class="n">dxrt</span><span class="o">::</span><span class="n">Configuration</span><span class="o">::</span><span class="n">ATTRIBUTE</span><span class="o">::</span><span class="n">PROFILER_SHOW_DATA</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;ON&quot;</span><span class="p">);</span>
<a id="__codelineno-11-9" name="__codelineno-11-9" href="#__codelineno-11-9"></a><span class="w">    </span><span class="n">dxrt</span><span class="o">::</span><span class="n">Configuration</span><span class="o">::</span><span class="n">GetInstance</span><span class="p">().</span><span class="n">SetAttribute</span><span class="p">(</span><span class="n">dxrt</span><span class="o">::</span><span class="n">Configuration</span><span class="o">::</span><span class="n">ITEM</span><span class="o">::</span><span class="n">PROFILER</span><span class="p">,</span><span class="w"> </span>
<a id="__codelineno-11-10" name="__codelineno-11-10" href="#__codelineno-11-10"></a><span class="w">                                                     </span><span class="n">dxrt</span><span class="o">::</span><span class="n">Configuration</span><span class="o">::</span><span class="n">ATTRIBUTE</span><span class="o">::</span><span class="n">PROFILER_SAVE_DATA</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;ON&quot;</span><span class="p">);</span>
<a id="__codelineno-11-11" name="__codelineno-11-11" href="#__codelineno-11-11"></a>
<a id="__codelineno-11-12" name="__codelineno-11-12" href="#__codelineno-11-12"></a><span class="w">    </span><span class="c1">// Step 3: Create the InferenceEngine instance and run inference</span>
<a id="__codelineno-11-13" name="__codelineno-11-13" href="#__codelineno-11-13"></a><span class="w">    </span><span class="c1">// The profiler will automatically work on the models run by this engine.</span>
<a id="__codelineno-11-14" name="__codelineno-11-14" href="#__codelineno-11-14"></a><span class="w">    </span><span class="n">dxrt</span><span class="o">::</span><span class="n">InferenceEngine</span><span class="w"> </span><span class="nf">ie</span><span class="p">(</span><span class="n">model_path</span><span class="p">);</span>
<a id="__codelineno-11-15" name="__codelineno-11-15" href="#__codelineno-11-15"></a>
<a id="__codelineno-11-16" name="__codelineno-11-16" href="#__codelineno-11-16"></a><span class="w">    </span><span class="c1">// ... run inference loop ...</span>
<a id="__codelineno-11-17" name="__codelineno-11-17" href="#__codelineno-11-17"></a><span class="p">}</span>
<a id="__codelineno-11-18" name="__codelineno-11-18" href="#__codelineno-11-18"></a><span class="k">catch</span><span class="w"> </span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">dxrt</span><span class="o">::</span><span class="n">Exception</span><span class="o">&amp;</span><span class="w"> </span><span class="n">e</span><span class="p">)</span>
<a id="__codelineno-11-19" name="__codelineno-11-19" href="#__codelineno-11-19"></a><span class="p">{</span>
<a id="__codelineno-11-20" name="__codelineno-11-20" href="#__codelineno-11-20"></a><span class="w">    </span><span class="c1">// ... handle exceptions ...</span>
<a id="__codelineno-11-21" name="__codelineno-11-21" href="#__codelineno-11-21"></a><span class="p">}</span>
</code></pre></div>
<hr />
<h3 id="camera&gt;_inference&gt;_display">Camera / Inference / Display<a class="headerlink" href="#camera&gt;_inference&gt;_display" title="Permanent link">&para;</a></h3>
<p>The following is an example of a pattern that performs inference using two models on a single camera input and combines the results from both models for display.</p>
<div class="center-text">
<p align="center">
<img src="./../resources/06_01_04_Multi-model_and_Multi-output.png" alt="Multi-model and Multi-output" width="800px">  
<br>
Figure. Multi-model and Multi-output  
<br><br>
</p>
</div>

<p>Multi-model, Async, Wait Thread <code>(CPU_1 → {NPU_1 + NPU_2} → CPU_2</code></p>
<p><code>display_async_wait.cpp</code>
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a>// DX-RT includes
<a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a>#include &quot;dxrt/dxrt_api.h&quot;
<a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>...
<a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a>
<a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a>// input processing main thread with 2 InferenceEngine (asynchronous) 
<a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a>// display thread 
<a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a>
<a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a>struct FrameJobId {
<a id="__codelineno-12-9" name="__codelineno-12-9" href="#__codelineno-12-9"></a>    int jobId_A = -1;
<a id="__codelineno-12-10" name="__codelineno-12-10" href="#__codelineno-12-10"></a>    int jobId_B = -1;
<a id="__codelineno-12-11" name="__codelineno-12-11" href="#__codelineno-12-11"></a>    void* frameBuffer = nullptr;
<a id="__codelineno-12-12" name="__codelineno-12-12" href="#__codelineno-12-12"></a>    int loopIndex = -1;
<a id="__codelineno-12-13" name="__codelineno-12-13" href="#__codelineno-12-13"></a>};
<a id="__codelineno-12-14" name="__codelineno-12-14" href="#__codelineno-12-14"></a>
<a id="__codelineno-12-15" name="__codelineno-12-15" href="#__codelineno-12-15"></a>static const int BUFFER_POOL_SIZE = 10;
<a id="__codelineno-12-16" name="__codelineno-12-16" href="#__codelineno-12-16"></a>static const int QUEUE_SIZE = 10;
<a id="__codelineno-12-17" name="__codelineno-12-17" href="#__codelineno-12-17"></a>
<a id="__codelineno-12-18" name="__codelineno-12-18" href="#__codelineno-12-18"></a>static ConcurrentQueue&lt;FrameJobId&gt; gFrameJobIdQueue(QUEUE_SIZE);
<a id="__codelineno-12-19" name="__codelineno-12-19" href="#__codelineno-12-19"></a>static std::shared_ptr&lt;SimpleCircularBufferPool&lt;uint8_t&gt;&gt; gInputBufferPool_A;
<a id="__codelineno-12-20" name="__codelineno-12-20" href="#__codelineno-12-20"></a>static std::shared_ptr&lt;SimpleCircularBufferPool&lt;uint8_t&gt;&gt; gInputBufferPool_B;
<a id="__codelineno-12-21" name="__codelineno-12-21" href="#__codelineno-12-21"></a>static std::shared_ptr&lt;SimpleCircularBufferPool&lt;uint8_t&gt;&gt; gFrameBufferPool;
<a id="__codelineno-12-22" name="__codelineno-12-22" href="#__codelineno-12-22"></a>
<a id="__codelineno-12-23" name="__codelineno-12-23" href="#__codelineno-12-23"></a>// total display count
<a id="__codelineno-12-24" name="__codelineno-12-24" href="#__codelineno-12-24"></a>static std::atomic&lt;int&gt; gTotalDisplayCount = {0};
<a id="__codelineno-12-25" name="__codelineno-12-25" href="#__codelineno-12-25"></a>
<a id="__codelineno-12-26" name="__codelineno-12-26" href="#__codelineno-12-26"></a>static int displayThreadFunc(int loopCount, dxrt::InferenceEngine&amp; ieA, dxrt::InferenceEngine&amp; ieB)
<a id="__codelineno-12-27" name="__codelineno-12-27" href="#__codelineno-12-27"></a>{
<a id="__codelineno-12-28" name="__codelineno-12-28" href="#__codelineno-12-28"></a>
<a id="__codelineno-12-29" name="__codelineno-12-29" href="#__codelineno-12-29"></a>    while(gTotalDisplayCount.load() &lt; loopCount)
<a id="__codelineno-12-30" name="__codelineno-12-30" href="#__codelineno-12-30"></a>    {
<a id="__codelineno-12-31" name="__codelineno-12-31" href="#__codelineno-12-31"></a>        // consumer framebuffer &amp; jobIds
<a id="__codelineno-12-32" name="__codelineno-12-32" href="#__codelineno-12-32"></a>        auto frameJobId = gFrameJobIdQueue.pop();
<a id="__codelineno-12-33" name="__codelineno-12-33" href="#__codelineno-12-33"></a>
<a id="__codelineno-12-34" name="__codelineno-12-34" href="#__codelineno-12-34"></a>        // output data of ieA
<a id="__codelineno-12-35" name="__codelineno-12-35" href="#__codelineno-12-35"></a>        auto outputA = ieA.Wait(frameJobId.jobId_A);
<a id="__codelineno-12-36" name="__codelineno-12-36" href="#__codelineno-12-36"></a>
<a id="__codelineno-12-37" name="__codelineno-12-37" href="#__codelineno-12-37"></a>        // output data of ieB
<a id="__codelineno-12-38" name="__codelineno-12-38" href="#__codelineno-12-38"></a>        auto outputB = ieB.Wait(frameJobId.jobId_B);
<a id="__codelineno-12-39" name="__codelineno-12-39" href="#__codelineno-12-39"></a>
<a id="__codelineno-12-40" name="__codelineno-12-40" href="#__codelineno-12-40"></a>        // post-processing w/ outputA &amp; outputB
<a id="__codelineno-12-41" name="__codelineno-12-41" href="#__codelineno-12-41"></a>        postProcessing(outputA, outputB);
<a id="__codelineno-12-42" name="__codelineno-12-42" href="#__codelineno-12-42"></a>
<a id="__codelineno-12-43" name="__codelineno-12-43" href="#__codelineno-12-43"></a>        gTotalDisplayCount++;
<a id="__codelineno-12-44" name="__codelineno-12-44" href="#__codelineno-12-44"></a>
<a id="__codelineno-12-45" name="__codelineno-12-45" href="#__codelineno-12-45"></a>        // display (update framebuffer)
<a id="__codelineno-12-46" name="__codelineno-12-46" href="#__codelineno-12-46"></a>    }
<a id="__codelineno-12-47" name="__codelineno-12-47" href="#__codelineno-12-47"></a>
<a id="__codelineno-12-48" name="__codelineno-12-48" href="#__codelineno-12-48"></a>    return 0;
<a id="__codelineno-12-49" name="__codelineno-12-49" href="#__codelineno-12-49"></a>}
<a id="__codelineno-12-50" name="__codelineno-12-50" href="#__codelineno-12-50"></a>
<a id="__codelineno-12-51" name="__codelineno-12-51" href="#__codelineno-12-51"></a>
<a id="__codelineno-12-52" name="__codelineno-12-52" href="#__codelineno-12-52"></a>int main(int argc, char* argv[])
<a id="__codelineno-12-53" name="__codelineno-12-53" href="#__codelineno-12-53"></a>{
<a id="__codelineno-12-54" name="__codelineno-12-54" href="#__codelineno-12-54"></a>    ...
<a id="__codelineno-12-55" name="__codelineno-12-55" href="#__codelineno-12-55"></a>
<a id="__codelineno-12-56" name="__codelineno-12-56" href="#__codelineno-12-56"></a>    try
<a id="__codelineno-12-57" name="__codelineno-12-57" href="#__codelineno-12-57"></a>    {
<a id="__codelineno-12-58" name="__codelineno-12-58" href="#__codelineno-12-58"></a>
<a id="__codelineno-12-59" name="__codelineno-12-59" href="#__codelineno-12-59"></a>        // create inference engine instance with model
<a id="__codelineno-12-60" name="__codelineno-12-60" href="#__codelineno-12-60"></a>        dxrt::InferenceEngine ieA(modelPath_A);
<a id="__codelineno-12-61" name="__codelineno-12-61" href="#__codelineno-12-61"></a>
<a id="__codelineno-12-62" name="__codelineno-12-62" href="#__codelineno-12-62"></a>        gInputBufferPool_A = std::make_shared&lt;SimpleCircularBufferPool&lt;uint8_t&gt;&gt;(BUFFER_POOL_SIZE, ieA.GetInputSize());
<a id="__codelineno-12-63" name="__codelineno-12-63" href="#__codelineno-12-63"></a>
<a id="__codelineno-12-64" name="__codelineno-12-64" href="#__codelineno-12-64"></a>        // create inference engine instance with model
<a id="__codelineno-12-65" name="__codelineno-12-65" href="#__codelineno-12-65"></a>        dxrt::InferenceEngine ieB(modelPath_B);
<a id="__codelineno-12-66" name="__codelineno-12-66" href="#__codelineno-12-66"></a>
<a id="__codelineno-12-67" name="__codelineno-12-67" href="#__codelineno-12-67"></a>        gInputBufferPool_B = std::make_shared&lt;SimpleCircularBufferPool&lt;uint8_t&gt;&gt;(BUFFER_POOL_SIZE, ieB.GetInputSize());
<a id="__codelineno-12-68" name="__codelineno-12-68" href="#__codelineno-12-68"></a>
<a id="__codelineno-12-69" name="__codelineno-12-69" href="#__codelineno-12-69"></a>        const int W = 512, H = 512, CH = 3;
<a id="__codelineno-12-70" name="__codelineno-12-70" href="#__codelineno-12-70"></a>        gFrameBufferPool = std::make_shared&lt;SimpleCircularBufferPool&lt;uint8_t&gt;&gt;(BUFFER_POOL_SIZE, W*H*CH);
<a id="__codelineno-12-71" name="__codelineno-12-71" href="#__codelineno-12-71"></a>
<a id="__codelineno-12-72" name="__codelineno-12-72" href="#__codelineno-12-72"></a>        // create thread
<a id="__codelineno-12-73" name="__codelineno-12-73" href="#__codelineno-12-73"></a>        std::thread displayThread(displayThreadFunc, loop_count, std::ref(ieA), std::ref(ieB));
<a id="__codelineno-12-74" name="__codelineno-12-74" href="#__codelineno-12-74"></a>
<a id="__codelineno-12-75" name="__codelineno-12-75" href="#__codelineno-12-75"></a>        // input processing
<a id="__codelineno-12-76" name="__codelineno-12-76" href="#__codelineno-12-76"></a>        for(int i = 0; i &lt; loop_count; ++i)
<a id="__codelineno-12-77" name="__codelineno-12-77" href="#__codelineno-12-77"></a>        {
<a id="__codelineno-12-78" name="__codelineno-12-78" href="#__codelineno-12-78"></a>            uint8_t* frameBuffer = gFrameBufferPool-&gt;pointer(); 
<a id="__codelineno-12-79" name="__codelineno-12-79" href="#__codelineno-12-79"></a>            readFrameBuffer(frameBuffer, W, H, CH);
<a id="__codelineno-12-80" name="__codelineno-12-80" href="#__codelineno-12-80"></a>
<a id="__codelineno-12-81" name="__codelineno-12-81" href="#__codelineno-12-81"></a>            uint8_t* inputA = gInputBufferPool_A-&gt;pointer();
<a id="__codelineno-12-82" name="__codelineno-12-82" href="#__codelineno-12-82"></a>            preProcessing(inputA, frameBuffer);
<a id="__codelineno-12-83" name="__codelineno-12-83" href="#__codelineno-12-83"></a>
<a id="__codelineno-12-84" name="__codelineno-12-84" href="#__codelineno-12-84"></a>            uint8_t* inputB = gInputBufferPool_B-&gt;pointer();
<a id="__codelineno-12-85" name="__codelineno-12-85" href="#__codelineno-12-85"></a>            preProcessing(inputB, frameBuffer);
<a id="__codelineno-12-86" name="__codelineno-12-86" href="#__codelineno-12-86"></a>
<a id="__codelineno-12-87" name="__codelineno-12-87" href="#__codelineno-12-87"></a>            // struct to pass to cpu operation thread 
<a id="__codelineno-12-88" name="__codelineno-12-88" href="#__codelineno-12-88"></a>            FrameJobId frameJobId;
<a id="__codelineno-12-89" name="__codelineno-12-89" href="#__codelineno-12-89"></a>
<a id="__codelineno-12-90" name="__codelineno-12-90" href="#__codelineno-12-90"></a>            // start inference of A model
<a id="__codelineno-12-91" name="__codelineno-12-91" href="#__codelineno-12-91"></a>            frameJobId.jobId_A = ieA.RunAsync(inputA);
<a id="__codelineno-12-92" name="__codelineno-12-92" href="#__codelineno-12-92"></a>
<a id="__codelineno-12-93" name="__codelineno-12-93" href="#__codelineno-12-93"></a>            // start inference of B model
<a id="__codelineno-12-94" name="__codelineno-12-94" href="#__codelineno-12-94"></a>            frameJobId.jobId_B = ieB.RunAsync(inputB);
<a id="__codelineno-12-95" name="__codelineno-12-95" href="#__codelineno-12-95"></a>
<a id="__codelineno-12-96" name="__codelineno-12-96" href="#__codelineno-12-96"></a>            // framebuffer used for input data
<a id="__codelineno-12-97" name="__codelineno-12-97" href="#__codelineno-12-97"></a>            frameJobId.frameBuffer = frameBuffer;
<a id="__codelineno-12-98" name="__codelineno-12-98" href="#__codelineno-12-98"></a>            frameJobId.loopIndex = i;
<a id="__codelineno-12-99" name="__codelineno-12-99" href="#__codelineno-12-99"></a>
<a id="__codelineno-12-100" name="__codelineno-12-100" href="#__codelineno-12-100"></a>            // producer frame &amp; jobId
<a id="__codelineno-12-101" name="__codelineno-12-101" href="#__codelineno-12-101"></a>            gFrameJobIdQueue.push(frameJobId);
<a id="__codelineno-12-102" name="__codelineno-12-102" href="#__codelineno-12-102"></a>
<a id="__codelineno-12-103" name="__codelineno-12-103" href="#__codelineno-12-103"></a>        }
<a id="__codelineno-12-104" name="__codelineno-12-104" href="#__codelineno-12-104"></a>
<a id="__codelineno-12-105" name="__codelineno-12-105" href="#__codelineno-12-105"></a>        displayThread.join();
<a id="__codelineno-12-106" name="__codelineno-12-106" href="#__codelineno-12-106"></a>
<a id="__codelineno-12-107" name="__codelineno-12-107" href="#__codelineno-12-107"></a>
<a id="__codelineno-12-108" name="__codelineno-12-108" href="#__codelineno-12-108"></a>    }
<a id="__codelineno-12-109" name="__codelineno-12-109" href="#__codelineno-12-109"></a>    catch (const dxrt::Exception&amp; e)
<a id="__codelineno-12-110" name="__codelineno-12-110" href="#__codelineno-12-110"></a>    {
<a id="__codelineno-12-111" name="__codelineno-12-111" href="#__codelineno-12-111"></a>        std::cerr &lt;&lt; e.what() &lt;&lt; &quot; error-code=&quot; &lt;&lt; e.code() &lt;&lt; std::endl;
<a id="__codelineno-12-112" name="__codelineno-12-112" href="#__codelineno-12-112"></a>        return -1;
<a id="__codelineno-12-113" name="__codelineno-12-113" href="#__codelineno-12-113"></a>    }
<a id="__codelineno-12-114" name="__codelineno-12-114" href="#__codelineno-12-114"></a>    catch (const std::exception&amp; e)
<a id="__codelineno-12-115" name="__codelineno-12-115" href="#__codelineno-12-115"></a>    {
<a id="__codelineno-12-116" name="__codelineno-12-116" href="#__codelineno-12-116"></a>        std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;
<a id="__codelineno-12-117" name="__codelineno-12-117" href="#__codelineno-12-117"></a>        return -1;
<a id="__codelineno-12-118" name="__codelineno-12-118" href="#__codelineno-12-118"></a>    }
<a id="__codelineno-12-119" name="__codelineno-12-119" href="#__codelineno-12-119"></a>    catch(...)
<a id="__codelineno-12-120" name="__codelineno-12-120" href="#__codelineno-12-120"></a>    {
<a id="__codelineno-12-121" name="__codelineno-12-121" href="#__codelineno-12-121"></a>        std::cerr &lt;&lt; &quot;Exception&quot; &lt;&lt; std::endl;
<a id="__codelineno-12-122" name="__codelineno-12-122" href="#__codelineno-12-122"></a>        return -1;
<a id="__codelineno-12-123" name="__codelineno-12-123" href="#__codelineno-12-123"></a>    }
<a id="__codelineno-12-124" name="__codelineno-12-124" href="#__codelineno-12-124"></a>
<a id="__codelineno-12-125" name="__codelineno-12-125" href="#__codelineno-12-125"></a>    return 0;
<a id="__codelineno-12-126" name="__codelineno-12-126" href="#__codelineno-12-126"></a>}
</code></pre></div></p>
<p>The following is an example of a pattern that sequentially performs operations using two models and CPU processing. The inference result from Model A is processed through CPU computation and then used as input data for Model B. Finally, the result from Model B is handled for display.</p>
<div class="center-text">
<p align="center">
<img src="./../resources/06_01_05_CPU_and_NPU_Pipeline_Operation.png" alt="CPU and NPU Pipeline Operation" width="780px">  
<br>
Figure. CPU and NPU Pipeline Operation  
<br><br>
</p>
</div>

<p>Multi-model, Async, Wait Thread <code>(CPU_1 → NPU_1 → CPU_2 → NPU_2 → CPU_3)</code></p>
<p><code>display_async_pipe.cpp</code>
<div class="highlight"><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a>// DX-RT includes
<a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>#include &quot;dxrt/dxrt_api.h&quot;
<a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a>...
<a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a>
<a id="__codelineno-13-5" name="__codelineno-13-5" href="#__codelineno-13-5"></a>// input main thread 
<a id="__codelineno-13-6" name="__codelineno-13-6" href="#__codelineno-13-6"></a>// 1 cpu processing thread  
<a id="__codelineno-13-7" name="__codelineno-13-7" href="#__codelineno-13-7"></a>// 1 display thread 
<a id="__codelineno-13-8" name="__codelineno-13-8" href="#__codelineno-13-8"></a>
<a id="__codelineno-13-9" name="__codelineno-13-9" href="#__codelineno-13-9"></a>struct FrameJobId {
<a id="__codelineno-13-10" name="__codelineno-13-10" href="#__codelineno-13-10"></a>    int jobId_A = -1;
<a id="__codelineno-13-11" name="__codelineno-13-11" href="#__codelineno-13-11"></a>    int jobId_B = -1;
<a id="__codelineno-13-12" name="__codelineno-13-12" href="#__codelineno-13-12"></a>    uint8_t* inputBufferA;
<a id="__codelineno-13-13" name="__codelineno-13-13" href="#__codelineno-13-13"></a>    uint8_t* inputBufferB;
<a id="__codelineno-13-14" name="__codelineno-13-14" href="#__codelineno-13-14"></a>    void* frameBuffer = nullptr;
<a id="__codelineno-13-15" name="__codelineno-13-15" href="#__codelineno-13-15"></a>
<a id="__codelineno-13-16" name="__codelineno-13-16" href="#__codelineno-13-16"></a>    int loopIndex;
<a id="__codelineno-13-17" name="__codelineno-13-17" href="#__codelineno-13-17"></a>};
<a id="__codelineno-13-18" name="__codelineno-13-18" href="#__codelineno-13-18"></a>
<a id="__codelineno-13-19" name="__codelineno-13-19" href="#__codelineno-13-19"></a>static const int BUFFER_POOL_SIZE = 10;
<a id="__codelineno-13-20" name="__codelineno-13-20" href="#__codelineno-13-20"></a>static const int QUEUE_SIZE = 10;
<a id="__codelineno-13-21" name="__codelineno-13-21" href="#__codelineno-13-21"></a>
<a id="__codelineno-13-22" name="__codelineno-13-22" href="#__codelineno-13-22"></a>static ConcurrentQueue&lt;FrameJobId&gt; gCPUOPQueue(QUEUE_SIZE);
<a id="__codelineno-13-23" name="__codelineno-13-23" href="#__codelineno-13-23"></a>static ConcurrentQueue&lt;FrameJobId&gt; gDisplayQueue(QUEUE_SIZE);
<a id="__codelineno-13-24" name="__codelineno-13-24" href="#__codelineno-13-24"></a>static std::shared_ptr&lt;SimpleCircularBufferPool&lt;uint8_t&gt;&gt; gInputBufferPool_A;
<a id="__codelineno-13-25" name="__codelineno-13-25" href="#__codelineno-13-25"></a>static std::shared_ptr&lt;SimpleCircularBufferPool&lt;uint8_t&gt;&gt; gInputBufferPool_B;
<a id="__codelineno-13-26" name="__codelineno-13-26" href="#__codelineno-13-26"></a>static std::shared_ptr&lt;SimpleCircularBufferPool&lt;uint8_t&gt;&gt; gFrameBufferPool;
<a id="__codelineno-13-27" name="__codelineno-13-27" href="#__codelineno-13-27"></a>
<a id="__codelineno-13-28" name="__codelineno-13-28" href="#__codelineno-13-28"></a>// total display count
<a id="__codelineno-13-29" name="__codelineno-13-29" href="#__codelineno-13-29"></a>static std::atomic&lt;int&gt; gTotalDisplayCount = {0};
<a id="__codelineno-13-30" name="__codelineno-13-30" href="#__codelineno-13-30"></a>
<a id="__codelineno-13-31" name="__codelineno-13-31" href="#__codelineno-13-31"></a>
<a id="__codelineno-13-32" name="__codelineno-13-32" href="#__codelineno-13-32"></a>static int displayThreadFunc(int loopCount, dxrt::InferenceEngine&amp; ieB)
<a id="__codelineno-13-33" name="__codelineno-13-33" href="#__codelineno-13-33"></a>{
<a id="__codelineno-13-34" name="__codelineno-13-34" href="#__codelineno-13-34"></a>
<a id="__codelineno-13-35" name="__codelineno-13-35" href="#__codelineno-13-35"></a>    while(gTotalDisplayCount.load() &lt; loopCount)
<a id="__codelineno-13-36" name="__codelineno-13-36" href="#__codelineno-13-36"></a>    {
<a id="__codelineno-13-37" name="__codelineno-13-37" href="#__codelineno-13-37"></a>        // consumer framebuffer &amp; jobIds
<a id="__codelineno-13-38" name="__codelineno-13-38" href="#__codelineno-13-38"></a>        auto frameJobId = gDisplayQueue.pop();
<a id="__codelineno-13-39" name="__codelineno-13-39" href="#__codelineno-13-39"></a>
<a id="__codelineno-13-40" name="__codelineno-13-40" href="#__codelineno-13-40"></a>        // output data of ieB
<a id="__codelineno-13-41" name="__codelineno-13-41" href="#__codelineno-13-41"></a>        auto outputB = ieB.Wait(frameJobId.jobId_B);
<a id="__codelineno-13-42" name="__codelineno-13-42" href="#__codelineno-13-42"></a>
<a id="__codelineno-13-43" name="__codelineno-13-43" href="#__codelineno-13-43"></a>        // post-processing w/ outputA &amp; outputB
<a id="__codelineno-13-44" name="__codelineno-13-44" href="#__codelineno-13-44"></a>        postProcessingB(outputB);
<a id="__codelineno-13-45" name="__codelineno-13-45" href="#__codelineno-13-45"></a>
<a id="__codelineno-13-46" name="__codelineno-13-46" href="#__codelineno-13-46"></a>        gTotalDisplayCount++;
<a id="__codelineno-13-47" name="__codelineno-13-47" href="#__codelineno-13-47"></a>
<a id="__codelineno-13-48" name="__codelineno-13-48" href="#__codelineno-13-48"></a>        // display (update framebuffer)
<a id="__codelineno-13-49" name="__codelineno-13-49" href="#__codelineno-13-49"></a>        if ( frameJobId.loopIndex == (loopCount - 1)) break;
<a id="__codelineno-13-50" name="__codelineno-13-50" href="#__codelineno-13-50"></a>    }
<a id="__codelineno-13-51" name="__codelineno-13-51" href="#__codelineno-13-51"></a>
<a id="__codelineno-13-52" name="__codelineno-13-52" href="#__codelineno-13-52"></a>    return 0;
<a id="__codelineno-13-53" name="__codelineno-13-53" href="#__codelineno-13-53"></a>}
<a id="__codelineno-13-54" name="__codelineno-13-54" href="#__codelineno-13-54"></a>
<a id="__codelineno-13-55" name="__codelineno-13-55" href="#__codelineno-13-55"></a>static int cpuOperationThreadFunc(int loopCount, dxrt::InferenceEngine&amp; ieA, dxrt::InferenceEngine&amp; ieB)
<a id="__codelineno-13-56" name="__codelineno-13-56" href="#__codelineno-13-56"></a>{
<a id="__codelineno-13-57" name="__codelineno-13-57" href="#__codelineno-13-57"></a>
<a id="__codelineno-13-58" name="__codelineno-13-58" href="#__codelineno-13-58"></a>    while(gTotalDisplayCount.load() &lt; loopCount)
<a id="__codelineno-13-59" name="__codelineno-13-59" href="#__codelineno-13-59"></a>    {
<a id="__codelineno-13-60" name="__codelineno-13-60" href="#__codelineno-13-60"></a>        // consumer framebuffer &amp; jobIds
<a id="__codelineno-13-61" name="__codelineno-13-61" href="#__codelineno-13-61"></a>        auto frameJobIdA = gCPUOPQueue.pop();
<a id="__codelineno-13-62" name="__codelineno-13-62" href="#__codelineno-13-62"></a>
<a id="__codelineno-13-63" name="__codelineno-13-63" href="#__codelineno-13-63"></a>        // output data of ieA
<a id="__codelineno-13-64" name="__codelineno-13-64" href="#__codelineno-13-64"></a>        auto outputA = ieA.Wait(frameJobIdA.jobId_A);
<a id="__codelineno-13-65" name="__codelineno-13-65" href="#__codelineno-13-65"></a>
<a id="__codelineno-13-66" name="__codelineno-13-66" href="#__codelineno-13-66"></a>        // post-processing w/ outputA
<a id="__codelineno-13-67" name="__codelineno-13-67" href="#__codelineno-13-67"></a>        postProcessingA(frameJobIdA.inputBufferB, outputA);
<a id="__codelineno-13-68" name="__codelineno-13-68" href="#__codelineno-13-68"></a>
<a id="__codelineno-13-69" name="__codelineno-13-69" href="#__codelineno-13-69"></a>        FrameJobId frameJobIdB;
<a id="__codelineno-13-70" name="__codelineno-13-70" href="#__codelineno-13-70"></a>        frameJobIdB.loopIndex = frameJobIdA.loopIndex;
<a id="__codelineno-13-71" name="__codelineno-13-71" href="#__codelineno-13-71"></a>        frameJobIdB.jobId_B = ieB.RunAsync(frameJobIdA.inputBufferB);
<a id="__codelineno-13-72" name="__codelineno-13-72" href="#__codelineno-13-72"></a>
<a id="__codelineno-13-73" name="__codelineno-13-73" href="#__codelineno-13-73"></a>        gDisplayQueue.push(frameJobIdB);
<a id="__codelineno-13-74" name="__codelineno-13-74" href="#__codelineno-13-74"></a>
<a id="__codelineno-13-75" name="__codelineno-13-75" href="#__codelineno-13-75"></a>        // display (update framebuffer)
<a id="__codelineno-13-76" name="__codelineno-13-76" href="#__codelineno-13-76"></a>        if ( frameJobIdA.loopIndex == (loopCount - 1)) break;
<a id="__codelineno-13-77" name="__codelineno-13-77" href="#__codelineno-13-77"></a>    }
<a id="__codelineno-13-78" name="__codelineno-13-78" href="#__codelineno-13-78"></a>
<a id="__codelineno-13-79" name="__codelineno-13-79" href="#__codelineno-13-79"></a>    return 0;
<a id="__codelineno-13-80" name="__codelineno-13-80" href="#__codelineno-13-80"></a>}
<a id="__codelineno-13-81" name="__codelineno-13-81" href="#__codelineno-13-81"></a>
<a id="__codelineno-13-82" name="__codelineno-13-82" href="#__codelineno-13-82"></a>
<a id="__codelineno-13-83" name="__codelineno-13-83" href="#__codelineno-13-83"></a>int main(int argc, char* argv[])
<a id="__codelineno-13-84" name="__codelineno-13-84" href="#__codelineno-13-84"></a>{
<a id="__codelineno-13-85" name="__codelineno-13-85" href="#__codelineno-13-85"></a>
<a id="__codelineno-13-86" name="__codelineno-13-86" href="#__codelineno-13-86"></a>    ...
<a id="__codelineno-13-87" name="__codelineno-13-87" href="#__codelineno-13-87"></a>
<a id="__codelineno-13-88" name="__codelineno-13-88" href="#__codelineno-13-88"></a>    try
<a id="__codelineno-13-89" name="__codelineno-13-89" href="#__codelineno-13-89"></a>    {
<a id="__codelineno-13-90" name="__codelineno-13-90" href="#__codelineno-13-90"></a>
<a id="__codelineno-13-91" name="__codelineno-13-91" href="#__codelineno-13-91"></a>        // create inference engine instance with model
<a id="__codelineno-13-92" name="__codelineno-13-92" href="#__codelineno-13-92"></a>        dxrt::InferenceEngine ieA(modelPath);
<a id="__codelineno-13-93" name="__codelineno-13-93" href="#__codelineno-13-93"></a>
<a id="__codelineno-13-94" name="__codelineno-13-94" href="#__codelineno-13-94"></a>        gInputBufferPool_A = std::make_shared&lt;SimpleCircularBufferPool&lt;uint8_t&gt;&gt;(BUFFER_POOL_SIZE, ieA.GetInputSize());
<a id="__codelineno-13-95" name="__codelineno-13-95" href="#__codelineno-13-95"></a>
<a id="__codelineno-13-96" name="__codelineno-13-96" href="#__codelineno-13-96"></a>        // create inference engine instance with model
<a id="__codelineno-13-97" name="__codelineno-13-97" href="#__codelineno-13-97"></a>        dxrt::InferenceEngine ieB(modelPath);
<a id="__codelineno-13-98" name="__codelineno-13-98" href="#__codelineno-13-98"></a>
<a id="__codelineno-13-99" name="__codelineno-13-99" href="#__codelineno-13-99"></a>        gInputBufferPool_B = std::make_shared&lt;SimpleCircularBufferPool&lt;uint8_t&gt;&gt;(BUFFER_POOL_SIZE, ieB.GetInputSize());
<a id="__codelineno-13-100" name="__codelineno-13-100" href="#__codelineno-13-100"></a>
<a id="__codelineno-13-101" name="__codelineno-13-101" href="#__codelineno-13-101"></a>        const int W = 512, H = 512, CH = 3;
<a id="__codelineno-13-102" name="__codelineno-13-102" href="#__codelineno-13-102"></a>        gFrameBufferPool = std::make_shared&lt;SimpleCircularBufferPool&lt;uint8_t&gt;&gt;(BUFFER_POOL_SIZE, W*H*CH);
<a id="__codelineno-13-103" name="__codelineno-13-103" href="#__codelineno-13-103"></a>
<a id="__codelineno-13-104" name="__codelineno-13-104" href="#__codelineno-13-104"></a>        // create thread
<a id="__codelineno-13-105" name="__codelineno-13-105" href="#__codelineno-13-105"></a>        std::thread cpuOperationThread(cpuOperationThreadFunc, loop_count, std::ref(ieA), std::ref(ieB));
<a id="__codelineno-13-106" name="__codelineno-13-106" href="#__codelineno-13-106"></a>        std::thread displayThread(displayThreadFunc, loop_count, std::ref(ieB));
<a id="__codelineno-13-107" name="__codelineno-13-107" href="#__codelineno-13-107"></a>
<a id="__codelineno-13-108" name="__codelineno-13-108" href="#__codelineno-13-108"></a>
<a id="__codelineno-13-109" name="__codelineno-13-109" href="#__codelineno-13-109"></a>        // input processing
<a id="__codelineno-13-110" name="__codelineno-13-110" href="#__codelineno-13-110"></a>        for(int i = 0; i &lt; loop_count; ++i)
<a id="__codelineno-13-111" name="__codelineno-13-111" href="#__codelineno-13-111"></a>        {
<a id="__codelineno-13-112" name="__codelineno-13-112" href="#__codelineno-13-112"></a>            uint8_t* frameBuffer = gFrameBufferPool-&gt;pointer(); 
<a id="__codelineno-13-113" name="__codelineno-13-113" href="#__codelineno-13-113"></a>            readFrameBuffer(frameBuffer, W, H, CH);
<a id="__codelineno-13-114" name="__codelineno-13-114" href="#__codelineno-13-114"></a>
<a id="__codelineno-13-115" name="__codelineno-13-115" href="#__codelineno-13-115"></a>            uint8_t* inputA = gInputBufferPool_A-&gt;pointer();
<a id="__codelineno-13-116" name="__codelineno-13-116" href="#__codelineno-13-116"></a>            preProcessing(inputA, frameBuffer);
<a id="__codelineno-13-117" name="__codelineno-13-117" href="#__codelineno-13-117"></a>
<a id="__codelineno-13-118" name="__codelineno-13-118" href="#__codelineno-13-118"></a>            // struct to pass to a thread 
<a id="__codelineno-13-119" name="__codelineno-13-119" href="#__codelineno-13-119"></a>            FrameJobId frameJobId;
<a id="__codelineno-13-120" name="__codelineno-13-120" href="#__codelineno-13-120"></a>
<a id="__codelineno-13-121" name="__codelineno-13-121" href="#__codelineno-13-121"></a>            frameJobId.inputBufferA = inputA;
<a id="__codelineno-13-122" name="__codelineno-13-122" href="#__codelineno-13-122"></a>            frameJobId.inputBufferB = gInputBufferPool_B-&gt;pointer();
<a id="__codelineno-13-123" name="__codelineno-13-123" href="#__codelineno-13-123"></a>
<a id="__codelineno-13-124" name="__codelineno-13-124" href="#__codelineno-13-124"></a>            // start inference of A model
<a id="__codelineno-13-125" name="__codelineno-13-125" href="#__codelineno-13-125"></a>            frameJobId.jobId_A = ieA.RunAsync(inputA);
<a id="__codelineno-13-126" name="__codelineno-13-126" href="#__codelineno-13-126"></a>
<a id="__codelineno-13-127" name="__codelineno-13-127" href="#__codelineno-13-127"></a>            // framebuffer used for input data
<a id="__codelineno-13-128" name="__codelineno-13-128" href="#__codelineno-13-128"></a>            frameJobId.frameBuffer = frameBuffer;
<a id="__codelineno-13-129" name="__codelineno-13-129" href="#__codelineno-13-129"></a>            frameJobId.loopIndex = i;
<a id="__codelineno-13-130" name="__codelineno-13-130" href="#__codelineno-13-130"></a>
<a id="__codelineno-13-131" name="__codelineno-13-131" href="#__codelineno-13-131"></a>            // producer frame &amp; jobId
<a id="__codelineno-13-132" name="__codelineno-13-132" href="#__codelineno-13-132"></a>            gCPUOPQueue.push(frameJobId);
<a id="__codelineno-13-133" name="__codelineno-13-133" href="#__codelineno-13-133"></a>
<a id="__codelineno-13-134" name="__codelineno-13-134" href="#__codelineno-13-134"></a>        }
<a id="__codelineno-13-135" name="__codelineno-13-135" href="#__codelineno-13-135"></a>
<a id="__codelineno-13-136" name="__codelineno-13-136" href="#__codelineno-13-136"></a>        cpuOperationThread.join();
<a id="__codelineno-13-137" name="__codelineno-13-137" href="#__codelineno-13-137"></a>        displayThread.join();
<a id="__codelineno-13-138" name="__codelineno-13-138" href="#__codelineno-13-138"></a>
<a id="__codelineno-13-139" name="__codelineno-13-139" href="#__codelineno-13-139"></a>    }
<a id="__codelineno-13-140" name="__codelineno-13-140" href="#__codelineno-13-140"></a>    catch (const dxrt::Exception&amp; e)
<a id="__codelineno-13-141" name="__codelineno-13-141" href="#__codelineno-13-141"></a>    {
<a id="__codelineno-13-142" name="__codelineno-13-142" href="#__codelineno-13-142"></a>        std::cerr &lt;&lt; e.what() &lt;&lt; &quot; error-code=&quot; &lt;&lt; e.code() &lt;&lt; std::endl;
<a id="__codelineno-13-143" name="__codelineno-13-143" href="#__codelineno-13-143"></a>        return -1;
<a id="__codelineno-13-144" name="__codelineno-13-144" href="#__codelineno-13-144"></a>    }
<a id="__codelineno-13-145" name="__codelineno-13-145" href="#__codelineno-13-145"></a>    catch (const std::exception&amp; e)
<a id="__codelineno-13-146" name="__codelineno-13-146" href="#__codelineno-13-146"></a>    {
<a id="__codelineno-13-147" name="__codelineno-13-147" href="#__codelineno-13-147"></a>        std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;
<a id="__codelineno-13-148" name="__codelineno-13-148" href="#__codelineno-13-148"></a>        return -1;
<a id="__codelineno-13-149" name="__codelineno-13-149" href="#__codelineno-13-149"></a>    }
<a id="__codelineno-13-150" name="__codelineno-13-150" href="#__codelineno-13-150"></a>    catch(...)
<a id="__codelineno-13-151" name="__codelineno-13-151" href="#__codelineno-13-151"></a>    {
<a id="__codelineno-13-152" name="__codelineno-13-152" href="#__codelineno-13-152"></a>        std::cerr &lt;&lt; &quot;Exception&quot; &lt;&lt; std::endl;
<a id="__codelineno-13-153" name="__codelineno-13-153" href="#__codelineno-13-153"></a>        return -1;
<a id="__codelineno-13-154" name="__codelineno-13-154" href="#__codelineno-13-154"></a>    }
<a id="__codelineno-13-155" name="__codelineno-13-155" href="#__codelineno-13-155"></a>
<a id="__codelineno-13-156" name="__codelineno-13-156" href="#__codelineno-13-156"></a>    return 0;
<a id="__codelineno-13-157" name="__codelineno-13-157" href="#__codelineno-13-157"></a>}
</code></pre></div></p>
<hr />
<h3 id="exception">Exception<a class="headerlink" href="#exception" title="Permanent link">&para;</a></h3>
<p>The error codes and types of exceptions for error handling are as follows.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a>enum ERROR_CODE {
<a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a>        DEFAULT = 0x0100,
<a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a>        FILE_NOT_FOUND,
<a id="__codelineno-14-4" name="__codelineno-14-4" href="#__codelineno-14-4"></a>        NULL_POINTER,
<a id="__codelineno-14-5" name="__codelineno-14-5" href="#__codelineno-14-5"></a>        FILE_IO,
<a id="__codelineno-14-6" name="__codelineno-14-6" href="#__codelineno-14-6"></a>        INVALID_ARGUMENT,
<a id="__codelineno-14-7" name="__codelineno-14-7" href="#__codelineno-14-7"></a>        INVALID_OPERATION,
<a id="__codelineno-14-8" name="__codelineno-14-8" href="#__codelineno-14-8"></a>        INVALID_MODEL,
<a id="__codelineno-14-9" name="__codelineno-14-9" href="#__codelineno-14-9"></a>        MODEL_PARSING,
<a id="__codelineno-14-10" name="__codelineno-14-10" href="#__codelineno-14-10"></a>        SERVICE_IO,
<a id="__codelineno-14-11" name="__codelineno-14-11" href="#__codelineno-14-11"></a>        DEVICE_IO
<a id="__codelineno-14-12" name="__codelineno-14-12" href="#__codelineno-14-12"></a>    };
</code></pre></div>
<ul>
<li>FileNotFoundException  </li>
<li>NullPointerException  </li>
<li>FileIOException  </li>
<li>InvalidArgumentException  </li>
<li>InvalidOperationException  </li>
<li>InvalidModelException  </li>
<li>ModelParsingException  </li>
<li>ServiceIOException  </li>
<li>DeviceIOException  </li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a>    // try/catch prototype
<a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a>
<a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a>    try
<a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a>    {
<a id="__codelineno-15-5" name="__codelineno-15-5" href="#__codelineno-15-5"></a>        // DX-RT APIs ...
<a id="__codelineno-15-6" name="__codelineno-15-6" href="#__codelineno-15-6"></a>    }
<a id="__codelineno-15-7" name="__codelineno-15-7" href="#__codelineno-15-7"></a>    catch(const dxrt::Exception&amp; e)  // exception for inference engine 
<a id="__codelineno-15-8" name="__codelineno-15-8" href="#__codelineno-15-8"></a>    {
<a id="__codelineno-15-9" name="__codelineno-15-9" href="#__codelineno-15-9"></a>        std::cerr &lt;&lt; e.what() &lt;&lt; &quot; error-code=&quot; &lt;&lt; e.code() &lt;&lt; std::endl;
<a id="__codelineno-15-10" name="__codelineno-15-10" href="#__codelineno-15-10"></a>        return -1; // or std::exit(-1);
<a id="__codelineno-15-11" name="__codelineno-15-11" href="#__codelineno-15-11"></a>    }
<a id="__codelineno-15-12" name="__codelineno-15-12" href="#__codelineno-15-12"></a>    catch(std::exception&amp; e)
<a id="__codelineno-15-13" name="__codelineno-15-13" href="#__codelineno-15-13"></a>    {
<a id="__codelineno-15-14" name="__codelineno-15-14" href="#__codelineno-15-14"></a>        std::cerr &lt;&lt; e.what() &lt;&lt; std::endl;
<a id="__codelineno-15-15" name="__codelineno-15-15" href="#__codelineno-15-15"></a>        return -1;  // or std::exit(-1);
<a id="__codelineno-15-16" name="__codelineno-15-16" href="#__codelineno-15-16"></a>    }
</code></pre></div>
<hr />
<h3 id="multi-input&gt;_inference">Multi-Input Inference<a class="headerlink" href="#multi-input&gt;_inference" title="Permanent link">&para;</a></h3>
<p>This guide explains various methods for performing inference on multi-input models using the <code>dxrt::InferenceEngine</code>. The examples cover different input formats, synchronous and asynchronous execution, and batch processing.</p>
<h4 id="model&gt;_information">Model Information<a class="headerlink" href="#model&gt;_information" title="Permanent link">&para;</a></h4>
<p>Before running inference, it's useful to inspect the model's properties. The <code>printModelInfo</code> function shows how to query the inference engine for details about the model's input and output tensors.</p>
<ul>
<li><strong><code>ie.IsMultiInputModel()</code></strong>: Checks if the loaded model has multiple inputs.</li>
<li><strong><code>ie.GetInputTensorCount()</code></strong>: Gets the number of input tensors.</li>
<li><strong><code>ie.GetInputTensorNames()</code></strong>: Retrieves the names of all input tensors.</li>
<li><strong><code>ie.GetInputTensorSizes()</code></strong>: Gets the size (in bytes) of each input tensor.</li>
<li><strong><code>ie.GetOutputTensorNames()</code> / <code>ie.GetOutputTensorSizes()</code></strong>: Provide similar information for output tensors.</li>
</ul>
<!-- end list -->

<div class="highlight"><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a><span class="kt">void</span><span class="w"> </span><span class="nf">printModelInfo</span><span class="p">(</span><span class="n">dxrt</span><span class="o">::</span><span class="n">InferenceEngine</span><span class="o">&amp;</span><span class="w"> </span><span class="n">ie</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">ie</span><span class="p">.</span><span class="n">IsMultiInputModel</span><span class="p">())</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-16-3" name="__codelineno-16-3" href="#__codelineno-16-3"></a><span class="w">        </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;Input tensor count: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">ie</span><span class="p">.</span><span class="n">GetInputTensorCount</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<a id="__codelineno-16-4" name="__codelineno-16-4" href="#__codelineno-16-4"></a><span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">inputNames</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ie</span><span class="p">.</span><span class="n">GetInputTensorNames</span><span class="p">();</span>
<a id="__codelineno-16-5" name="__codelineno-16-5" href="#__codelineno-16-5"></a><span class="w">        </span><span class="k">auto</span><span class="w"> </span><span class="n">inputSizes</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ie</span><span class="p">.</span><span class="n">GetInputTensorSizes</span><span class="p">();</span>
<a id="__codelineno-16-6" name="__codelineno-16-6" href="#__codelineno-16-6"></a><span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">size_t</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">inputNames</span><span class="p">.</span><span class="n">size</span><span class="p">();</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-16-7" name="__codelineno-16-7" href="#__codelineno-16-7"></a><span class="w">            </span><span class="n">std</span><span class="o">::</span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;  &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">inputNames</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot;: &quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">inputSizes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s">&quot; bytes&quot;</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
<a id="__codelineno-16-8" name="__codelineno-16-8" href="#__codelineno-16-8"></a><span class="w">        </span><span class="p">}</span>
<a id="__codelineno-16-9" name="__codelineno-16-9" href="#__codelineno-16-9"></a><span class="w">    </span><span class="p">}</span>
<a id="__codelineno-16-10" name="__codelineno-16-10" href="#__codelineno-16-10"></a><span class="p">}</span>
</code></pre></div>
<h4 id="synchronous&gt;_single&gt;_inference">Synchronous Single Inference<a class="headerlink" href="#synchronous&gt;_single&gt;_inference" title="Permanent link">&para;</a></h4>
<p>These examples demonstrate different ways to run a single inference request synchronously.</p>
<h5 id="input&gt;_formats">Input Formats<a class="headerlink" href="#input&gt;_formats" title="Permanent link">&para;</a></h5>
<h6 id="a&gt;_dictionary&gt;_format&gt;_stdmapstdstring&gt;_void">A. Dictionary Format (<code>std::map&lt;std::string, void*&gt;</code>)<a class="headerlink" href="#a&gt;_dictionary&gt;_format&gt;_stdmapstdstring&gt;_void" title="Permanent link">&para;</a></h6>
<p>This is the most robust method. You provide a map where keys are the tensor names and values are pointers to the input data. This format is not sensitive to the order of tensors.</p>
<ul>
<li><strong>API</strong>: <code>ie.RunMultiInput(inputTensors)</code></li>
<li><strong>Use Case</strong>: Recommended for clarity and to avoid errors from tensor reordering.</li>
</ul>
<!-- end list -->

<div class="highlight"><pre><span></span><code><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a><span class="c1">// Create input data</span>
<a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a><span class="n">std</span><span class="o">::</span><span class="n">map</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="o">*&gt;</span><span class="w"> </span><span class="n">inputTensors</span><span class="p">;</span>
<a id="__codelineno-17-3" name="__codelineno-17-3" href="#__codelineno-17-3"></a><span class="n">inputTensors</span><span class="p">[</span><span class="s">&quot;input_1&quot;</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inputData1</span><span class="p">.</span><span class="n">data</span><span class="p">();</span>
<a id="__codelineno-17-4" name="__codelineno-17-4" href="#__codelineno-17-4"></a><span class="n">inputTensors</span><span class="p">[</span><span class="s">&quot;input_2&quot;</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inputData2</span><span class="p">.</span><span class="n">data</span><span class="p">();</span>
<a id="__codelineno-17-5" name="__codelineno-17-5" href="#__codelineno-17-5"></a>
<a id="__codelineno-17-6" name="__codelineno-17-6" href="#__codelineno-17-6"></a><span class="c1">// Run inference</span>
<a id="__codelineno-17-7" name="__codelineno-17-7" href="#__codelineno-17-7"></a><span class="k">auto</span><span class="w"> </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ie</span><span class="p">.</span><span class="n">RunMultiInput</span><span class="p">(</span><span class="n">inputTensors</span><span class="p">);</span>
</code></pre></div>
<h6 id="b&gt;_vector&gt;_format&gt;_stdvectorvoid">B. Vector Format (<code>std::vector&lt;void*&gt;</code>)<a class="headerlink" href="#b&gt;_vector&gt;_format&gt;_stdvectorvoid" title="Permanent link">&para;</a></h6>
<p>You provide a vector of pointers to the input data. The order of pointers in the vector <strong>must</strong> match the order returned by <code>ie.GetInputTensorNames()</code>.</p>
<ul>
<li><strong>API</strong>: <code>ie.RunMultiInput(inputPtrs)</code></li>
<li><strong>Use Case</strong>: When tensor order is known and fixed. Can be slightly more performant than the map-based approach due to less overhead.</li>
</ul>
<!-- end list -->

<div class="highlight"><pre><span></span><code><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a><span class="c1">// Create input data in the correct order</span>
<a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">void</span><span class="o">*&gt;</span><span class="w"> </span><span class="n">inputPtrs</span><span class="p">;</span>
<a id="__codelineno-18-3" name="__codelineno-18-3" href="#__codelineno-18-3"></a><span class="n">inputPtrs</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">inputData1</span><span class="p">.</span><span class="n">data</span><span class="p">());</span><span class="w"> </span><span class="c1">// Corresponds to first name in GetInputTensorNames()</span>
<a id="__codelineno-18-4" name="__codelineno-18-4" href="#__codelineno-18-4"></a><span class="n">inputPtrs</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">inputData2</span><span class="p">.</span><span class="n">data</span><span class="p">());</span><span class="w"> </span><span class="c1">// Corresponds to second name</span>
<a id="__codelineno-18-5" name="__codelineno-18-5" href="#__codelineno-18-5"></a>
<a id="__codelineno-18-6" name="__codelineno-18-6" href="#__codelineno-18-6"></a><span class="c1">// Run inference</span>
<a id="__codelineno-18-7" name="__codelineno-18-7" href="#__codelineno-18-7"></a><span class="k">auto</span><span class="w"> </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ie</span><span class="p">.</span><span class="n">RunMultiInput</span><span class="p">(</span><span class="n">inputPtrs</span><span class="p">);</span>
</code></pre></div>
<h6 id="c&gt;_auto-split&gt;_concatenated&gt;_buffer">C. Auto-Split Concatenated Buffer<a class="headerlink" href="#c&gt;_auto-split&gt;_concatenated&gt;_buffer" title="Permanent link">&para;</a></h6>
<p>You provide a single, contiguous buffer containing all input data concatenated together. The engine automatically splits this buffer into the correct tensor inputs based on their sizes. The concatenation order <strong>must</strong> match the order from <code>ie.GetInputTensorNames()</code>.</p>
<ul>
<li><strong>API</strong>: <code>ie.Run(concatenatedInput.data())</code></li>
<li><strong>Use Case</strong>: Efficient when input data is already in a single block or when interfacing with systems that provide data this way.</li>
</ul>
<!-- end list -->

<div class="highlight"><pre><span></span><code><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a><span class="c1">// Create a single buffer with all input data concatenated</span>
<a id="__codelineno-19-2" name="__codelineno-19-2" href="#__codelineno-19-2"></a><span class="k">auto</span><span class="w"> </span><span class="n">concatenatedInput</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">createDummyInput</span><span class="p">(</span><span class="n">ie</span><span class="p">.</span><span class="n">GetInputSize</span><span class="p">());</span>
<a id="__codelineno-19-3" name="__codelineno-19-3" href="#__codelineno-19-3"></a>
<a id="__codelineno-19-4" name="__codelineno-19-4" href="#__codelineno-19-4"></a><span class="c1">// Run inference</span>
<a id="__codelineno-19-5" name="__codelineno-19-5" href="#__codelineno-19-5"></a><span class="k">auto</span><span class="w"> </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ie</span><span class="p">.</span><span class="n">Run</span><span class="p">(</span><span class="n">concatenatedInput</span><span class="p">.</span><span class="n">data</span><span class="p">());</span>
</code></pre></div>
<h5 id="output&gt;_buffer&gt;_management">Output Buffer Management<a class="headerlink" href="#output&gt;_buffer&gt;_management" title="Permanent link">&para;</a></h5>
<p>For each synchronous method, you can either let the engine allocate output memory automatically or provide a pre-allocated buffer for performance gains.</p>
<ul>
<li>
<p><strong>Auto-Allocated Output (No Buffer Provided)</strong>: Simpler to use. The engine returns smart pointers to newly allocated memory.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a><span class="c1">// Engine allocates and manages output memory</span>
<a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a><span class="k">auto</span><span class="w"> </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ie</span><span class="p">.</span><span class="n">RunMultiInput</span><span class="p">(</span><span class="n">inputTensors</span><span class="p">);</span>
</code></pre></div>
</li>
<li>
<p><strong>User-Provided Output Buffer</strong>: More performant as it avoids repeated memory allocations. The user is responsible for allocating a buffer of size <code>ie.GetOutputSize()</code>.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a><span class="c1">// User allocates the output buffer</span>
<a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">uint8_t</span><span class="o">&gt;</span><span class="w"> </span><span class="n">outputBuffer</span><span class="p">(</span><span class="n">ie</span><span class="p">.</span><span class="n">GetOutputSize</span><span class="p">());</span>
<a id="__codelineno-21-3" name="__codelineno-21-3" href="#__codelineno-21-3"></a>
<a id="__codelineno-21-4" name="__codelineno-21-4" href="#__codelineno-21-4"></a><span class="c1">// Run inference, placing results in the provided buffer</span>
<a id="__codelineno-21-5" name="__codelineno-21-5" href="#__codelineno-21-5"></a><span class="k">auto</span><span class="w"> </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ie</span><span class="p">.</span><span class="n">RunMultiInput</span><span class="p">(</span><span class="n">inputTensors</span><span class="p">,</span><span class="w"> </span><span class="k">nullptr</span><span class="p">,</span><span class="w"> </span><span class="n">outputBuffer</span><span class="p">.</span><span class="n">data</span><span class="p">());</span>
</code></pre></div>
</li>
</ul>
<h4 id="synchronous&gt;_batch&gt;_inference">Synchronous Batch Inference<a class="headerlink" href="#synchronous&gt;_batch&gt;_inference" title="Permanent link">&para;</a></h4>
<p>For processing multiple inputs at once to maximize throughput, you can use the batch inference API. This is more efficient than running single inferences in a loop.</p>
<ul>
<li><strong>API</strong>: <code>ie.Run(batchInputPtrs, batchOutputPtrs, userArgs)</code></li>
<li><strong>Input</strong>: A vector of pointers, where each pointer is a concatenated buffer for one sample in the batch.</li>
<li><strong>Output</strong>: A vector of pointers, where each pointer is a pre-allocated buffer for the corresponding sample's output.</li>
</ul>
<!-- end list -->

<div class="highlight"><pre><span></span><code><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a><span class="kt">int</span><span class="w"> </span><span class="n">batchSize</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">3</span><span class="p">;</span>
<a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">void</span><span class="o">*&gt;</span><span class="w"> </span><span class="n">batchInputPtrs</span><span class="p">;</span>
<a id="__codelineno-22-3" name="__codelineno-22-3" href="#__codelineno-22-3"></a><span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">void</span><span class="o">*&gt;</span><span class="w"> </span><span class="n">batchOutputPtrs</span><span class="p">;</span>
<a id="__codelineno-22-4" name="__codelineno-22-4" href="#__codelineno-22-4"></a>
<a id="__codelineno-22-5" name="__codelineno-22-5" href="#__codelineno-22-5"></a><span class="c1">// Prepare input and output buffers for each sample in the batch</span>
<a id="__codelineno-22-6" name="__codelineno-22-6" href="#__codelineno-22-6"></a><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">batchSize</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-22-7" name="__codelineno-22-7" href="#__codelineno-22-7"></a><span class="w">    </span><span class="c1">// Each input is a full concatenated buffer</span>
<a id="__codelineno-22-8" name="__codelineno-22-8" href="#__codelineno-22-8"></a><span class="w">    </span><span class="n">batchInputData</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">createDummyInput</span><span class="p">(</span><span class="n">ie</span><span class="p">.</span><span class="n">GetInputSize</span><span class="p">());</span>
<a id="__codelineno-22-9" name="__codelineno-22-9" href="#__codelineno-22-9"></a><span class="w">    </span><span class="n">batchInputPtrs</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">batchInputData</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">data</span><span class="p">());</span>
<a id="__codelineno-22-10" name="__codelineno-22-10" href="#__codelineno-22-10"></a>
<a id="__codelineno-22-11" name="__codelineno-22-11" href="#__codelineno-22-11"></a><span class="w">    </span><span class="c1">// Pre-allocate output buffer for each sample</span>
<a id="__codelineno-22-12" name="__codelineno-22-12" href="#__codelineno-22-12"></a><span class="w">    </span><span class="n">batchOutputData</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">resize</span><span class="p">(</span><span class="n">ie</span><span class="p">.</span><span class="n">GetOutputSize</span><span class="p">());</span>
<a id="__codelineno-22-13" name="__codelineno-22-13" href="#__codelineno-22-13"></a><span class="w">    </span><span class="n">batchOutputPtrs</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">batchOutputData</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">data</span><span class="p">());</span>
<a id="__codelineno-22-14" name="__codelineno-22-14" href="#__codelineno-22-14"></a><span class="p">}</span>
<a id="__codelineno-22-15" name="__codelineno-22-15" href="#__codelineno-22-15"></a>
<a id="__codelineno-22-16" name="__codelineno-22-16" href="#__codelineno-22-16"></a><span class="c1">// Run batch inference</span>
<a id="__codelineno-22-17" name="__codelineno-22-17" href="#__codelineno-22-17"></a><span class="k">auto</span><span class="w"> </span><span class="n">batchOutputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ie</span><span class="p">.</span><span class="n">Run</span><span class="p">(</span><span class="n">batchInputPtrs</span><span class="p">,</span><span class="w"> </span><span class="n">batchOutputPtrs</span><span class="p">);</span>
</code></pre></div>
<h4 id="asynchronous&gt;_inference">Asynchronous Inference<a class="headerlink" href="#asynchronous&gt;_inference" title="Permanent link">&para;</a></h4>
<p>Asynchronous APIs allow you to submit inference requests without blocking the calling thread. The results are returned later via a callback function. This is ideal for applications that need to remain responsive, such as those with a user interface.</p>
<ul>
<li><strong>APIs</strong>:<ul>
<li><code>ie.RunAsyncMultiInput(inputTensors, userArg)</code></li>
<li><code>ie.RunAsync(concatenatedInput.data(), userArg)</code></li>
</ul>
</li>
<li><strong>Callback Registration</strong>: <code>ie.RegisterCallback(callback_function)</code></li>
</ul>
<p>The <code>AsyncInferenceHandler</code> class demonstrates how to manage state across multiple asynchronous calls.</p>
<ul>
<li><strong>Register a Callback</strong>: Provide a function that the engine will call upon completion of each async request. The callback receives the output tensors and a <code>userArg</code> pointer for context.</li>
<li><strong>Submit Requests</strong>: Call an <code>RunAsync</code> variant. This call returns immediately with a job ID.</li>
<li><strong>Process in Callback</strong>: The callback function is executed in a separate worker thread. Here, you can process the results. It's crucial to ensure thread safety if you modify shared data.</li>
</ul>
<!-- end list -->

<div class="highlight"><pre><span></span><code><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a><span class="c1">// 1. Create a handler and register its callback method</span>
<a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a><span class="n">AsyncInferenceHandler</span><span class="w"> </span><span class="nf">handler</span><span class="p">(</span><span class="n">asyncCount</span><span class="p">);</span>
<a id="__codelineno-23-3" name="__codelineno-23-3" href="#__codelineno-23-3"></a><span class="n">ie</span><span class="p">.</span><span class="n">RegisterCallback</span><span class="p">([</span><span class="o">&amp;</span><span class="n">handler</span><span class="p">](</span><span class="n">dxrt</span><span class="o">::</span><span class="n">TensorPtrs</span><span class="o">&amp;</span><span class="w"> </span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">userArg</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-23-4" name="__codelineno-23-4" href="#__codelineno-23-4"></a><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">handler</span><span class="p">.</span><span class="n">callback</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span><span class="w"> </span><span class="n">userArg</span><span class="p">);</span>
<a id="__codelineno-23-5" name="__codelineno-23-5" href="#__codelineno-23-5"></a><span class="p">});</span>
<a id="__codelineno-23-6" name="__codelineno-23-6" href="#__codelineno-23-6"></a>
<a id="__codelineno-23-7" name="__codelineno-23-7" href="#__codelineno-23-7"></a><span class="c1">// 2. Submit multiple async requests in a loop</span>
<a id="__codelineno-23-8" name="__codelineno-23-8" href="#__codelineno-23-8"></a><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">asyncCount</span><span class="p">;</span><span class="w"> </span><span class="o">++</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<a id="__codelineno-23-9" name="__codelineno-23-9" href="#__codelineno-23-9"></a><span class="w">    </span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">userArg</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">reinterpret_cast</span><span class="o">&lt;</span><span class="kt">void</span><span class="o">*&gt;</span><span class="p">(</span><span class="k">static_cast</span><span class="o">&lt;</span><span class="kt">uintptr_t</span><span class="o">&gt;</span><span class="p">(</span><span class="n">i</span><span class="p">));</span>
<a id="__codelineno-23-10" name="__codelineno-23-10" href="#__codelineno-23-10"></a><span class="w">    </span><span class="c1">// Each call is non-blocking</span>
<a id="__codelineno-23-11" name="__codelineno-23-11" href="#__codelineno-23-11"></a><span class="w">    </span><span class="n">ie</span><span class="p">.</span><span class="n">RunAsyncMultiInput</span><span class="p">(</span><span class="n">asyncInputTensors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">userArg</span><span class="p">);</span>
<a id="__codelineno-23-12" name="__codelineno-23-12" href="#__codelineno-23-12"></a><span class="p">}</span>
<a id="__codelineno-23-13" name="__codelineno-23-13" href="#__codelineno-23-13"></a>
<a id="__codelineno-23-14" name="__codelineno-23-14" href="#__codelineno-23-14"></a><span class="c1">// 3. Wait for all callbacks to complete</span>
<a id="__codelineno-23-15" name="__codelineno-23-15" href="#__codelineno-23-15"></a><span class="n">handler</span><span class="p">.</span><span class="n">waitForCompletion</span><span class="p">();</span>
<a id="__codelineno-23-16" name="__codelineno-23-16" href="#__codelineno-23-16"></a>
<a id="__codelineno-23-17" name="__codelineno-23-17" href="#__codelineno-23-17"></a><span class="c1">// 4. Clear the callback when done</span>
<a id="__codelineno-23-18" name="__codelineno-23-18" href="#__codelineno-23-18"></a><span class="n">ie</span><span class="p">.</span><span class="n">RegisterCallback</span><span class="p">(</span><span class="k">nullptr</span><span class="p">);</span>
</code></pre></div>
<hr />
<h3 id="examples">Examples<a class="headerlink" href="#examples" title="Permanent link">&para;</a></h3>
<p>The examples provided earlier are actual code samples that can be executed. Please refer to them for practical use.  </p>
<ul>
<li><code>display_async_pipe</code><br />
    : An example using <code>[CPU_1 → {NPU_1 + NPU_2} → CPU_2]</code> pattern  </li>
<li><code>display_async_wait</code><br />
    : An example using <code>[CPU_1 → NPU_1 → CPU_2 → NPU_2 → CPU_3]</code> pattern  </li>
<li><code>display_async_thread</code><br />
    : An example using single model and multi threads  </li>
<li><code>display_async_models_1</code><br />
    : An example using multi models and multi threads (Inference Engine is created within each thread)  </li>
<li><code>display_async_models_2</code><br />
    : An example using multi models and multi threads (Inference Engine is created in the main thread)  </li>
<li><code>run_async_model</code><br />
    : A performance-optimized example using a callback function  </li>
<li><code>run_async_model_thread</code><br />
    : An example using a single inference engine, callback function, and thread<br />
    : Usage method when there is a single AI model and multiple inputs  </li>
<li><code>run_async_model_wait</code><br />
    : An example using threads and waits  </li>
<li><code>run_async_model_conf</code><br />
    : An example of using configuration  </li>
<li><code>run_async_model_profiler</code><br />
    : An example of using profiler  </li>
<li><code>run_async_model_conf</code><br />
    : An example of using configuration and device status  </li>
<li><code>run_async_model_profiler</code><br />
    : An example of using profiler configuration </li>
<li><code>run_sync_model</code><br />
    : An example using a single thread  </li>
<li><code>run_sync_model_thread</code><br />
    : An example running an inference engine on multiple threads  </li>
<li><code>run_sync_model_bound</code><br />
    : An example of specifying an NPU using the bound option  </li>
<li><code>run_batch_model</code><br />
    : An example of using batch inference  </li>
<li><code>multi_input_model_inference</code><br />
    : An example of using multi-input model inference  </li>
</ul>
<hr />












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      ⓒ Copyright 2025 <a href="http://deepx.ai">DEEPX</a>. All Rights Reserved.
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/company/deepx-corporation/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["toc.integrate", "content.code.annotate", "navigation.tabs", "navigation.tabs.sticky", "content.tabs.link", "content.code.copy"], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>