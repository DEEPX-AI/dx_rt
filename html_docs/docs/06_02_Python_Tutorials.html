
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="06_01_C%2B%2B_Tutorials.html">
      
      
        <link rel="next" href="07_01_C%2B%2B_API_Reference.html">
      
      
      <link rel="icon" href="../img/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>Python Tutorials - DXNN Runtime (DX-RT) User Manual</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans+Display:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Noto Sans Display";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#run>_synchronous" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="DXNN Runtime (DX-RT) User Manual" class="md-header__button md-logo" aria-label="DXNN Runtime (DX-RT) User Manual" data-md-component="logo">
      
  <img src="../img/deepx.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            DXNN Runtime (DX-RT) User Manual
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Python Tutorials
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="01_DXNN_Runtime_Overview.html" class="md-tabs__link">
        
  
  
    
  
  DXNN Runtime Overview

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="02_Installation_on_Linux.html" class="md-tabs__link">
        
  
  
    
  
  Installation on Linux

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="03_Installation_on_Windows.html" class="md-tabs__link">
        
  
  
    
  
  Installation on Windows

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="04_Model_Inference.html" class="md-tabs__link">
        
  
  
    
  
  Model Inference

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="05_Command_Line_Interface.html" class="md-tabs__link">
        
  
  
    
  
  Command Line Interface

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="06_01_C%2B%2B_Tutorials.html" class="md-tabs__link">
          
  
  
  Tutorials

        </a>
      </li>
    
  

      
        
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="07_01_C%2B%2B_API_Reference.html" class="md-tabs__link">
          
  
  
  API Reference

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="Appendix_Change_Log.html" class="md-tabs__link">
        
  
  
    
  
  Change Log

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="DXNN Runtime (DX-RT) User Manual" class="md-nav__button md-logo" aria-label="DXNN Runtime (DX-RT) User Manual" data-md-component="logo">
      
  <img src="../img/deepx.png" alt="logo">

    </a>
    DXNN Runtime (DX-RT) User Manual
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="01_DXNN_Runtime_Overview.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    DXNN Runtime Overview
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="02_Installation_on_Linux.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Installation on Linux
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="03_Installation_on_Windows.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Installation on Windows
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="04_Model_Inference.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Model Inference
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="05_Command_Line_Interface.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Command Line Interface
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" checked>
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Tutorials
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="06_01_C%2B%2B_Tutorials.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    C++ Tutorials
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Python Tutorials
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="06_02_Python_Tutorials.html" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Python Tutorials
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#run>_synchronous" class="md-nav__link">
    <span class="md-ellipsis">
      Run (Synchronous)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#runasync>_asynchronous" class="md-nav__link">
    <span class="md-ellipsis">
      RunAsync (Asynchronous)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#run>_batch" class="md-nav__link">
    <span class="md-ellipsis">
      Run (Batch)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#inference>_option" class="md-nav__link">
    <span class="md-ellipsis">
      Inference Option
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#examples" class="md-nav__link">
    <span class="md-ellipsis">
      Examples
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    API Reference
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="07_01_C%2B%2B_API_Reference.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    C++ API Reference
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="07_02_Python_API_Reference.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python API Reference
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="Appendix_Change_Log.html" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Change Log
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



  <h1>Python Tutorials</h1>

<h3 id="run&gt;_synchronous">Run (Synchronous)<a class="headerlink" href="#run&gt;_synchronous" title="Permanent link">&para;</a></h3>
<p>The synchronous Run method uses a single NPU core to perform inference in a blocking manner. It can be configured to utilize multiple NPU cores simultaneously by employing threads to run each core independently. (Refer to <strong>Figure</strong> in <strong>Section 5.2. Inference Workflow</strong>)  </p>
<p><strong>Inference Engine Run (Python)</strong>  </p>
<p><code>run_sync_model.py</code></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a># DX-RT importes
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>from dx_engine import InferenceEngine
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>...
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>if __name__ == &quot;__main__&quot;:
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    ...    
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a>
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a>    # create inference engine instance with model
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a>    ie = InferenceEngine(modelPath)
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>    input = [np.zeros(ie.GetInputSize(), dtype=np.uint8)]
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a>
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a>    # inference loop
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    for i in range(loop_count):
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>        # inference synchronously 
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>        # use only one npu core 
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>        outputs = ie.Run(input)
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a>
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a>        # post processing 
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>        postProcessing(outputs)
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a>
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a>    exit(0)
</code></pre></div>
<h3 id="runasync&gt;_asynchronous">RunAsync (Asynchronous)<a class="headerlink" href="#runasync&gt;_asynchronous" title="Permanent link">&para;</a></h3>
<p>The asynchronous Run mode is a method that performs inference asynchronously while utilizing multiple NPU cores simultaneously. It can be implemented to maximize NPU resources through a callback function or a thread wait mechanism. </p>
<p>Inference Engine RunAsync, Callback, User Argument  </p>
<ul>
<li>the outputs are guaranteed to be valid <strong>only</strong> within this callback function  </li>
<li>processing this callback functions as quickly as possible is beneficial for improving inference performance  </li>
<li>inference asynchronously, use all npu cores  </li>
<li>if <code>device-load &gt;= max-load-value</code>, this function will block  </li>
</ul>
<p>The following is an example of asynchronous inference using a callback function. A user argument can be used to synchronize the input with the output of the callback.  </p>
<p><strong>Inference Engine RunAsync, Callback, User Argument (Python)</strong></p>
<p><code>run_async_model.py</code></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>from dx_engine import InferenceEngine
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>...
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>q = queue.Queue()
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>gLoopCount = 0
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>
<a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a>lock = threading.Lock()
<a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>
<a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a>def onInferenceCallbackFunc(outputs, user_arg):
<a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a>
<a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>    # the outputs are guaranteed to be valid only within this callback function
<a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a>    # processing this callback functions as quickly as possible is beneficial 
<a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>    # for improving inference performance
<a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a>
<a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a>    global gLoopCount
<a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a>
<a id="__codelineno-1-17" name="__codelineno-1-17" href="#__codelineno-1-17"></a>    # Mutex locks should be properly adjusted 
<a id="__codelineno-1-18" name="__codelineno-1-18" href="#__codelineno-1-18"></a>    # to ensure that callback functions are thread-safe.
<a id="__codelineno-1-19" name="__codelineno-1-19" href="#__codelineno-1-19"></a>    with lock:
<a id="__codelineno-1-20" name="__codelineno-1-20" href="#__codelineno-1-20"></a>        # user data type casting
<a id="__codelineno-1-21" name="__codelineno-1-21" href="#__codelineno-1-21"></a>        index, loop_count = user_arg
<a id="__codelineno-1-22" name="__codelineno-1-22" href="#__codelineno-1-22"></a>
<a id="__codelineno-1-23" name="__codelineno-1-23" href="#__codelineno-1-23"></a>
<a id="__codelineno-1-24" name="__codelineno-1-24" href="#__codelineno-1-24"></a>        # post processing
<a id="__codelineno-1-25" name="__codelineno-1-25" href="#__codelineno-1-25"></a>        #postProcessing(outputs);
<a id="__codelineno-1-26" name="__codelineno-1-26" href="#__codelineno-1-26"></a>
<a id="__codelineno-1-27" name="__codelineno-1-27" href="#__codelineno-1-27"></a>        # something to do
<a id="__codelineno-1-28" name="__codelineno-1-28" href="#__codelineno-1-28"></a>
<a id="__codelineno-1-29" name="__codelineno-1-29" href="#__codelineno-1-29"></a>        print(&quot;Inference output (callback) index=&quot;, index)
<a id="__codelineno-1-30" name="__codelineno-1-30" href="#__codelineno-1-30"></a>
<a id="__codelineno-1-31" name="__codelineno-1-31" href="#__codelineno-1-31"></a>        gLoopCount += 1
<a id="__codelineno-1-32" name="__codelineno-1-32" href="#__codelineno-1-32"></a>        if ( gLoopCount == loop_count ) :
<a id="__codelineno-1-33" name="__codelineno-1-33" href="#__codelineno-1-33"></a>            print(&quot;Complete Callback&quot;)
<a id="__codelineno-1-34" name="__codelineno-1-34" href="#__codelineno-1-34"></a>            q.put(0)
<a id="__codelineno-1-35" name="__codelineno-1-35" href="#__codelineno-1-35"></a>
<a id="__codelineno-1-36" name="__codelineno-1-36" href="#__codelineno-1-36"></a>    return 0
<a id="__codelineno-1-37" name="__codelineno-1-37" href="#__codelineno-1-37"></a>
<a id="__codelineno-1-38" name="__codelineno-1-38" href="#__codelineno-1-38"></a>
<a id="__codelineno-1-39" name="__codelineno-1-39" href="#__codelineno-1-39"></a>if __name__ == &quot;__main__&quot;:
<a id="__codelineno-1-40" name="__codelineno-1-40" href="#__codelineno-1-40"></a>
<a id="__codelineno-1-41" name="__codelineno-1-41" href="#__codelineno-1-41"></a>    ...    
<a id="__codelineno-1-42" name="__codelineno-1-42" href="#__codelineno-1-42"></a>
<a id="__codelineno-1-43" name="__codelineno-1-43" href="#__codelineno-1-43"></a>    # create inference engine instance with model
<a id="__codelineno-1-44" name="__codelineno-1-44" href="#__codelineno-1-44"></a>    ie = InferenceEngine(modelPath)
<a id="__codelineno-1-45" name="__codelineno-1-45" href="#__codelineno-1-45"></a>
<a id="__codelineno-1-46" name="__codelineno-1-46" href="#__codelineno-1-46"></a>    # register call back function
<a id="__codelineno-1-47" name="__codelineno-1-47" href="#__codelineno-1-47"></a>    ie.register_callback(onInferenceCallbackFunc)
<a id="__codelineno-1-48" name="__codelineno-1-48" href="#__codelineno-1-48"></a>
<a id="__codelineno-1-49" name="__codelineno-1-49" href="#__codelineno-1-49"></a>
<a id="__codelineno-1-50" name="__codelineno-1-50" href="#__codelineno-1-50"></a>    input = [np.zeros(ie.GetInputSize(), dtype=np.uint8)]
<a id="__codelineno-1-51" name="__codelineno-1-51" href="#__codelineno-1-51"></a>
<a id="__codelineno-1-52" name="__codelineno-1-52" href="#__codelineno-1-52"></a>    # inference loop
<a id="__codelineno-1-53" name="__codelineno-1-53" href="#__codelineno-1-53"></a>    for i in range(loop_count):
<a id="__codelineno-1-54" name="__codelineno-1-54" href="#__codelineno-1-54"></a>
<a id="__codelineno-1-55" name="__codelineno-1-55" href="#__codelineno-1-55"></a>        # inference asynchronously, use all npu cores
<a id="__codelineno-1-56" name="__codelineno-1-56" href="#__codelineno-1-56"></a>        # if device-load &gt;= max-load-value, this function will block  
<a id="__codelineno-1-57" name="__codelineno-1-57" href="#__codelineno-1-57"></a>        ie.RunAsync(input, user_arg=[i, loop_count])
<a id="__codelineno-1-58" name="__codelineno-1-58" href="#__codelineno-1-58"></a>
<a id="__codelineno-1-59" name="__codelineno-1-59" href="#__codelineno-1-59"></a>        print(&quot;Inference start (async)&quot;, i)
<a id="__codelineno-1-60" name="__codelineno-1-60" href="#__codelineno-1-60"></a>
<a id="__codelineno-1-61" name="__codelineno-1-61" href="#__codelineno-1-61"></a>    exit(q.get())
</code></pre></div>
<p>The following is an example where multiple threads start input and inference, and a single callback processes the output.</p>
<p>Inference Engine RunAsync, Callback, User Argument, Thread  </p>
<ul>
<li>the outputs are guaranteed to be valid <strong>only</strong> within this callback function  </li>
<li>processing this callback functions as quickly as possible is beneficial for improving inference performance  </li>
<li>inference asynchronously, use all npu cores  </li>
<li>if <code>device-load &gt;= max-load-value</code>, this function will block  </li>
</ul>
<p><strong>Inference Engine RunAsync, Callback, User Argument, Thread (Python)</strong></p>
<p><code>run_async_model_thread.py</code>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>from dx_engine import InferenceEngine
<a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>...
<a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>
<a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a>THRAD_COUNT = 3
<a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a>total_count = 0
<a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a>q = queue.Queue()
<a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>
<a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a>lock = threading.Lock()
<a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a>
<a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a>
<a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a>def inferenceThreadFunc(ie, threadIndex, loopCount):
<a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a>
<a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a>    # input
<a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a>    input = [np.zeros(ie.get_input_size(), dtype=np.uint8)]
<a id="__codelineno-2-15" name="__codelineno-2-15" href="#__codelineno-2-15"></a>
<a id="__codelineno-2-16" name="__codelineno-2-16" href="#__codelineno-2-16"></a>    # inference loop
<a id="__codelineno-2-17" name="__codelineno-2-17" href="#__codelineno-2-17"></a>    for i in range(loopCount):
<a id="__codelineno-2-18" name="__codelineno-2-18" href="#__codelineno-2-18"></a>
<a id="__codelineno-2-19" name="__codelineno-2-19" href="#__codelineno-2-19"></a>        # inference asynchronously, use all npu cores
<a id="__codelineno-2-20" name="__codelineno-2-20" href="#__codelineno-2-20"></a>        # if device-load &gt;= max-load-value, this function will block  
<a id="__codelineno-2-21" name="__codelineno-2-21" href="#__codelineno-2-21"></a>        ie.RunAsync(input,user_arg = [i, loopCount, threadIndex])
<a id="__codelineno-2-22" name="__codelineno-2-22" href="#__codelineno-2-22"></a>
<a id="__codelineno-2-23" name="__codelineno-2-23" href="#__codelineno-2-23"></a>    return 0
<a id="__codelineno-2-24" name="__codelineno-2-24" href="#__codelineno-2-24"></a>
<a id="__codelineno-2-25" name="__codelineno-2-25" href="#__codelineno-2-25"></a>def onInferenceCallbackFunc(outputs, user_arg):
<a id="__codelineno-2-26" name="__codelineno-2-26" href="#__codelineno-2-26"></a>    # the outputs are guaranteed to be valid only within this callback function
<a id="__codelineno-2-27" name="__codelineno-2-27" href="#__codelineno-2-27"></a>    # processing this callback functions as quickly as possible is beneficial 
<a id="__codelineno-2-28" name="__codelineno-2-28" href="#__codelineno-2-28"></a>    # for improving inference performance
<a id="__codelineno-2-29" name="__codelineno-2-29" href="#__codelineno-2-29"></a>
<a id="__codelineno-2-30" name="__codelineno-2-30" href="#__codelineno-2-30"></a>    global total_count
<a id="__codelineno-2-31" name="__codelineno-2-31" href="#__codelineno-2-31"></a>
<a id="__codelineno-2-32" name="__codelineno-2-32" href="#__codelineno-2-32"></a>    # Mutex locks should be properly adjusted 
<a id="__codelineno-2-33" name="__codelineno-2-33" href="#__codelineno-2-33"></a>    # to ensure that callback functions are thread-safe.
<a id="__codelineno-2-34" name="__codelineno-2-34" href="#__codelineno-2-34"></a>    with lock:
<a id="__codelineno-2-35" name="__codelineno-2-35" href="#__codelineno-2-35"></a>        # user data type casting
<a id="__codelineno-2-36" name="__codelineno-2-36" href="#__codelineno-2-36"></a>        index = user_arg[0]
<a id="__codelineno-2-37" name="__codelineno-2-37" href="#__codelineno-2-37"></a>        loop_count = user_arg[1]
<a id="__codelineno-2-38" name="__codelineno-2-38" href="#__codelineno-2-38"></a>        thread_index = user_arg[2]
<a id="__codelineno-2-39" name="__codelineno-2-39" href="#__codelineno-2-39"></a>
<a id="__codelineno-2-40" name="__codelineno-2-40" href="#__codelineno-2-40"></a>        # post processing
<a id="__codelineno-2-41" name="__codelineno-2-41" href="#__codelineno-2-41"></a>        #postProcessing(outputs);
<a id="__codelineno-2-42" name="__codelineno-2-42" href="#__codelineno-2-42"></a>
<a id="__codelineno-2-43" name="__codelineno-2-43" href="#__codelineno-2-43"></a>        # something to do
<a id="__codelineno-2-44" name="__codelineno-2-44" href="#__codelineno-2-44"></a>
<a id="__codelineno-2-45" name="__codelineno-2-45" href="#__codelineno-2-45"></a>        total_count += 1
<a id="__codelineno-2-46" name="__codelineno-2-46" href="#__codelineno-2-46"></a>
<a id="__codelineno-2-47" name="__codelineno-2-47" href="#__codelineno-2-47"></a>        if ( total_count ==  loop_count * THRAD_COUNT) :
<a id="__codelineno-2-48" name="__codelineno-2-48" href="#__codelineno-2-48"></a>            q.put(0)
<a id="__codelineno-2-49" name="__codelineno-2-49" href="#__codelineno-2-49"></a>
<a id="__codelineno-2-50" name="__codelineno-2-50" href="#__codelineno-2-50"></a>    return 0
<a id="__codelineno-2-51" name="__codelineno-2-51" href="#__codelineno-2-51"></a>
<a id="__codelineno-2-52" name="__codelineno-2-52" href="#__codelineno-2-52"></a>
<a id="__codelineno-2-53" name="__codelineno-2-53" href="#__codelineno-2-53"></a>if __name__ == &quot;__main__&quot;:
<a id="__codelineno-2-54" name="__codelineno-2-54" href="#__codelineno-2-54"></a>    ...    
<a id="__codelineno-2-55" name="__codelineno-2-55" href="#__codelineno-2-55"></a>
<a id="__codelineno-2-56" name="__codelineno-2-56" href="#__codelineno-2-56"></a>    # create inference engine instance with model
<a id="__codelineno-2-57" name="__codelineno-2-57" href="#__codelineno-2-57"></a>    ie = InferenceEngine(modelPath)
<a id="__codelineno-2-58" name="__codelineno-2-58" href="#__codelineno-2-58"></a>
<a id="__codelineno-2-59" name="__codelineno-2-59" href="#__codelineno-2-59"></a>    # register call back function
<a id="__codelineno-2-60" name="__codelineno-2-60" href="#__codelineno-2-60"></a>    ie.register_callback(onInferenceCallbackFunc)
<a id="__codelineno-2-61" name="__codelineno-2-61" href="#__codelineno-2-61"></a>
<a id="__codelineno-2-62" name="__codelineno-2-62" href="#__codelineno-2-62"></a>
<a id="__codelineno-2-63" name="__codelineno-2-63" href="#__codelineno-2-63"></a>    t1 = threading.Thread(target=inferenceThreadFunc, args=(ie, 0, loop_count))
<a id="__codelineno-2-64" name="__codelineno-2-64" href="#__codelineno-2-64"></a>    t2 = threading.Thread(target=inferenceThreadFunc, args=(ie, 1, loop_count))
<a id="__codelineno-2-65" name="__codelineno-2-65" href="#__codelineno-2-65"></a>    t3 = threading.Thread(target=inferenceThreadFunc, args=(ie, 2, loop_count))
<a id="__codelineno-2-66" name="__codelineno-2-66" href="#__codelineno-2-66"></a>
<a id="__codelineno-2-67" name="__codelineno-2-67" href="#__codelineno-2-67"></a>    # Start and join
<a id="__codelineno-2-68" name="__codelineno-2-68" href="#__codelineno-2-68"></a>    t1.start()
<a id="__codelineno-2-69" name="__codelineno-2-69" href="#__codelineno-2-69"></a>    t2.start()
<a id="__codelineno-2-70" name="__codelineno-2-70" href="#__codelineno-2-70"></a>    t3.start()
<a id="__codelineno-2-71" name="__codelineno-2-71" href="#__codelineno-2-71"></a>
<a id="__codelineno-2-72" name="__codelineno-2-72" href="#__codelineno-2-72"></a>
<a id="__codelineno-2-73" name="__codelineno-2-73" href="#__codelineno-2-73"></a>    # join
<a id="__codelineno-2-74" name="__codelineno-2-74" href="#__codelineno-2-74"></a>    t1.join()
<a id="__codelineno-2-75" name="__codelineno-2-75" href="#__codelineno-2-75"></a>    t2.join()
<a id="__codelineno-2-76" name="__codelineno-2-76" href="#__codelineno-2-76"></a>    t3.join()
<a id="__codelineno-2-77" name="__codelineno-2-77" href="#__codelineno-2-77"></a>
<a id="__codelineno-2-78" name="__codelineno-2-78" href="#__codelineno-2-78"></a>
<a id="__codelineno-2-79" name="__codelineno-2-79" href="#__codelineno-2-79"></a>    exit(q.get())
</code></pre></div></p>
<p>The following is an example of performing asynchronous inference by creating an inference wait thread. The main thread starts input and inference, and the inference wait thread retrieves the output data corresponding to the input.</p>
<p>Inference Engine RunAsync, Wait  </p>
<ul>
<li>inference asynchronously, use all npu cores  </li>
<li>if <code>device-load &gt;= max-load-value</code>, this function will block  </li>
</ul>
<p><strong>Inference Engine RunAsync, Wait (Python)</strong></p>
<p><code>run_async_model_wait.py</code>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a># DX-RT imports
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>from dx_engine import InferenceEngine
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>...
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>
<a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>q = queue.Queue()
<a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>
<a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>
<a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>def inferenceThreadFunc(ie, loopCount):
<a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>
<a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>    count = 0
<a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>
<a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a>    while(True):
<a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>
<a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a>        # pop item from queue 
<a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a>        jobId = q.get()
<a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a>
<a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a>        # waiting for the inference to complete by jobId
<a id="__codelineno-3-18" name="__codelineno-3-18" href="#__codelineno-3-18"></a>        # ownership of the outputs is transferred to the user 
<a id="__codelineno-3-19" name="__codelineno-3-19" href="#__codelineno-3-19"></a>        outputs = ie.Wait(jobId)
<a id="__codelineno-3-20" name="__codelineno-3-20" href="#__codelineno-3-20"></a>
<a id="__codelineno-3-21" name="__codelineno-3-21" href="#__codelineno-3-21"></a>        # post processing
<a id="__codelineno-3-22" name="__codelineno-3-22" href="#__codelineno-3-22"></a>        # postProcessing(outputs);
<a id="__codelineno-3-23" name="__codelineno-3-23" href="#__codelineno-3-23"></a>
<a id="__codelineno-3-24" name="__codelineno-3-24" href="#__codelineno-3-24"></a>        # something to do
<a id="__codelineno-3-25" name="__codelineno-3-25" href="#__codelineno-3-25"></a>
<a id="__codelineno-3-26" name="__codelineno-3-26" href="#__codelineno-3-26"></a>        count += 1
<a id="__codelineno-3-27" name="__codelineno-3-27" href="#__codelineno-3-27"></a>        if ( count &gt;= loopCount ):
<a id="__codelineno-3-28" name="__codelineno-3-28" href="#__codelineno-3-28"></a>            break
<a id="__codelineno-3-29" name="__codelineno-3-29" href="#__codelineno-3-29"></a>
<a id="__codelineno-3-30" name="__codelineno-3-30" href="#__codelineno-3-30"></a>    return 0
<a id="__codelineno-3-31" name="__codelineno-3-31" href="#__codelineno-3-31"></a>
<a id="__codelineno-3-32" name="__codelineno-3-32" href="#__codelineno-3-32"></a>
<a id="__codelineno-3-33" name="__codelineno-3-33" href="#__codelineno-3-33"></a>if __name__ == &quot;__main__&quot;:
<a id="__codelineno-3-34" name="__codelineno-3-34" href="#__codelineno-3-34"></a>    ...
<a id="__codelineno-3-35" name="__codelineno-3-35" href="#__codelineno-3-35"></a>
<a id="__codelineno-3-36" name="__codelineno-3-36" href="#__codelineno-3-36"></a>    # create inference engine instance with model
<a id="__codelineno-3-37" name="__codelineno-3-37" href="#__codelineno-3-37"></a>    with InferenceEngine(modelPath) as ie:
<a id="__codelineno-3-38" name="__codelineno-3-38" href="#__codelineno-3-38"></a>
<a id="__codelineno-3-39" name="__codelineno-3-39" href="#__codelineno-3-39"></a>        # do not register call back function
<a id="__codelineno-3-40" name="__codelineno-3-40" href="#__codelineno-3-40"></a>        # ie.register_callback(onInferenceCallbackFunc)
<a id="__codelineno-3-41" name="__codelineno-3-41" href="#__codelineno-3-41"></a>
<a id="__codelineno-3-42" name="__codelineno-3-42" href="#__codelineno-3-42"></a>        t1 = threading.Thread(target=inferenceThreadFunc, args=(ie, loop_count))
<a id="__codelineno-3-43" name="__codelineno-3-43" href="#__codelineno-3-43"></a>
<a id="__codelineno-3-44" name="__codelineno-3-44" href="#__codelineno-3-44"></a>        t1.start()
<a id="__codelineno-3-45" name="__codelineno-3-45" href="#__codelineno-3-45"></a>
<a id="__codelineno-3-46" name="__codelineno-3-46" href="#__codelineno-3-46"></a>        input = [np.zeros(ie.get_input_size(), dtype=np.uint8)]
<a id="__codelineno-3-47" name="__codelineno-3-47" href="#__codelineno-3-47"></a>
<a id="__codelineno-3-48" name="__codelineno-3-48" href="#__codelineno-3-48"></a>        # inference loop
<a id="__codelineno-3-49" name="__codelineno-3-49" href="#__codelineno-3-49"></a>        for i in range(loop_count):
<a id="__codelineno-3-50" name="__codelineno-3-50" href="#__codelineno-3-50"></a>
<a id="__codelineno-3-51" name="__codelineno-3-51" href="#__codelineno-3-51"></a>            # inference asynchronously, use all npu cores
<a id="__codelineno-3-52" name="__codelineno-3-52" href="#__codelineno-3-52"></a>            # if device-load &gt;= max-load-value, this function will block  
<a id="__codelineno-3-53" name="__codelineno-3-53" href="#__codelineno-3-53"></a>            jobId = ie.run_async(input, user_arg=0)
<a id="__codelineno-3-54" name="__codelineno-3-54" href="#__codelineno-3-54"></a>
<a id="__codelineno-3-55" name="__codelineno-3-55" href="#__codelineno-3-55"></a>            q.put(jobId)
<a id="__codelineno-3-56" name="__codelineno-3-56" href="#__codelineno-3-56"></a>
<a id="__codelineno-3-57" name="__codelineno-3-57" href="#__codelineno-3-57"></a>        t1.join()
<a id="__codelineno-3-58" name="__codelineno-3-58" href="#__codelineno-3-58"></a>
<a id="__codelineno-3-59" name="__codelineno-3-59" href="#__codelineno-3-59"></a>    exit(0)
</code></pre></div></p>
<h3 id="run&gt;_batch">Run (Batch)<a class="headerlink" href="#run&gt;_batch" title="Permanent link">&para;</a></h3>
<p>The following is an example of batch inference with multiple inputs and multiple outputs.</p>
<p><code>run_batch_model.py</code></p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>import numpy as np
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>import sys
<a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a>from dx_engine import InferenceEngine
<a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a>from dx_engine import InferenceOption
<a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>
<a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>
<a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a>if __name__ == &quot;__main__&quot;:
<a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>    ...
<a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>
<a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a>    # create inference engine instance with model
<a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>    with InferenceEngine(modelPath) as ie:
<a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a>
<a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a>        input_buffers = []
<a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a>        output_buffers = []
<a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a>        index = 0
<a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a>        for b in range(batch_count):
<a id="__codelineno-4-17" name="__codelineno-4-17" href="#__codelineno-4-17"></a>            input_buffers.append([np.array([np.random.randint(0, 255)],  dtype=np.uint8)])
<a id="__codelineno-4-18" name="__codelineno-4-18" href="#__codelineno-4-18"></a>            output_buffers.append([np.zeros(ie.get_output_size(), dtype=np.uint8)])
<a id="__codelineno-4-19" name="__codelineno-4-19" href="#__codelineno-4-19"></a>            index = index + 1
<a id="__codelineno-4-20" name="__codelineno-4-20" href="#__codelineno-4-20"></a>
<a id="__codelineno-4-21" name="__codelineno-4-21" href="#__codelineno-4-21"></a>        # inference loop
<a id="__codelineno-4-22" name="__codelineno-4-22" href="#__codelineno-4-22"></a>        for i in range(loop_count):
<a id="__codelineno-4-23" name="__codelineno-4-23" href="#__codelineno-4-23"></a>
<a id="__codelineno-4-24" name="__codelineno-4-24" href="#__codelineno-4-24"></a>            # batch inference
<a id="__codelineno-4-25" name="__codelineno-4-25" href="#__codelineno-4-25"></a>            # It operates asynchronously internally 
<a id="__codelineno-4-26" name="__codelineno-4-26" href="#__codelineno-4-26"></a>            # for the specified number of batches and returns the results
<a id="__codelineno-4-27" name="__codelineno-4-27" href="#__codelineno-4-27"></a>            results = ie.run_batch(input_buffers, output_buffers)
<a id="__codelineno-4-28" name="__codelineno-4-28" href="#__codelineno-4-28"></a>
<a id="__codelineno-4-29" name="__codelineno-4-29" href="#__codelineno-4-29"></a>            # post processing 
<a id="__codelineno-4-30" name="__codelineno-4-30" href="#__codelineno-4-30"></a>
<a id="__codelineno-4-31" name="__codelineno-4-31" href="#__codelineno-4-31"></a>    exit(0)
</code></pre></div>
<h3 id="inference&gt;_option">Inference Option<a class="headerlink" href="#inference&gt;_option" title="Permanent link">&para;</a></h3>
<p>The following inference options allow you to specify an NPU core for performing inference.</p>
<p>Inference Engine Run, Inference Option  </p>
<ul>
<li>
<dl>
<dt>select devices</dt>
<dd>default device is <code>[]</code>  </dd>
<dd>Choose the device to utilize  (ex. <code>[0, 2]</code>)  </dd>
</dl>
</li>
<li>
<dl>
<dt>select bound option per device</dt>
<dd><code>InferenceOption.BOUND_OPTION.NPU_ALL</code>  </dd>
<dd><code>InferenceOption.BOUND_OPTION.NPU_0</code>  </dd>
<dd><code>InferenceOption.BOUND_OPTION.NPU_1</code>  </dd>
<dd><code>InferenceOption.BOUND_OPTION.NPU_2</code> </dd>
</dl>
</li>
<li>
<dl>
<dt>use onnx runtime library (<code>ORT</code>)</dt>
<dd><code>set_use_ort / get_use_ort</code>  </dd>
</dl>
</li>
</ul>
<p>NPU_ALL / NPU_0 / NPU_1 / NPU_2
<div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a># DX-RT imports
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>from dx_engine import InferenceEngine, InferenceOption
<a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>...
<a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>
<a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>if __name__ == &quot;__main__&quot;:
<a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>    ...
<a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>
<a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>    # inference option
<a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a>    option = InferenceOption()
<a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>
<a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a>    print(&quot;Inference Options:&quot;)
<a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a>
<a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a>    # select devices
<a id="__codelineno-5-14" name="__codelineno-5-14" href="#__codelineno-5-14"></a>    option.devices = [0]
<a id="__codelineno-5-15" name="__codelineno-5-15" href="#__codelineno-5-15"></a>
<a id="__codelineno-5-16" name="__codelineno-5-16" href="#__codelineno-5-16"></a>    # NPU bound opion (NPU_ALL or NPU_0 or NPU_1 or NPU_2)
<a id="__codelineno-5-17" name="__codelineno-5-17" href="#__codelineno-5-17"></a>    option.bound_option = InferenceOption.BOUND_OPTION.NPU_ALL
<a id="__codelineno-5-18" name="__codelineno-5-18" href="#__codelineno-5-18"></a>
<a id="__codelineno-5-19" name="__codelineno-5-19" href="#__codelineno-5-19"></a>    # use ONNX Runtime (True or False)
<a id="__codelineno-5-20" name="__codelineno-5-20" href="#__codelineno-5-20"></a>    option.use_ort = False
<a id="__codelineno-5-21" name="__codelineno-5-21" href="#__codelineno-5-21"></a>
<a id="__codelineno-5-22" name="__codelineno-5-22" href="#__codelineno-5-22"></a>    # create inference engine instance with model
<a id="__codelineno-5-23" name="__codelineno-5-23" href="#__codelineno-5-23"></a>    with InferenceEngine(modelPath, option) as ie:
<a id="__codelineno-5-24" name="__codelineno-5-24" href="#__codelineno-5-24"></a>
<a id="__codelineno-5-25" name="__codelineno-5-25" href="#__codelineno-5-25"></a>        input = [np.zeros(ie.get_input_size(), dtype=np.uint8)]
<a id="__codelineno-5-26" name="__codelineno-5-26" href="#__codelineno-5-26"></a>
<a id="__codelineno-5-27" name="__codelineno-5-27" href="#__codelineno-5-27"></a>        # inference loop
<a id="__codelineno-5-28" name="__codelineno-5-28" href="#__codelineno-5-28"></a>        for i in range(loop_count):
<a id="__codelineno-5-29" name="__codelineno-5-29" href="#__codelineno-5-29"></a>
<a id="__codelineno-5-30" name="__codelineno-5-30" href="#__codelineno-5-30"></a>            # inference synchronously 
<a id="__codelineno-5-31" name="__codelineno-5-31" href="#__codelineno-5-31"></a>            # use only one npu core 
<a id="__codelineno-5-32" name="__codelineno-5-32" href="#__codelineno-5-32"></a>            # ownership of the outputs is transferred to the user 
<a id="__codelineno-5-33" name="__codelineno-5-33" href="#__codelineno-5-33"></a>            outputs = ie.run(input)
<a id="__codelineno-5-34" name="__codelineno-5-34" href="#__codelineno-5-34"></a>
<a id="__codelineno-5-35" name="__codelineno-5-35" href="#__codelineno-5-35"></a>            # post processing 
<a id="__codelineno-5-36" name="__codelineno-5-36" href="#__codelineno-5-36"></a>            #postProcessing(outputs)
<a id="__codelineno-5-37" name="__codelineno-5-37" href="#__codelineno-5-37"></a>            print(&quot;Inference outputs &quot;, i)
<a id="__codelineno-5-38" name="__codelineno-5-38" href="#__codelineno-5-38"></a>
<a id="__codelineno-5-39" name="__codelineno-5-39" href="#__codelineno-5-39"></a>    exit(0)
</code></pre></div></p>
<h3 id="examples">Examples<a class="headerlink" href="#examples" title="Permanent link">&para;</a></h3>
<p>The examples provided earlier are actual code samples that can be executed. Please refer to them for practical use. (<code>examples/python</code>)  </p>
<ul>
<li>
<dl>
<dt><code>run_async_model.py</code></dt>
<dd>A performance-optimized example using a callback function  </dd>
</dl>
</li>
<li>
<dl>
<dt><code>run_async_model_thread.py</code></dt>
<dd>An example using a single inference engine, callback function, and thread  </dd>
<dd>Usage method when there is a single AI model and multiple inputs  </dd>
</dl>
</li>
<li>
<dl>
<dt><code>run_async_model_wait.py</code></dt>
<dd>An example using threads and waits  </dd>
</dl>
</li>
<li>
<dl>
<dt><code>run_sync_model.py</code></dt>
<dd>An example using a single thread  </dd>
</dl>
</li>
<li>
<dl>
<dt><code>run_sync_model_thread.py</code></dt>
<dd>An example running an inference engine on multiple threads  </dd>
</dl>
</li>
<li>
<dl>
<dt><code>run_sync_model_bound.py</code></dt>
<dd>An example of specifying an NPU using the bound option  </dd>
</dl>
</li>
</ul>
<hr />












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
       Copyright 2025 <a href="http://deepx.ai">DEEPX</a>. All Rights Reserved.
    </div>
  
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/company/deepx-corporation/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["toc.integrate", "content.code.annotate", "navigation.tabs", "navigation.tabs.sticky", "content.tabs.link", "content.code.copy"], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>